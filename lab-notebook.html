<!DOCTYPE html>
<html lang="en" xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
  <head prefix="dc: http://purl.org/dc/terms/ og: http://ogp.me/ns#">
  <meta http-equiv='Content-Type' content='text/html; charset=utf-8'/>
  <title>Lab Notebook</title>
  <meta name="author" content="Carl Boettiger" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  

<!-- Get date last modified from git log. (Uses current time if file entry not found, e.g. projects/)  -->



<!-- For posts, page.date is the date they are published under, which we use as their 'canonical' dc:date -->
 <!-- If we don't have a page.date, then use modified time (pages) -->
   


<!-- Posts declare modified timestamps in the sidebar, so would be redundant to put here. But then 
     pages don't have a dc:modified... unless we give them their own (modified) sidebar?  
-->
<!-- Ideally we would want date originally created from the _oldest_ git commit too...-->

<!-- HTML5 metadata -->
<meta name="keywords" content="" />
<meta name="description" content="" />
<meta name="resource_type" content="website"/> 
<!-- RDFa Metadata (in DublinCore) -->
<meta property="dc:title" content="Lab Notebook" />
<meta property="dc:creator" content="Carl Boettiger" />
<meta property="dc:date" content="2013-04-12T08:53:44-07:00" />
<meta property="dc:format" content="text/html" />
<meta property="dc:language" content="en" />
<meta property="dc:identifier" content="/lab-notebook.html" />
<meta property="dc:rights" content="CC0" />
<meta property="dc:source" content="Lab Notebook" />
<meta property="dc:subject" content="Ecology" /> 
<meta property="dc:type" content="website" /> 
<!-- RDFa Metadata (in OpenGraph) -->
<meta property="og:title" content="Lab Notebook" />
<meta property="og:author" content="http://carlboettiger.info/index.html#me" />  <!-- Should be Liquid? URI? -->
<meta property="http://ogp.me/ns/profile#first_name" content="Carl"/>
<meta property="http://ogp.me/ns/profile#last_name" content="Boettiger"/>
<meta property="http://ogp.me/ns/article#published_time" content="2013-04-12T08:53:44-07:00" />
<meta property="og:site_name" content="Lab Notebook" /> <!-- Same as dc:source? -->
<meta property="og:url" content="http://carlboettiger.info/lab-notebook.html" />
<meta property="og:type" content="website" /> 
<!-- Google Scholar Metadata -->
<meta name="citation_author" content="Carl Boettiger"/>
<meta name="citation_date" content="2013-04-12T08:53:44-07:00"/>
<meta name="citation_title" content="Lab Notebook"/>
<meta name="citation_journal_title" content="Lab Notebook"/>

<!--NOTE: see also the COinS Metadata in span element in footer -->




  <!-- CSS Stylesheets (toggled with javascript) -->
  <link href="/assets/css/bootstrap.css" rel="stylesheet" 
        type="text/css" title="white" />
  <link href="/assets/css/light.css" rel="alternate stylesheet"
        type="text/css" id="stl" title="light" />
  <link href="/assets/css/dark.css" rel="alternate stylesheet" 
        type="text/css" title="dark" />
  <link href="/assets/css/bootstrap-responsive.css" rel="stylesheet" 
        type="text/css"/>
  <!-- Javascript needed for theme toggle, load immediately -->
  <script type="text/javascript" src="/assets/js/switch-css.js"></script>
  <script type="text/javascript">
    set_style_from_cookie(); 
  </script>
</head>


  <body prefix="dc: http://purl.org/dc/terms/ foaf: http://xmlns.com/foaf/0.1/"> 
    <!-- Navbar  ================================================== -->
<div class="navbar navbar-fixed-top">
  <div class="navbar-inner">
    <div class="container">
      <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </a>
      <a class="brand" href="/README.html"><i style="float:right;" class="icon-info-sign" alt="info"></i></span></a>
      <div class="nav-collapse">
        <ul class="nav">
          <li>
          <a href="/index.html">Home</a></li>

          <li>
          <a href="/vita.html">Vita</a></li>

          <li>
          <a href="/research.html">Research</a></li>

          <li>
          <a href="/teaching.html">Teaching</a></li>

          <li>
          <a href="/community.html">Community</a></li>

          <li class="active">
          <a href="/lab-notebook.html">Lab Notebook</a></li>

        </ul>
      </div><!--/.nav-collapse -->

      <!-- Search site using Google's index -->
      <form class="navbar-search pull-right" method="get" action="http://google.com/search">
        <p>
          <input type="hidden" name="q" value="site:carlboettiger.info" />
          <input type="text" class="search-query" name="q" />
          <button class="btn btn-mini" type="submit"><i class="icon-search"></i></button> 
        </p>
      </form>
      <!--
      <div id="search">
      <form method="get" class="navbar-search pull-right form-search">
        <p>
        <input type="text" name="search-text" id="search-text">
         <button class="btn btn-mini" type="submit"><i class="icon-search"></i></button> 
        </p>
      </form>
      </div>
      -->
     </div> <!-- /container -->
   </div> <!-- /navbar-inner -->
 </div> <!-- /navbar -->



    <div class="container"> <!-- Responsive grid layout --> 

      <header class="jumbotron">
  <h1 class="entry-title">Lab Notebook</h1>
  <h3>(<a href="http://www.carlboettiger.info/2012/09/28/Welcome-to-my-lab-notebook.html">Introduction</a>)</h3>
</header>



<div class="row feed">
  <div class="span3 offset1">
    <h4>  <a property="account" href="https://github.com/cboettig" onclick="recordOutboundLink(this, 'Outbound Links', 'Github'); return false;"><i class="icon-github" alt="github"></i> Coding </a></h4> 
     <div class="excerpt">
        <ul><li>cboettig pushed to master at cboettig/cboettig.github.com: <em>update site</em> <a href="https://github.com/cboettig/cboettig.github.com/compare/6fdaf5ec66...8a0af5a64c">04:15 2013/06/10</a></li><li>cboettig pushed to master at cboettig/labnotebook: <em>review moved to reviews repository instead new post updated and released post</em> <a href="https://github.com/cboettig/labnotebook/compare/60fee991d3...dd0c31f713">03:58 2013/06/10</a></li><li>cboettig pushed to master at cboettig/nonparametric-bayes: <em>myers model with diff parameters from parametric-vs-nonparametric at … allen model with diff parameters from process-noise-only at this comm…</em> <a href="https://github.com/cboettig/nonparametric-bayes/compare/239da673f5...a1dcf10186">10:49 2013/06/07</a></li><li>cboettig pushed to master at cboettig/nonparametric-bayes: <em>example set up based on Myers model simulations</em> <a href="https://github.com/cboettig/nonparametric-bayes/compare/f6de09b60a...239da673f5">10:42 2013/06/07</a></li><li>cboettig pushed to master at cboettig/nonparametric-bayes: <em>update (merge with process-noise-only) try searching in non-transformed paramaters on all models ignore mpi queue submit scripts</em> <a href="https://github.com/cboettig/nonparametric-bayes/compare/f4efe39de5...f6de09b60a">10:40 2013/06/07</a></li></ul>
    </div>
  </div>
  <div class="span3">
    <h4> <a property="account" href="https://twitter.com/cboettig" onclick="recordOutboundLink(this, 'Outbound Links', 'Twitter'); return false;"><i class="icon-twitter"></i> Discussing </a></h4> 
     <div class="excerpt">
       <ul><li><p>@phylorich @mwpennell @hylopsar @<em>inundata @stevenkembel @recology</em> @hadleywickham I prefer <code>keyword internal</code>, and not deleting .Rd ...</p>
 <a href="http://twitter.com/cboettig/statuses/343153047465250817">04:50 2013/06/07</a> </li><li><p>.@mwpennell @hylopsar @phylorich @<em>inundata @stevenkembel @recology</em> um but why is not doc internal #rstas fns a good idea?/ @hadleywickham</p>
 <a href="http://twitter.com/cboettig/statuses/343089299543183360">12:37 2013/06/07</a> </li><li><p>RT @omearabrian: @NIMBioS postdoc deadline Sept. 1: Work on your own project, many good colleagues, ample resources, biodiversity. http://t…</p>
 <a href="http://twitter.com/cboettig/statuses/342422255495684096">04:26 2013/06/05</a> </li><li><p>in PRSB: &quot;Optimal behaviour can violate the principle of regularity&quot;  <a href="http://t.co/iyq5xiuYDc">http://t.co/iyq5xiuYDc</a></p>
 <a href="http://twitter.com/cboettig/statuses/342308248793272320">08:53 2013/06/05</a> </li><li><p>@jbkinney @davidjayharris we say an SDE/Fokker Planck is a GP when the drift term is linear. So yes, BM is linear (zero-drift) GP</p>
 <a href="http://twitter.com/cboettig/statuses/342305439238725633">08:42 2013/06/05</a> </li></ul>
    </div> 
  </div> 
  <div class="span3">
    <h4> <a href="http://www.mendeley.com/groups/634301/theoretical-ecology/papers/" onClick="recordOutboundLink(this, 'Outbound Links', 'Mendeley'); return false;"><i class="icon-book"></i> Reading </a></h4> 
    <div class="excerpt">
      <ul><li>Review of Sokal and Rolf 2012 Biometry 4th Ed.: Limnology and Oceanography Bulletin (2013). Volume: 115, Issue: 2. Pages: 62-65. Stuart H. Hurlbert et al. <a href="http://www.mendeley.com/research/review-sokal-rolf-2012-biometry-4th-ed-1/">05:21 2013/06/03</a></li><li>Signature of ocean warming in global fisheries catch: Nature (2013). Volume: 497, Issue: 7449. Pages: 365-368. William W. L. Cheung, Reg Watson, Daniel Pauly et al. <a href="http://www.mendeley.com/research/signature-ocean-warming-global-fisheries-catch-7/">05:21 2013/06/03</a></li><li>Innovations in capture fisheries are an imperative for nutrition security in the developing world: Proceedings of the National Academy of Sciences (2013). Pages: 1-6. S. J. Hall, R. Hilborn, N. L. Andrew, E. H. Allison et al. <a href="http://www.mendeley.com/research/innovations-capture-fisheries-imperative-nutrition-security-developing-world/">05:21 2013/06/03</a></li><li>What early warning systems are there for environmental shocks?: Environmental Science & Policy (2013). Pages: S60-S75. Timothy M. Lenton et al. <a href="http://www.mendeley.com/research/early-warning-systems-environmental-shocks/">05:21 2013/06/03</a></li></ul>
    </div>
  </div> 
</div>

<hr>
<div class="row postpreview">
  <div class="span11 offset1">
    <div class="row">
      <h4> <a href="http://carlboettiger.info/atom.xml"
              onClick="recordOutboundLink(this,
              'Outbound Links', 'RSS'); return false;"
              style="color: inherit;"
              ><i class="icon-rss" ></i> Entries</a></h4>
      
        <div class="span3">
          <header><h4><a href="/2013/06/10/mansucript-reviews-on-github.html">maunscript reviews on github?</a></h4></header>
<p><span>examples and questions</span></p>
<p style="font-style:italic"> 10 Jun 2013</p>

<p style="font-style:italic"> pageviews: (not calculated) </p>

<article>
<div class="excerpt">
<p>I was recently impressed to learn of Trevor Bedford’s strategy of seeking <a href="https://twitter.com/trvrb/status/334310856982671361">pre-approval</a> for posting his reviewer’s comments as Github issues. Beyond providing links to the data and source-code, I generally don’t advertise the open science nature of papers I submit – I guess I assume that if the reader or reviewers care, it should be easy enough for them to discover it. Consequently I am usually immediately frustrated to realize that upon receiving my reviews I have to create a second, private repository for the review material, our replies to reviewers, etc., as I don’t have permission to disclose that information. <sup><a href="#fn1" class="footnoteRef" id="fnref1">1</a></sup> I have recently stumbled across <a href="http://www.steinsaltz.me.uk/pnas.html">several</a> <a href="http://theseamonster.net/2013/05/are-unreasonably-harsh-reviewers-retarding-the-pace-of-coral-reef-science/">examples</a> of authors publishing to the web anonymous reviews they have received. Though anonymous, I feel the practice potentially murky without explicit permission, so I would appreciate any insight others have on this.</p>
<h3 id="asking-permission">Asking permission</h3>
<p>Trevor’s approach suggests I should consider broaching this question when first submitting my review, so I am puzzling over the best way to do so. One option would be to include such a request in the cover letter. For example,</p>
<blockquote>
<p>The authors of this manuscript would like to request that the editor and reviewers indicate in their replies if they consent or decline to have their comments posted anonymously in the public <a href="#">Issues Tracker</a> of this paper.</p>
</blockquote>
<p>Does that need more explanation? A link to examples like <a href="https://github.com/trvrb/flux/issues?labels=reviewer+1">Trevor’s</a> that have done this before? Do I need to explain the value of having this kind of transparent provenance for the paper? Should I mention how this could give the reviewer more transparent credit? Encourage them to comment directly on Github from their own account?</p>
<p>Does this need the blessing of the journal? How would you feel about such a clause as a reviewer or editor? For a recent review I had done of a paper that was similarly written on Github, I obtained the Journal’s permission to post my review as an <a href="https://github.com/weecology/data-sharing-paper/issues/71">issue</a> in their repository. I would love to see more examples of this kind of thing, if anyone has come across them.</p>
<h2 id="cover-letters-for-open-science-manuscripts">Cover letters for open science manuscripts?</h2>
<p>While I lean towards a minimal statement such as the one above, perhaps a cover letter would be a good place to document some of the other open and reproducible features of the manuscript? Or perhaps such statements should be added to the manuscript itself? Among the options, I might point out:</p>
<ol type="1">
<li>The manuscript has been written on Github. Consequently the full drafting and <strong>revision history</strong> is available, along with graphs of author contributions (which omit authors without Github accounts and may be distorted by trivial line changes)</li>
<li>The manuscript has been written with all the code necessary to repoduce the results embedded as a <a href="http://yihui.name/knitr">knitr</a> <strong>dynamic document</strong>. This helps ensure the analysis is always in synch with the results presented in the manuscript and the that the research is reproducible. The analysis, figures, and manuscript can be reassembled from scratch by typing <code>make pdf</code> in the repository directory.<br /></li>
<li><strong>Code</strong> to replicate the analysis and produce each of the figures shown can be found at: (Version-stable lnk to the appropriate Github pages? Deposit in Figshare/Dryad first?)<br /></li>
<li><strong>Data</strong> to replicate the analysis and data shown in each of the figures can be found at: (Easiest to link to Github, since the code and data already reside there.<br /><em>Alternatively I could deposit these in <a href="http://figshare.com">Figshare</a> or <a href="http://datadryad.org">Dryad</a> first…)</em></li>
<li>The manuscript, code, data, and documentation are available <strong>as an R package in the Github repository</strong>.<br /></li>
<li>The <strong>issues tracker</strong> associated with the manuscript’s repository provides a record of this research, including lines of investigation that were resolved into the results presented here, lines that were closed as dead-ends or null results, and outstanding issues for further investigation.<br /></li>
<li>The <strong>daily lab notebook entries</strong> accompanying this research can be found under the <a href="/tags">project-tag</a> between dates of XX and XX.</li>
</ol>
<p>Listing all of these would make for a somewhat lengthy cover letter, which might be a bit overwhelming to be useful (or seem more promotional than valuable). Are any of the seven things above worth highlighting in particular?</p>
<p>Perhaps these details could be deferred to a README file in the project’s Github repo, and the cover letter could simply provide a link to the project repository? What, if anything, would appear most useful and accessible to a reviewer unfamiliar with this approach or its potential value? Though elements of this approach have been discussed in the published literature, e.g. <span class="showtooltip" title="Gentleman R and Temple Lang D (2007). Statistical Analyses And
Reproducible Research. _Journal of Computational And Graphical
Statistics_, *16*. ISSN 1061-8600, 
http://dx.doi.org/10.1198/106186007X178663."><a href="http://dx.doi.org/10.1198/106186007X178663" rel="http://purl.org/spar/cito/citesAsEvidence" >Gentleman &amp; Temple Lang (2007)</a></span> ‘compendium’ concept, <span class="showtooltip" title="Stodden V (2009). Enabling Reproducible Research: Open Licensing
for Scientific Innovation. 
http://papers.ssrn.com/sol3/papers.cfm?abstract_id=1362040. 
http://papers.ssrn.com/sol3/papers.cfm?abstract_id=1362040."><a href="http://papers.ssrn.com/sol3/papers.cfm?abstract_id=1362040" rel="http://purl.org/spar/cito/citesAsEvidence" >Stodden (2009)</a></span> RRS concept, or <span class="showtooltip" title="Peng R (2011). Reproducible Research in Computational Science.
_Science_, *334*. ISSN 0036-8075, 
http://dx.doi.org/10.1126/science.1213847."><a href="http://dx.doi.org/10.1126/science.1213847" rel="http://purl.org/spar/cito/citesAsEvidence" >Peng (2011)</a></span> reproducible papers in the Journal of Biostatistics, I’m unsure if pointing a reviewer to these references would be more valuable or more confusing. Let me know what you think.</p>
<h2 id="references">References</h2>
<ul>
<li>Robert Gentleman, Duncan Temple Lang, (2007) Statistical Analyses And Reproducible Research. <em>Journal of Computational And Graphical Statistics</em> <strong>16</strong> <a href="http://dx.doi.org/10.1198/106186007X178663">10.1198/106186007X178663</a></li>
<li>R. D. Peng, (2011) Reproducible Research in Computational Science. <em>Science</em> <strong>334</strong> <a href="http://dx.doi.org/10.1126/science.1213847">10.1126/science.1213847</a></li>
<li>Victoria Stodden, (2009) Enabling Reproducible Research: Open Licensing for Scientific Innovation. <a href="http://papers.ssrn.com/sol3/papers.cfm?abstract_id=1362040">http://papers.ssrn.com/sol3/papers.cfm?abstract_id=1362040</a></li>
</ul>
<section class="footnotes">
<hr />
<ol>
<li id="fn1"><p>Strictly speaking the edits to the manuscript in the open repository could also be considered confidential, though at that stage I haven’t yet signed the copyright agreements that come with publication, which tend to be quite reasonable even for the traditional subscription based journals I work with<a href="#fnref1">↩</a></p></li>
</ol>
</section>
 
<!-- not that raw_content depends on custom generator, 
     see _plugins/jekyll-labnotebook-plugins/raw_content --> 
</article> 
<p> <a href="/2013/06/10/mansucript-reviews-on-github.html"> <em>Read more</em></a> </p>
<br />
<br />


        </div>
      
        <div class="span3">
          <header><h4><a href="/2013/06/05/semi-analytic-posteriors.html">Semi Analytic Posteriors</a></h4></header>
<p><span></span></p>
<p style="font-style:italic"> 05 Jun 2013</p>

<p style="font-style:italic"> pageviews: 9 </p>

<article>
<div class="excerpt">
<p>The difficulty in comparing the nonparametric Bayesian inference against parametric Bayesian inference is ensuring that the poorer performance of the latter is not do to numerical limitations of the MCMC (no one is quite so worried about the cases where the mcmc solution appears to work well…) Convergence is almost impossible to truly establish, and lots of pathologies (correlations between variables, particularly without simulataneous updating) can frustrate it considerably. While multiple chains and long run times are the reasonable default, for simple enough models we can take a more direct approach.</p>
<ul>
<li>Script matches commit <a href="https://github.com/cboettig/nonparametric-bayes/blob/26d84c5c147d853a075dc5b1c1be593a38d04f10/inst/examples/semi-analytic-posteriors.md">26d84c/semi-analytic-posteriors.md</a></li>
</ul>
<h3 id="generating-model-and-parameters">Generating Model and parameters</h3>
<p>Ricker model, parameterized as</p>
<p><span class="math">\[X_{t+1} = X_t r e^{-\beta X_t + \sigma Z_t}\]</span></p>
<p>for random unit normal <span class="math">\(Z_t\)</span></p>
<pre class="sourceCode r"><code class="sourceCode r">f &lt;- function(x,h,p)  x * p[<span class="dv">1</span>] * <span class="kw">exp</span>(-x * p[<span class="dv">2</span>]) 
p &lt;- <span class="kw">c</span>(<span class="kw">exp</span>(<span class="dv">1</span>), <span class="dv">1</span>/<span class="dv">10</span>)
K &lt;- <span class="dv">10</span>  <span class="co"># approx, a li&#39;l&#39; less</span>
Xo &lt;- <span class="dv">1</span> <span class="co"># approx, a li&#39;l&#39; less</span></code></pre>
<pre class="sourceCode r"><code class="sourceCode r">sigma_g &lt;- <span class="fl">0.1</span>
z_g &lt;- function() <span class="kw">rlnorm</span>(<span class="dv">1</span>,<span class="dv">0</span>, sigma_g)
x_grid &lt;- <span class="kw">seq</span>(<span class="dv">0</span>, <span class="fl">1.5</span> * K, <span class="dt">length=</span><span class="dv">50</span>)
N &lt;- <span class="dv">40</span>
<span class="kw">set.seed</span>(<span class="dv">123</span>)</code></pre>
<h3 id="sample-data">Sample Data</h3>
<pre class="sourceCode r"><code class="sourceCode r">x &lt;- <span class="kw">numeric</span>(N)
x[<span class="dv">1</span>] &lt;- Xo
for(t in <span class="dv">1</span>:(N<span class="dv">-1</span>))
  x[t<span class="dv">+1</span>] = <span class="kw">z_g</span>() * <span class="kw">f</span>(x[t], <span class="dt">h=</span><span class="dv">0</span>, <span class="dt">p=</span>p)
<span class="kw">qplot</span>(<span class="dv">1</span>:N, x)</code></pre>
<figure>
<img src="http://farm9.staticflickr.com/8279/8962756154_f2a4fa4257_o.png" />
</figure>
<h2 id="compute-the-posterior-after-marginalizing-over-r-and-sigma-parameters">Compute the posterior after marginalizing over <span class="math">\(r\)</span> and <span class="math">\(\sigma\)</span> parameters:</h2>
<p><span class="math">\[P(\beta | X) \]</span></p>
<pre class="sourceCode r"><code class="sourceCode r">Mt &lt;- function(t, beta) <span class="kw">log</span>(x[t<span class="dv">+1</span>]) - <span class="kw">log</span>(x[t]) + beta * x[t]
beta_grid = <span class="kw">seq</span>(<span class="fl">1e-5</span>, <span class="dv">2</span>, <span class="dt">by=</span><span class="fl">1e-3</span>)

P_B.X &lt;- <span class="kw">sapply</span>(beta_grid, function(beta){
  Mt_vec = <span class="kw">sapply</span>(<span class="dv">1</span>:(N<span class="dv">-1</span>), Mt, beta)
  sum_of_squares &lt;- <span class="kw">sum</span>(Mt_vec^<span class="dv">2</span>)
  square_of_sums &lt;- <span class="kw">sum</span>(Mt_vec)^<span class="dv">2</span>
  <span class="fl">0.5</span> ^ (N/<span class="dv">2-1</span>) * (sum_of_squares - square_of_sums/(N<span class="dv">-1</span>)) ^ (N/<span class="dv">2-1</span>) / <span class="kw">gamma</span>(N/<span class="dv">2-1</span>)
  })

<span class="kw">qplot</span>(beta_grid, -<span class="kw">log</span>(P_B.X))</code></pre>
<figure>
<img src="http://farm4.staticflickr.com/3800/8962756744_a8e8471f32_o.png" />
</figure>
<p>Posterior mode is at:</p>
<pre class="sourceCode r"><code class="sourceCode r">beta_grid[<span class="kw">which.min</span>(P_B.X)]</code></pre>
<pre><code>[1] 0.09801</code></pre>
<p>Estimating the Myers model on this data:</p>
<p><span class="math">\[X_{t+1} = Z_t \frac{r X_t^{\theta}}{1 + X_t^{\theta} / K}\]</span></p>
<p>With <span class="math">\(Z_t\)</span> lognormal, unit mean, std <span class="math">\(\sigma\)</span>.</p>
<p>Marginal distribution over the remaining parameters is a 2D grid:</p>
<pre class="sourceCode r"><code class="sourceCode r">Mt &lt;- function(t, theta, K) <span class="kw">log</span>(x[t<span class="dv">+1</span>]) - theta * <span class="kw">log</span>(x[t]) + <span class="kw">log</span>(<span class="dv">1</span> + x[t] ^ theta / K) 
theta_grid = <span class="kw">seq</span>(<span class="fl">1e-5</span>, <span class="dv">5</span>, <span class="dt">length=</span><span class="dv">100</span>)
K_grid = <span class="kw">seq</span>(<span class="fl">1e-5</span>, <span class="dv">30</span>, <span class="dt">length=</span><span class="dv">100</span>)

prob &lt;- function(theta, K){
  Mt_vec = <span class="kw">sapply</span>(<span class="dv">1</span>:(N<span class="dv">-1</span>), Mt, theta, K)
  sum_of_squares &lt;- <span class="kw">sum</span>(Mt_vec^<span class="dv">2</span>)
  square_of_sums &lt;- <span class="kw">sum</span>(Mt_vec)^<span class="dv">2</span>
  <span class="fl">0.5</span> ^ (N/<span class="dv">2-1</span>) * (sum_of_squares - square_of_sums/(N<span class="dv">-1</span>)) ^ (N/<span class="dv">2-1</span>) / <span class="kw">gamma</span>(N/<span class="dv">2-1</span>)
}



P_theta_K.X &lt;- <span class="kw">sapply</span>(theta_grid, function(theta)
                <span class="kw">sapply</span>(K_grid, function(k) <span class="kw">prob</span>(theta, k)))


<span class="kw">require</span>(reshape2)</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">df = <span class="kw">melt</span>(P_theta_K.X)
<span class="kw">names</span>(df) = <span class="kw">c</span>(<span class="st">&quot;theta&quot;</span>, <span class="st">&quot;K&quot;</span>, <span class="st">&quot;lik&quot;</span>)
<span class="kw">ggplot</span>(df, <span class="kw">aes</span>(theta_grid[theta], K_grid[K], <span class="dt">z=</span>-<span class="kw">log</span>(lik))) + <span class="kw">stat_contour</span>(<span class="kw">aes</span>(<span class="dt">color=</span>..level..), <span class="dt">binwidth=</span><span class="dv">3</span>)</code></pre>
<figure>
<img src="http://farm3.staticflickr.com/2806/8961561559_66a72a0ecc_o.png" />
</figure>
 
<!-- not that raw_content depends on custom generator, 
     see _plugins/jekyll-labnotebook-plugins/raw_content --> 
</article> 
<p> <a href="/2013/06/05/semi-analytic-posteriors.html"> <em>Read more</em></a> </p>
<br />
<br />


        </div>
      
        <div class="span3">
          <header><h4><a href="/2013/06/03/DOI-citable.html">DOI != citable</a></h4></header>
<p><span></span></p>
<p style="font-style:italic"> 03 Jun 2013</p>

<p style="font-style:italic"> pageviews: 321 </p>

<article>
<div class="excerpt">
<p>I feel I see this kind of comment almost daily:</p>
<blockquote class="twitter-tweet" data-partner="tweetdeck"><p>
Is there a way to obtain DOI for a <a href="https://twitter.com/github">@github</a> repository? (for citing <a href="https://twitter.com/search?q=%23opensource&amp;src=hash">#opensource</a> software packages, similar to <a href="https://twitter.com/figshare">@figshare</a> objects) <a href="https://twitter.com/search?q=%23git&amp;src=hash">#git</a>
</p>
— Ahmed Moustafa (@AhmedMoustafa) <a href="https://twitter.com/AhmedMoustafa/statuses/339727912896954369">May 29, 2013</a>
</blockquote>
<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script>

<p>Again and again, researchers suggest that DOI to makes something “citable”. And this <a href="https://twitter.com/cboettig/status/337986074624282624">frustrates me</a>.</p>
<p>Don’t get me wrong. I love DOIs, and I love CrossRef. And I bang on the table when I have some old journal article that doesn’t yet have a DOI. I use DOIs every day in many ways. I use CrossRef’s APIs all the time to draw in metadata for citations in my notebook (through my <a href="http://github.com/cboettig/knitcitations">knitcitations</a> package), and to import metadata into my reference manager, Mendeley. I’ve written my own implementations in R and ruby, and keep an eye on their exciting new tools on the <a href="https://github.com/crossref">Crossref Github page</a>. I wrote to bibsonomy when I realized they were not using the CrossRef API to look up metadata by DOIs, and they have now implemented this feature. I use DOIs to look up papers I’ve come across, and to share content I am reading. (Crossref’s <a href="http://shortdoi.org/">DOI shortener</a> is great for this). I even use DOI-based links to <a href="http://carlboettiger.info/2013/02/22/semantic-citations-for-the-notebook-and-knitr.html">embed semantic information</a> into links and citations of articles.</p>
<p>But I still have no idea what researchers mean when they suggest that this makes something <em>citable</em>.</p>
<h3 id="some-background-on-dois">Some background on DOIs</h3>
<p>At its heart, a DOI is a very simple concept. It is a “permanent identifier”. All this means is that is is really just a URL redirect. Type http://dx.doi.org/mnn into any browser and get redirected to where the article actually lives. Why does that make it permanent? Because if the journal decides to change their URL structure, the DOI’s redirect can just be mapped to the new address and voila, it still works. That is, a DOI is simply a tool to fight <a href="https://en.wikipedia.org/wiki/Link_rot">link-rot</a>.</p>
<p>So you might ask, why does the ability to remap the address have anything to do with being “permanent?” It doesn’t, really. The permanence comes not so much from the technology as from the social contract that goes with it. As CrossRef’s <a href="http://blogs.plos.org/mfenner/2009/02/17/interview_with_geoffrey_bilder/">Geoffery Bilder eloquently explains</a>, a publisher can only receive DOIs if they promise to keep these redirects up-to-date. A publisher who fails to maintain this responsibility would presumably lose their right to receive DOIs. A brilliant, simple, social incentive.</p>
<p>This still does not guarantee permanence – e.g. what would happen to the content if the publisher disappears. That problem is not addressed by the DOI technology itself, but by a robust backup archiving solution, such as <a href="http://clockss.org">CLOCKSS</a>, which provides a geo-politically distributed network of backup copies for many journals. Again the social contract comes into play – presumably CrossRef would not provide a publisher with DOIs if they did not have such a robust archival solution in place.</p>
<p>So far we have seen two crucial functions of the DOI – as a permanent identifier that can be used to reach the content despite link rot, and as an incentive to maintain good archival backups of the content and the links to it.</p>
<h3 id="what-do-we-mean-by-citations-anyway">What do we mean by citations, anyway?</h3>
<p>So what does this have to do with being citable? Obviously these are nice properties to have for things we cite – but they are by no means a requirement. (As <a href="https://twitter.com/noamross/status/337987521243918337">Noam Ross observes</a>, try finding a permanent identifier for “Personal Communication”). Books, reports, and other grey literature frequently appear in citations, as do links to websites. MLA even has guidelines on the proper format to <a href="http://www.mla.org/style/handbook_faq/cite_a_tweet">cite a tweet</a> (which, incidentally, come closer to having a permanent identifier and an archival strategy than most other things in this list). So what do we mean by citable anyway?</p>
<p>But what about the reference list? While a publisher may be just fine including some link to your software, is it really cited if it isn’t in the reference list? Journals restrict what appears in the reference list because these references are indexed by the infamous citation counters like Thompson-Reuters. (A frequent complaint is that many journals do not similarly index citations appearing in the reference list of the supplementary materials, making it difficult or impossible to give appropriate attribution to large numbers of data providers, for instance). Does having a DOI address this problem?</p>
<h4 id="citation-counts-in-dois">Citation counts in DOIs</h4>
<p>Counting citations depends on who is counting them. The most well-known is Thompson-Reuters, which has their own process for deciding what gets counted (based on publisher), so no guarantee there. Meanwhile Google Scholar counts anything meeting it’s <a href="http://carlboettiger.info/2012/11/23/citing-lab-notebook-entries.html">indexing requirements &amp; arbitrary selection</a>. I have recently learned that CrossRef just launched it’s own <a href="https://github.com/articlemetrics/alm/wiki/Crossref">internal citation counting</a>, which is available from the CrossRef metadata (totals only for the public, publishers can resolve which articles did the citing…). However, most proposals to make some alternative research product “citable” by giving it a DOI use DataCite DOIs (e.g. fig<strong>share</strong>, PeerJ Preprints), which lag behind in this feature. Moving the control of citation data beyond the grasp of particular publishing companies like TR is undoubtedly an important step forward. The <a href="http://www.jisc.ac.uk/whatwedo/programmes/inf11/jiscexpo/jiscopencitation.aspx">Open Citation Project</a> is a more comprehensive, if very young, move in this direct. (Hat tip to Martin Fenner for explaining CrossRef citations to me).</p>
<h3 id="additional-metadata">Additional Metadata</h3>
<p>In addition to resolving links, DOI providers also serve a rich collection of metadata about the publication that can be <a href="http://www.crosscite.org/cn/">queried by DOI</a> or by <a href="https://github.com/CrossRef/cr-search">other elements</a> like author and title. Rich semantic formats and disambiguation of author names by connections to ORCID IDs are among the many advantages of this. Because many of these tools are publicly accessible by through their APIs, it is easy for other developers to build services upon them.</p>
<h2 id="conclusions">Conclusions</h2>
<p>While DOI providers have done an excellent job in ensuring persistent URLs, archived content, and valuable metadata, these things are largely the product of the social contract between publisher and the DOI provider. It is not possible for an author or organization to simply “get DOIs” for all their content. But it is not the only way to provide these features, either. While I understand the value in providing a simple and reliable way to encapsulate each of these concepts as “has a DOI,” it also appears to put these features beyond the reach of individual researchers. If issues of persistent URLs, archived content, and rich metadata tools are always reduced to “has a DOI,” publishers become the only path to achieve these ends. On the contrary, a rich collection of tools is available to researchers.</p>
<p>So what do we mean when we say a DOI makes something ‘citable?’ If this is shorthand for the properties we would want in something citable: persistent identifier, archival content, machine-readable metadata, than we should start to recognize other things that share these features. Further innovation requires valuing the features the DOI provides, not simply a “brand name” researchers recognize.</p>
<h2 id="alternative-tools">Alternative tools</h2>
<p>In a <a href="http://purl.org/cboettig/2013/05/31/notebook-features-digital-archiving">recent post</a> in a series on technical features of my open notebook, I discuss some of the tools available to address these challenges. In particular:</p>
<ul>
<li>The use of <a href="http://en.wikipedia.org/wiki/Persistent_uniform_resource_locator">PURLs</a> for persistent identifiers</li>
<li>Git for archival redundancy</li>
<li><a href="http://greycite.knowledgeblog.org">Greycite</a> for metadata extraction</li>
</ul>
<p>Of course, if you ever need a DOI for a research product, there is always <a href="http://figshare.com">figshare</a>.</p>
 
<!-- not that raw_content depends on custom generator, 
     see _plugins/jekyll-labnotebook-plugins/raw_content --> 
</article> 
<p> <a href="/2013/06/03/DOI-citable.html"> <em>Read more</em></a> </p>
<br />
<br />


        </div>
      
    </div>

    <div class="row">
      
        <div class="span3">
          <header><h4><a href="/2013/06/03/ADMB-basic-example.html">Admb Basic Example</a></h4></header>
<p><span></span></p>
<p style="font-style:italic"> 03 Jun 2013</p>

<p style="font-style:italic"> pageviews: 7 </p>

<article>
<div class="excerpt">
<p>After a few <a href="https://github.com/cboettig/nonparametric-bayes/commits/b4576cfc0b5a0c87701348976875c8657f0fd048/inst/examples/admb-example.md">iterations</a> I have a working minimal example (below). Hoping that ADMB is a bit more robust than vanilla <code>optim</code> out of R as I loop over data sets for the sensitivity analysis (<a href="https://github.com/cboettig/nonparametric-bayes/issues/32">#32</a>). Does not seem to hold in simple example here, not sure why.</p>
<ul>
<li>These notes correspond to script <a href="https://github.com/cboettig/nonparametric-bayes/blob/84a1025854987ef659b4ef17e172933d72547f6d/inst/examples/admb-example.md">84a102/admb-example.md</a></li>
</ul>
<h1 id="learning-admb">Learning ADMB</h1>
<p>Plotting and knitr options, (can generally be ignored)</p>
<h3 id="model-and-parameters">Model and parameters</h3>
<pre class="sourceCode r"><code class="sourceCode r">f &lt;- function(x,h,p)  x * <span class="kw">exp</span>(p[<span class="dv">1</span>] * (<span class="dv">1</span> - x / p[<span class="dv">2</span>]) * (x - p[<span class="dv">3</span>]) / p[<span class="dv">2</span>] ) 
p &lt;- <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">10</span>, <span class="dv">5</span>)
K &lt;- <span class="dv">10</span>  <span class="co"># approx, a li&#39;l&#39; less</span>
Xo &lt;- <span class="dv">6</span> <span class="co"># approx, a li&#39;l&#39; less</span></code></pre>
<p>Various parameters defining noise dynamics, grid, and policy costs.</p>
<pre class="sourceCode r"><code class="sourceCode r">sigma_g &lt;- <span class="fl">0.1</span>
z_g &lt;- function() <span class="kw">rlnorm</span>(<span class="dv">1</span>,<span class="dv">0</span>, sigma_g)
x_grid &lt;- <span class="kw">seq</span>(<span class="dv">0</span>, <span class="fl">1.5</span> * K, <span class="dt">length=</span><span class="dv">50</span>)
Tobs &lt;- <span class="dv">40</span>
<span class="kw">set.seed</span>(<span class="dv">123</span>)</code></pre>
<h3 id="sample-data">Sample Data</h3>
<pre class="sourceCode r"><code class="sourceCode r">x &lt;- <span class="kw">numeric</span>(Tobs)
x[<span class="dv">1</span>] &lt;- Xo
for(t in <span class="dv">1</span>:(Tobs<span class="dv">-1</span>))
  x[t<span class="dv">+1</span>] = <span class="kw">z_g</span>() * <span class="kw">f</span>(x[t], <span class="dt">h=</span><span class="dv">0</span>, <span class="dt">p=</span>p)
<span class="kw">qplot</span>(<span class="dv">1</span>:Tobs, x)</code></pre>
<figure>
<img src="http://farm3.staticflickr.com/2807/8956942302_0d7d47ea49_o.png" alt="plot of chunk obs" /><figcaption>plot of chunk obs</figcaption>
</figure>
<h2 id="maximum-likelihood-by-hand">Maximum Likelihood “by hand”</h2>
<pre class="sourceCode r"><code class="sourceCode r">STABLIZE = <span class="fl">1e-10</span>
n = <span class="kw">length</span>(x)
mloglik &lt;- function(pars){ 
  r = pars[<span class="dv">1</span>]; k = pars[<span class="dv">2</span>]; c = pars[<span class="dv">3</span>]; s = pars[<span class="dv">4</span>];
  mu = (x+STABLIZE) * <span class="kw">exp</span>( r * (<span class="dv">1</span> - x / (k+STABLIZE)) * (x - c) / (k + STABLIZE));
  mu = <span class="kw">pmin</span>(<span class="fl">1e100</span>, mu) <span class="co"># avoid infinite values </span>
  f = <span class="fl">0.5</span> * n * <span class="kw">log</span>(<span class="dv">2</span> * pi) + n * <span class="kw">log</span>(s + STABLIZE) + <span class="fl">0.5</span> * <span class="kw">sum</span>(x - mu + STABLIZE)^<span class="dv">2</span>/ (s + STABLIZE)^<span class="dv">2</span>;

  f
  }</code></pre>
<p>Starting from the true values we mostly just shrink the noise parameter:</p>
<pre class="sourceCode r"><code class="sourceCode r">init &lt;- <span class="kw">c</span>(p, sigma_g)
<span class="kw">mloglik</span>(init) <span class="co">#true minus loglik</span></code></pre>
<pre><code>[1] -35.72</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">o &lt;- <span class="kw">optim</span>(init, mloglik, <span class="dt">method=</span><span class="st">&quot;L&quot;</span>, <span class="dt">lower=</span><span class="fl">1e-5</span>, <span class="dt">upper=</span><span class="fl">1e5</span>)
o$value</code></pre>
<pre><code>[1] -247.6</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">o$par</code></pre>
<pre><code>[1] 0.9967297 9.9813554 5.1742699 0.0008183</code></pre>
<p>While starting from arbitrary values we still find the optim.</p>
<pre class="sourceCode r"><code class="sourceCode r">init &lt;- <span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>)  
init &lt;- <span class="kw">c</span>(p, sigma_g)
<span class="kw">mloglik</span>(init) <span class="co">#true minus loglik</span></code></pre>
<pre><code>[1] -35.72</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">o &lt;- <span class="kw">optim</span>(init, mloglik, <span class="dt">method=</span><span class="st">&quot;L&quot;</span>, <span class="dt">lower=</span><span class="fl">1e-5</span>, <span class="dt">upper=</span><span class="fl">1e5</span>)
o$value</code></pre>
<pre><code>[1] -247.6</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">o$par</code></pre>
<pre><code>[1] 0.9967297 9.9813554 5.1742699 0.0008183</code></pre>
<p>Okay, now lets try admb. We use R2admb which is just a convenient way to write our data and parameters into an admb file.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># install_github(&quot;R2admb&quot;, &quot;bbolker&quot;, subdir=&quot;R2admb&quot;) # dev version</span>
<span class="kw">library</span>(R2admb)</code></pre>
<h2 id="admb-definition">ADMB definition</h2>
<p>We still need to define the model using ADMB notation in the procedure section. This is mostly like R or C++, with the exception of special functions like <code>square</code> in place of <code>^2</code>, <code>norm2</code> for the sum of squares, and <code>elem_prod</code> istead of <code>*</code> for the element-wise product of two arrays. The constant <code>pi</code> is given as <code>M_PI</code>, as typical of C/C++ libraries. Where these other functions are defined I’m not sure, but some useful guides to <a href="http://fish.washington.edu/research/MPAM/resources/ADMB_Minte-Vera.pdf">ADMB vector/matrix operations</a> or an (undefined) list of <a href="http://www.admb-project.org/developers/contribute-documentation/functions/keywords.txt/view">keywords</a>…</p>
<p>The equivalent model</p>
<pre class="sourceCode r"><code class="sourceCode r">model &lt;- 
<span class="kw">paste</span>(<span class="st">&quot;</span>
<span class="st">PARAMETER_SECTION</span>
<span class="st">  vector mu(1,n) // per capita mort prob</span>
<span class="st">      </span>
<span class="st">PROCEDURE_SECTION</span>
<span class="st">  mu = log(x) + r * elem_prod((1 - x / k), (x - c) / k);</span>
<span class="st">  f = 0.5 * n * log(2 * M_PI) + n * log(s) + 0.5 * norm2(x - exp(mu)) / square(s);</span>
<span class="st">&quot;</span>)
<span class="kw">writeLines</span>(model, <span class="st">&quot;model.tpl&quot;</span>)</code></pre>
<p>Without explicit handling of the overflow errors, ADMB does not give us reliable estimates with arbitrary starting conditions</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">setup_admb</span>(<span class="st">&quot;/var/admb&quot;</span>)</code></pre>
<pre><code>[1] &quot;/var/admb&quot;</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">
df &lt;- <span class="kw">data.frame</span>(<span class="dt">x=</span>x)
params &lt;- <span class="kw">list</span>(<span class="dt">r =</span> <span class="dv">1</span>, <span class="dt">k =</span> <span class="dv">1</span>, <span class="dt">c =</span> <span class="dv">1</span>, <span class="dt">s =</span> <span class="dv">1</span>) ## starting parameters
bounds &lt;- <span class="kw">list</span>(<span class="dt">r =</span> <span class="kw">c</span>(<span class="fl">1e-10</span>, <span class="fl">1e3</span>), <span class="dt">k=</span><span class="kw">c</span>(<span class="fl">1e-10</span>, <span class="fl">1e3</span>), <span class="dt">c=</span><span class="kw">c</span>(<span class="fl">1e-10</span>, <span class="fl">1e3</span>), <span class="dt">s =</span> <span class="kw">c</span>(<span class="fl">1e-5</span>,<span class="fl">1e3</span>)) ## bounds
dat &lt;- <span class="kw">c</span>(<span class="kw">list</span>(<span class="dt">n =</span> <span class="kw">nrow</span>(df)), df)
m1 &lt;- <span class="kw">do_admb</span>(<span class="st">&quot;model&quot;</span>,
              <span class="dt">data =</span> dat,
              <span class="dt">params =</span> params,
              <span class="dt">bounds =</span> bounds,
              <span class="dt">run.opts =</span> <span class="kw">run.control</span>(<span class="dt">checkparam=</span><span class="st">&quot;write&quot;</span>,
                                     <span class="dt">checkdata=</span><span class="st">&quot;write&quot;</span>, <span class="dt">clean=</span><span class="ot">FALSE</span>))
m1</code></pre>
<pre><code>Model file: model_gen 
Negative log-likelihood: 146.5 
Coefficients:
     r      k      c      s 
0.9992 1.0023 1.0004 9.4369 </code></pre>
<p>But does fine with good starting values. Hmm.. thought that was supposed to be the other way around…</p>
<pre class="sourceCode r"><code class="sourceCode r">params &lt;- <span class="kw">list</span>(<span class="dt">r =</span> <span class="dv">1</span>, <span class="dt">k =</span> <span class="dv">10</span>, <span class="dt">c =</span> <span class="dv">5</span>, <span class="dt">s =</span> .<span class="dv">1</span>) ## starting parameters

m1 &lt;- <span class="kw">do_admb</span>(<span class="st">&quot;model&quot;</span>,
              <span class="dt">data =</span> dat,
              <span class="dt">params =</span> params,
              <span class="dt">bounds =</span> bounds,
              <span class="dt">run.opts =</span> <span class="kw">run.control</span>(<span class="dt">checkparam=</span><span class="st">&quot;write&quot;</span>,
                                     <span class="dt">checkdata=</span><span class="st">&quot;write&quot;</span>))</code></pre>
<pre><code>Warning: running command &#39;./model_gen &gt; model_gen.out&#39; had status 1</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">m1</code></pre>
<pre><code>Model file: model_gen 
Negative log-likelihood: -423.8 
Coefficients:
        r         k         c         s 
2.025e-10 9.498e+00 1.051e+01 1.000e-05 </code></pre>
<p>Which finds a better optim (though substantailly overfit in reality)</p>
<p>Hans suggests adding an error term in the function definitions rather than in limiting the bounds or log transforming the variables:</p>
<blockquote>
<p>The most common plase where this goes wrong is 1/0, log(0), sqrt(0), pow(0,1) etc. Your suggestion is OK, but usually I prefer to put in log(1e-10+my_expression), sqrt(1e-10+my_expression), pow(1e-10+my_expression,1)</p>
</blockquote>
<h2 id="misc">Misc</h2>
<ul>
<li><p>Finished off posts regarding DOIs and digital archiving. A shorter version appears in my answer to <a href="http://opendata.stackexchange.com/questions/694/preservation-of-blog-posts-articles-and-essays/719#719">opendata.stackexchange</a> on blog archiving.</p></li>
<li><p>Interesting discussion on using PURL redirects with SHA hash to link to repositories. For instance, the commit matching our arXiv submission of the ews-review paper is found at <a href="http://purl.org/cboettig/ews-review/33dfb58e24ceb5861dad7cf756cffe2c5d66a655">cboettig/ews-review/33dfb58e24ceb5861dad7cf756cffe2c5d66a655</a>. If the hash shown in the PURL doesn’t match the one at the repository then we know something has gone wrong, since it is impossible to change the contents without changing the hash. This gives us a version-stable identifier that can always be remapped to this commit, even if Github should disappear. Of course nothing guarentees that the PURL maintainer / package author does this updating, but in principle the system is more robust than simply linking to Github.</p></li>
<li><p>In other news, I should add some <a href="https://github.com/cboettig/labnotebook/issues/94">automatic link checking, #94</a> to the notebook.</p></li>
</ul>
 
<!-- not that raw_content depends on custom generator, 
     see _plugins/jekyll-labnotebook-plugins/raw_content --> 
</article> 
<p> <a href="/2013/06/03/ADMB-basic-example.html"> <em>Read more</em></a> </p>
<br />
<br />


        </div>
      
        <div class="span3">
          <header><h4><a href="/2013/05/31/notebook-features-digital-archiving.html">Notebook features: digital archiving</a></h4></header>
<p><span></span></p>
<p style="font-style:italic"> 31 May 2013</p>

<p style="font-style:italic"> pageviews: 12 </p>

<article>
<div class="excerpt">
<p>Note: this entry is part of a <a href="http://carlboettiger.info/2013/04/26/notebook-features-introduction.html">series of posts</a> which explain some of the technical features of my lab notebook.</p>
<p>Archival preservation of digital scholarly content is an important challenge throughout the research community. As the notebook is the permanent record of my regular scholarly endeavors, this provides the opportunity to experiment with tools and techniques for digital archiving while also better preserving the notebook. In the experimental spirit that drives all my exploration here, I am testing several ways to accomplish this. In so doing, I learn which approaches are easiest to implement, to use, and gather feedback from, while also hedging my bets in the event that any given strategy should fail.</p>
<p>Archiving digital content involves two fundamental challenges that can be difficult to satisfy simultaneously: providing a robust backup copy of the <em>content</em>, and providing a consistent location (such as a URL) where the content can be retrieved.</p>
<h2 id="a-custom-domain">A custom domain</h2>
<p>The simplest archival measure employed in the notebook comes from hosting through my own domain, <a href="http://carlboettiger.info">carlboettiger.info</a> rather than an external server. By controlling the domain structure myself, I am not tied to a University server that can be altered by an IT department without my knowledge, thereby breaking my links. When I choose to move platforms, as I did in migrating from <a href="/2012/09/19/migrating-from-wordpress-to-jekyll.html">Wordpress to Jekyll</a>, I could ensure that links would be appropriately mapped. This was not the case when I started my open notebook on the OpenWetWare platform, since links are all mapped to the <a href="http://openwetware.org">openwetware.org</a> domain which I obviously cannot control, even though I could at least migrate my content. <a href="https://github.com/cboettig/labnotebook/blob/8481569132142c850e585a2fc8c12a671527cd4f/_plugins/redirects.rb">HTML redirects</a> make sure links still resolve when I change structure (e.g. <a href="/archives/211">carlboettiger.info/archives/211</a>). I don’t have to worry about moving my domain when I change institutions, and can seamlessly migrate to a different server or DNS provider to get better rates or uptime performance.</p>
<p>Of course these advantages are also the greatest weaknesses of this approach – they all depend entirely on me. I could make or forget to make any number of changes that could cause this all to break. Time has shown that even the best-intentioned researchers are not the best curators of there own data, and no doubt I am no exception. How can the content and its identifying addresses outlive me or my interest in it?</p>
<h2 id="purls-preserving-identifiers">PURLs: preserving identifiers</h2>
<p><a href="http://purl.org">PURLs</a>, or Persistent Uniform Resource Locators, provide a DOI-like mechanism for addressing the challenge of link-rot. As <a href="http://blogs.plos.org/mfenner/2009/02/17/interview_with_geoffrey_bilder/">Geoffrey Bilder eloquently argues</a>, the technological solution is quite simple, the real challenge lies on the social side of the implementation – a social contract that promises content providers will maintain their identifiers if they want to continue to receive identifiers. Though users must register to be able to create PURLs, PURL does not provide such enforcement.</p>
<p>The PURLs solution is a bit more web-native solution than DOIs, in being more democratic, using a URL structure, and being built upon widely distributed servers and open-source web technology. Not surprisingly, other web-native systems such as most of the major semantic web ontology providers rely on PURLs, e.g. Dublin Core uses <a href="http://purl.org/dc/terms/">purl.org/dc/terms/</a>. The PURL <a href="http://purl.oclc.org/docs/faq.html">FAQ</a> provides a great overview.</p>
<p>Implementing PURLs for the notebook was very straight-forward. After registering as a user at <a href="http://purl.org">purl.org</a> I applied for my own top-level domain: <code>cboettig</code>, which I then mapped to my current domain, <a href="http://carlboettiger.info">carlboettiger.info</a> By enabling partial redirects, each page on my site will also be resolved using this top-level domain followed by my existing page structure. Following my existing structure is not necessary – I could map each page to an arbitrary path in my domain, but would have to enter these somewhat manually. While the partial redirect is simpler to implement, it does require that I maintain the rest of the link structure.</p>
<p>In this way, <a href="http://purl.org/cboettig/lab-notebook.html">purl.org/cboettig/lab-notebook.html</a> now resolves to <a href="http://carlboettiger.info/lab-notebook.html">carlboettiger.info/lab-notebook.html</a>. Likewise, each page in the notebook can be similarly resolved from the purl.org domain instead of my personal carlboettiger.info domain. Should I ever somehow lose control of carlboettiger.info, I could re-assign my PURL to redirect to my new domain URL. This provides DOI-like technology of permanent identifiers for every page in the notebook.</p>
<h2 id="github-preserving-content-and-versions">GitHub: preserving content and versions</h2>
<p>Committing content to an external repository is the recommended way to avoid link-rot from the user errors and website changes that so frequently plague self-archiving of scholarly content. Keeping multiple copies of content in geographically distinct locations is the time-honored approach of digital archiving. Git and GitHub make this easy. Not only does this mean that a backup copy is publicly available and forkable online, but it is also easy to clone copies on each of the machines I work on and rely on git to keep them in sync. Should Github disappear, a little <code>git remote add</code> and everything will be effortlessly deployed with complete history elsewhere.</p>
<p>The notebook has two Github repositories: the “source-code” consisting of plain-text (markdown) content and Jekyll-based templates on <a href="http://github.com/cboettig/labnotebook">labnotebook</a>, and a second for the rendered HTML <a href="http://github.com/cboettig/cboettig.github.com">cboettig.github.com</a> (which also now hosts the website).</p>
<p>While a custom domain and PURLs provide persistent <em>locators</em> for the content, distributed copies on Git help archive the content itself. Should my domain vanish or Github disappear, copies of the content, complete with version history, would remain distributed across various machines with a copy of the repository. Links to Github would break in that process, unless we had remapped all links from the notebook to Github using PURLs.</p>
<h2 id="greycite-programmatic-access-and-indexing-of-metadata">Greycite: Programmatic access and indexing of metadata</h2>
<p>I think of good metadata as the third leg to proper digital archiving, in addition to permanent identifiers and backup of content. We want to be able to point a tool at the permanent identifier / URL of an entry and extract reliable information on the author, time published and last modified, title, author, key words, etc. that might be useful in citing or categorizing the content. Providing this information is really the subject of adding <a href="http://carlboettiger.info/2012/10/23/semantic-markup-examples-for-the-lab-notebook.html">Semantic metadata</a> to the site, and is covered in another entry in this series. Meanwhile, the <a href="http://greycite.knowledgeblog.org">Greycite</a> tool and it’s API are an excellent way to extract this metadata into a variety of useful formats, working much the same way that CrossRef’s tool does using DOIs. Here is an <a href="http://greycite.knowledgeblog.org/?uri=http%3A%2F%2Fpurl.org%2Fcboettig%2F2012%2F10%2F23%2Fsemantic-markup-examples-for-the-lab-notebook.html">example query</a></p>
<figure>
<img src="http://farm6.staticflickr.com/5325/8940923396_fcf4941197.jpg" />
</figure>
<h2 id="robust-archiving-with-figshare"><strong>Robust archiving</strong> with fig<strong>share</strong></h2>
<p>Depositing a copy of the notebook on fig<strong>share</strong> is one of the most robust archival solutions of which I am currently aware. Not so much because it has the coveted DOI solution to the permanent identifier problem but because it has the promise of <a href="http://clocks.org">CLOCKSS</a> archiving, should anything ever happen to fig<strong>share</strong>.</p>
<p>Nevertheless, it raises several challenges. The native home for the content is as rendered HTML at my domain, not as raw HTML on an archive completely unassociated with that domain, difficult to view, and divorced from my usual workflow, unlike my usual publishing source-code to Github and website to my domain. It also raises questions of just what to archive and when. I discuss some of these strengths and challenges as a separate post, <a href="http://purl.org/cboettig/2013/05/31/notebook-features-archiving-with-figshare">archiving the lab notebook on figshare: advantages and challenges</a>.</p>
<h2 id="conclusions">Conclusions</h2>
<p>Digital archiving is a challenging problem that is not completely addressed by any one of these approaches. In the end, robust archiving will be best left in the hands of its experts. Unfortunately, the best examples currently available (such as CLOCKSS, national libraries, etc.) will not archive a researcher’s web page directly. The solutions explored here are not perfect, but they are free and simple to implement. I’d love to hear what others think.</p>
<h3 id="see-also">See also</h3>
<ul>
<li><a href="http://www.digitalpreservation.gov/ndsa/">DigitalPreservation.gov</a></li>
<li><a href="http://internetarchive.org">The Internet Archive</a></li>
</ul>
 
<!-- not that raw_content depends on custom generator, 
     see _plugins/jekyll-labnotebook-plugins/raw_content --> 
</article> 
<p> <a href="/2013/05/31/notebook-features-digital-archiving.html"> <em>Read more</em></a> </p>
<br />
<br />


        </div>
      
        <div class="span3">
          <header><h4><a href="/2013/05/31/notebook-features-archiving-with-figshare.html">Archiving the lab notebook on figshare</a></h4></header>
<p><span>Advantages and challenges</span></p>
<p style="font-style:italic"> 31 May 2013</p>

<p style="font-style:italic"> pageviews: 9 </p>

<article>
<div class="excerpt">
<h2 id="robust-archiving-through-clockss">Robust archiving through CLOCKSS</h2>
<p>One of the most comprehensive approaches I have come across so far uses fig<strong>share</strong>. This offers the most promising avenue for content preservation, but is weakest in managing the URIs and associating them with the original content. All fig<strong>share</strong> content is archived by <a href="http://clockss.org">CLOCKSS</a>, an international library cooperation providing redundant and geopolitically distributed backup of the archives around the world (and used by many academic journals, both subscription based &amp; open access). Should fig<strong>share</strong> vanish from the face of the planet, it will trigger the release of all of its content to resolve through the CLOCKSS servers, with the same appearance and resolving at the same URLs as the original figshare content. Presumably the DOIs provided to figshare content will also continue to resolve there.</p>
<h2 id="challenges">Challenges</h2>
<p>It would certainly be preferable to have the notebook archived by CLOCKSS directly, since the association between the original online content at carlboettiger.info is lost in archiving the entries on figshare. More problematically, the content as archived on fig<strong>share</strong> is not recognized by search engines, etc., as a separate HTML pages to index, but merely as a bundle of attached text files. On the upside, the content becomes part of the global scientific datasets preserved and indexed by fig<strong>share</strong> with appropriate metadata, etc., increasing the chances for discovery through that venue. Also, fig<strong>share</strong> provides a convenient API that can help automate deposition.</p>
<h3 id="what-content-what-format">What content? What format?</h3>
<p>Deciding just what to archive in the fig<strong>share</strong> database is also less straight forward than it may seem. I have gone through a few iterations:</p>
<ol type="1">
<li>Archiving the markdown.<br /></li>
<li>Archiving external images with Data URIs.<br /></li>
<li>Archiving the HTML versions of pages alone</li>
<li>Archiving the whole git repository, <code>_site</code> HTML included (?)</li>
</ol>
<p>I began by archiving the markdown files that I write to create each entry. These are plain-text files that can be easily read in any text editor, even if the conventions for rendering them as HTML are lost. Like HTML, figures are linked to external files, and are thus not captured by this solution. To work around this, I adopted the trick of using <a href="http://carlboettiger.info/2013/01/24/Data-URIs-for-image-archives.html">Data URIs</a> to embed images. This places a binary encoding of the image in the text itself, which can be rendered by almost any browser as the appropriate image. While this keeps the content together, the long data URI strings are rather out-of-place inside a plain text document. Further, the markdown loses all of the valuable semantics that are automatically added to each page when Jekyll renders them to HTML. As Phil Lord argues, if there’s any format that future archivists can read successfully – it will be HTML. Consequently I’ve settled on archiving the HTML versions of each notebook entry, with images embedded as Data URIs. Each HTML file contains rich metadata in the header, sidebar, and footer, that give more information about the content and its context in the notebook (relative path, categories and tags, timestamps and SHA hashes, etc). I have archived these entries in annual chunks following the year/month/day directory structure already employed on the site.</p>
<h3 id="how-about-site-assets">How about site assets?</h3>
<p>There is still additional external content used to render the site – CSS and javascript files – that are not captured in this approach. Though entries actually render <a href="http://stackoverflow.com/questions/14046738">just fine without the css</a>, it would certainly be possible to include this material in the archive (though some Javascript comes from external CDNs). This does make for a bit larger and more cluttered archive, and more to the point is a rather crude solution to a problem already solved by Internet archiving programs such as CLOCKSS or internetarchive.org.</p>
<h3 id="versioning">Versioning?</h3>
<p>Lastly there is the concern of preserving the version history of entries. Though fig<strong>share</strong> provides versioning of its content, this doesn’t capture finer resolution of individual page changes available through the Github repository. At the expense of creating an ever more cumbersome archival object, one could include the <code>.git</code> history, either for the HTML rendered version (which lives at <a href="https://github.com/cboettig/cboettig.github.com/">cboettig.github.com</a>) or the source files used to create it (<a href="https://github.com/cboettig/labnotebook">labnotebook</a>).</p>
<h3 id="connecting-to-the-original-instances">Connecting to the original instances?</h3>
<p>Of course this fails to address the preservation of externally linked content. The most frequent outbound links point to other publications through, usually their DOIs, which we hope will take care of themselves. The most important externally linked content in the notebook entries are the links to scripts, functions, and manuscripts in the various project repositories on Github. The simplest solution is to embed the most important scripts in the notebook entries themselves. Archiving the project repositories is an additional challenge, but if a user can recover a copy of the project repository (along with it’s <code>.git</code> history) then it would be possible to identify the linked file using the SHA hash from these links (by matching it against the SHAs in the log). See my entry on <a href="/2013/05/03/notebook-features-hashes-providing-an-immutable-and-verifiable-research-record.html">SHA hashes</a> for more on this topic.</p>
<h2 id="links-to-the-archives">Links to the archives</h2>
<p>Current and previous archives of my lab notebook can be found on figshare by year. Older versions of these archives have taken a different approach, including just archiving the markdown files. The links use the DOI and point to the most recent version. (At this time linking to explicit versions with FigShare’s DataCite DOI links doesn’t appear to be working)</p>
<ul>
<li><a href="http://dx.doi.org/10.6084/m9.figshare.96916">Lab Notebook, 2010</a></li>
<li><a href="http://dx.doi.org/10.6084/m9.figshare.96919">Lab Notebook, 2011</a></li>
<li><a href="http://dx.doi.org/10.6084/m9.figshare.106620">Lab Notebook, 2012</a></li>
</ul>
 
<!-- not that raw_content depends on custom generator, 
     see _plugins/jekyll-labnotebook-plugins/raw_content --> 
</article> 
<p> <a href="/2013/05/31/notebook-features-archiving-with-figshare.html"> <em>Read more</em></a> </p>
<br />
<br />


        </div>
      
    </div>

    <div class="row">
      
        <div class="span3">
          <header><h4><a href="/2013/05/29/notes.html">Notes</a></h4></header>
<p><span></span></p>
<p style="font-style:italic"> 29 May 2013</p>

<p style="font-style:italic"> pageviews: 7 </p>

<article>
<div class="excerpt">
<h2 id="nonparametric-bayes">nonparametric-bayes</h2>
<p>Not getting good convergence from jags models with uniformative priors without observation noise and arbitary starting postions. See examples:</p>
<ul>
<li>fixed myers_jags run, loads knitr_defaults <a href="https://github.com/cboettig/nonparametric-bayes/commit/783ed119848772dcc3ee26d9e1dbe10b1e1afbbc">11:18 am 2013/05/29</a></li>
<li>trouble with MCMC convergence for process-noise-only: Now with longer runs and better posterior estimator. Set for run on zero. <a href="https://github.com/cboettig/nonparametric-bayes/commit/5e3f3f5b00dbd6085e6cddee03ad03151a759b22">11:01 am 2013/05/29</a></li>
</ul>
<p>Also a few updates:</p>
<ul>
<li>slides for adp section of group meeting <a href="https://github.com/cboettig/nonparametric-bayes/commit/094b44822abb47b1145f0a0bb0ae2c8364bbee25">11:44 am 2013/05/29</a></li>
<li>updated adp-intro <a href="https://github.com/cboettig/nonparametric-bayes/commit/4eb6a30441f28e9cbe87690d9e098b0e068cc395">11:43 am 2013/05/29</a></li>
</ul>
<h2 id="prosecutor">prosecutor</h2>
<ul>
<li>Combine comment code into single file for both models: <a href="https://github.com/cboettig/earlywarning/blob/resubmission/inst/examples/comment_reply.Rmd">comment_reply.Rmd</a></li>
<li>Comment resubmitted. (repository tag: <a href="https://github.com/cboettig/earlywarning/blob/resubmission"><code>resubmission</code></a>)</li>
<li>Ooh: tags provide a convenient way to make readable version-stable links (e.g. as opposed to linking by the hash.)</li>
</ul>
<h2 id="handling-scripts">handling scripts</h2>
<p>Separated out my common knitr settings that usually take up space in my first code chunk.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># My preferred defaults (may be changed in individual chunks)</span>
opts_chunk$<span class="kw">set</span>(<span class="dt">tidy=</span><span class="ot">FALSE</span>, <span class="dt">warning=</span><span class="ot">FALSE</span>, <span class="dt">message=</span><span class="ot">FALSE</span>, <span class="dt">cache=</span><span class="ot">TRUE</span>, 
               <span class="dt">comment=</span><span class="ot">NA</span>, <span class="dt">verbose=</span><span class="ot">TRUE</span>, <span class="dt">fig.width=</span><span class="dv">6</span>, <span class="dt">fig.height=</span><span class="dv">4</span>)
 
<span class="co"># Name the cache path and fig.path based on filename...</span>
 opts_chunk$<span class="kw">set</span>(<span class="dt">fig.path =</span> <span class="kw">paste</span>(<span class="st">&quot;figure/&quot;</span>,
                                 <span class="kw">gsub</span>(<span class="st">&quot;.Rmd&quot;</span>, <span class="st">&quot;&quot;</span>, knitr:::knit_concord$<span class="kw">get</span>(<span class="st">&#39;infile&#39;</span>)),
                                 <span class="st">&quot;-&quot;</span>, <span class="dt">sep=</span><span class="st">&quot;&quot;</span>),
                                 <span class="dt">cache.path =</span> <span class="kw">paste</span>(<span class="kw">gsub</span>(<span class="st">&quot;.Rmd&quot;</span>, <span class="st">&quot;&quot;</span>, knitr:::knit_concord$<span class="kw">get</span>(<span class="st">&#39;infile&#39;</span>) ), 
                                 <span class="st">&quot;/&quot;</span>, <span class="dt">sep=</span><span class="st">&quot;&quot;</span>))
  
<span class="co"># Set plotting to bw plot default, but with transparent background elements.  </span>
<span class="co"># Note transparency requires the panel.background, plot.background, and device background all be set!</span>
  <span class="kw">library</span>(ggplot2) 
  <span class="kw">theme_set</span>(<span class="kw">theme_bw</span>(<span class="dt">base_size=</span><span class="dv">12</span>))
  <span class="kw">theme_update</span>(<span class="dt">panel.background =</span> <span class="kw">element_rect</span>(<span class="dt">fill =</span> <span class="st">&quot;transparent&quot;</span>, <span class="dt">colour =</span> <span class="ot">NA</span>),
               <span class="dt">plot.background =</span> <span class="kw">element_rect</span>(<span class="dt">fill =</span> <span class="st">&quot;transparent&quot;</span>, <span class="dt">colour =</span> <span class="ot">NA</span>))
  opts_chunk$<span class="kw">set</span>(<span class="dt">dev.args=</span><span class="kw">list</span>(<span class="dt">bg=</span><span class="st">&quot;transparent&quot;</span>))
   
<span class="co"># Set a color-blind friendly pallette</span>
<span class="co"># adapted from http://www.cookbook-r.com/Graphs/Colors_(ggplot2)/</span>
   cbPalette &lt;- <span class="kw">c</span>(<span class="st">&quot;#000000&quot;</span>, <span class="st">&quot;#E69F00&quot;</span>, <span class="st">&quot;#56B4E9&quot;</span>, <span class="st">&quot;#009E73&quot;</span>, 
                  <span class="st">&quot;#F0E442&quot;</span>, <span class="st">&quot;#0072B2&quot;</span>, <span class="st">&quot;#D55E00&quot;</span>, <span class="st">&quot;#CC79A7&quot;</span>)</code></pre>
<p>also appears as <a href="https://gist.github.com/cboettig/5600558">gist:5600558</a></p>
<p>Saved script as <code>~/.knit_defaults.R</code> and is sourced in by the first chunk instead.</p>
 
<!-- not that raw_content depends on custom generator, 
     see _plugins/jekyll-labnotebook-plugins/raw_content --> 
</article> 
<p> <a href="/2013/05/29/notes.html"> <em>Read more</em></a> </p>
<br />
<br />


        </div>
      
        <div class="span3">
          <header><h4><a href="/2013/05/28/notes.html">Notes</a></h4></header>
<p><span></span></p>
<p style="font-style:italic"> 28 May 2013</p>

<p style="font-style:italic"> pageviews: 12 </p>

<article>
<div class="excerpt">
<h2 id="mangel-group-talk">Mangel group talk</h2>
<ul>
<li>Presented nonparametric-bayes slides</li>
<li>ADP introduction / trouble-shooting (see yesterday’s entry), <a href="https://github.com/cboettig/nonparametric-bayes/blob/094b44822abb47b1145f0a0bb0ae2c8364bbee25/inst/mydeck/slides.html">html5 slides</a></li>
</ul>
<h3 id="notes">Notes</h3>
<ul>
<li>Decent convergence in the forward algorithm is hard. Consider basis function representation of value function to decrease the search space in the backwards-algorithm first. Also consider searching for policy function (under appropriate piecewise constraints).</li>
<li>Starts to sound more and more similar to POMDP</li>
</ul>
<h2 id="misc">Misc</h2>
<ul>
<li>Trouble with equations in <a href="https://github.com/ramnathv/slidify/issues/214">slidify/214</a></li>
<li><p>Finishing up posts from last week</p></li>
<li><p><strong><a href="http://osswatch.jiscinvolve.org/wp/2013/05/21/unlicensed-code-movement-or-madness/">On the lack of licenses on Github</a></strong></p></li>
</ul>
<p>R packages state licenses in the DESCRIPTION file, which automatically recognizes standard licenses rather than distributing a copy of the license. This seems sensible but it’s not like we don’t have a few bits to spare for a million duplicate copies of license files, so I suppose I could add this in explicitly.</p>
<p>Clearly my own thinking on licenses has evolved ahead of my adaptation:</p>
<pre class="sourceCode bash"><code class="sourceCode bash">$ <span class="kw">grep</span> <span class="st">&quot;License&quot;</span> code/*/DESCRIPTION

AdaptiveDynamics/DESCRIPTION:License: GPL <span class="kw">(&gt;</span>= 2<span class="kw">)</span>
earlywarning/DESCRIPTION:License: BSD
fluctuationDomains/DESCRIPTION:License: CC ZERO 1.0 + <span class="kw">file</span> LICENSE
knitcitations/DESCRIPTION:License: CC0
mcmcTools/DESCRIPTION:License: BSD
multiple_uncertainty/DESCRIPTION:License: BSD
nonparametric-bayes/DESCRIPTION:License: BSD
OUwie/DESCRIPTION:License: GPL <span class="kw">(&gt;</span>= 2<span class="kw">)</span>
pdg_control/DESCRIPTION:License: BSD
pmc/DESCRIPTION:License: CC0
populationdynamics/DESCRIPTION:License: BSD
prosecutors-fallacy/DESCRIPTION:License: BSD
socialR/DESCRIPTION:License: GPL <span class="kw">(&gt;</span>= 2<span class="kw">)</span>
structured-populations/DESCRIPTION:License: GPL <span class="kw">(&gt;</span>= 3<span class="kw">)</span>
warningsignals/DESCRIPTION:License: GPL <span class="kw">(&gt;</span>= 2<span class="kw">)</span>
wrightscape/DESCRIPTION:License: GPL-2</code></pre>
<p>Looks like it’s time for a little</p>
<pre><code>sed -i &quot;s/License: .*/License: CC0/&quot; */DESCRIPTION</code></pre>
<p>Yeehaw!</p>
<p>Just for the sake of being pendantic,</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">wget</span> http://creativecommons.org/publicdomain/zero/1.0/legalcode.txt
<span class="kw">mv</span> legalcode.txt LICENSE
<span class="kw">echo</span> */R/.. <span class="kw">|</span> <span class="kw">xargs</span> -n 1 <span class="kw">cp</span> LICENSE </code></pre>
<h3 id="rcurl-query-from-scott">RCurl query from Scott</h3>
<p>Translate a cURL command’s <code>-d</code> flag to RCurl, e.g.</p>
<pre class="sourceCode bash"><code class="sourceCode bash">curl -H <span class="st">&quot;X-Gauges-Token: &lt;token&gt;&quot;</span> <span class="kw">\</span>
     -d <span class="st">&quot;title=Example&quot;</span> <span class="kw">\</span>
     -d <span class="st">&quot;tz=Eastern Time (US %26 Canada)&quot;</span> <span class="kw">\</span>
     https://secure.gaug.es/gauges</code></pre>
<p>I proposed</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">httpPOST</span>(<span class="st">&quot;https://secure.gaug.es/gauges&quot;</span>, 
         <span class="dt">postfields=</span><span class="st">&quot;title=Example&amp;tz=Eastern Time (US %26 Canada)&quot;</span>, 
         <span class="dt">httpHeader=</span><span class="kw">c</span>(<span class="st">&quot;X-Gauges-Token&quot;</span>=<span class="st">&quot;&lt;token&gt;&quot;</span>), <span class="dt">verbose=</span><span class="ot">TRUE</span>)</code></pre>
<p>Though here is an <a href="http://stackoverflow.com/questions/12302941/">SO example</a> with slightly more elegant construction of postfields.</p>
<h2 id="two-column-layout-with-longtable">Two column layout with <code>longtable</code></h2>
<p>Pandoc now uses the <code>longtable</code> package to generate tables. Annoyingly, these insist on being single-column objects and are not handled properly by <code>elsarticle</code> two-column layouts. To get around this, I edit the latex Pandoc creates, wrapping the table in a float environment (<code>\begin{figure}</code>), followed by a toggle to <code>\onecolumn</code>. After the <code>longtable</code> envirnoment block ends, I include the caption, then toggle back to <code>\twocolumn</code> layout. I also have to tune the width of the <code>minipage</code> objects used by <code>longtable</code>, and change its alignment option to left-align (<code>\begin{longtable}[l]</code>). After these modifications I have a nice floating table in the width of a single column, embedded in my two-column layout.</p>
<p>Brilliantly, arXiv has no trouble with the scores of extra package dependencies introduced by pandoc, as long as the document is pdflatex compatible (no xelatex, hence non-ascii UTF-8, or custom fonts, sorry). Still far ahead of my experience submitting the same document to the acutal journal…</p>
<p>This nicely formatted tex is in the repository as <a href="">arxiv-copy.tex</a>. Should be generated from source with <code>make fancy</code>, since default <code>make</code> builds the 1980s plaintex format for the journal. I need to add make commands to automatically wrap the longtable as described above, hopefully a few lines of <code>sed</code> should do this…</p>
<p>So, arXiv copy sumbmitted… stay tuned on Thursday.</p>
 
<!-- not that raw_content depends on custom generator, 
     see _plugins/jekyll-labnotebook-plugins/raw_content --> 
</article> 
<p> <a href="/2013/05/28/notes.html"> <em>Read more</em></a> </p>
<br />
<br />


        </div>
      
        <div class="span3">
          <header><h4><a href="/2013/05/27/exploring-approximate-dynamic-programming-approaches.html">Exploring Approximate Dynamic Programming Approaches</a></h4></header>
<p><span></span></p>
<p style="font-style:italic"> 27 May 2013</p>

<p style="font-style:italic"> pageviews: 12 </p>

<article>
<div class="excerpt">
<h2 id="introductory-examples-in-approximate-dynamic-programming">Introductory examples in approximate dynamic programming</h2>
<p><em>Based on Powell 2006, page 97. I try to conform to that notation throughout</em>. Haven’t really figured this out yet, so this is more a walk through of me thinking this out then a tutorial. My active copy of this analysis can be found in the <a href="https://github.com/cboettig/nonparametric-bayes/blob/4eb6a30441f28e9cbe87690d9e098b0e068cc395/inst/examples/adp-intro.md">adp-intro</a> file of my nonparametric-bayes repo, see there for the <a href="https://github.com/cboettig/nonparametric-bayes/blob/master/inst/examples/adp-intro.md">most recent</a> (or earlier) versions.</p>
<h2 id="setup-my-sample-problem">Setup my sample problem</h2>
<p>First we define the Beverton-Holt stock-recruitment relationship as a function of stock size <code>x</code>, harvest <code>h</code> and parameters <code>p</code></p>
<pre class="sourceCode r"><code class="sourceCode r">f &lt;- function(x, h, p){
    A &lt;- p[<span class="dv">1</span>] 
    B &lt;- p[<span class="dv">2</span>] 
    s &lt;- <span class="kw">pmax</span>(x-h, <span class="dv">0</span>)
    A * s/(<span class="dv">1</span> + B * s)
}
p &lt;- pars &lt;- <span class="kw">c</span>(<span class="fl">1.5</span>, <span class="fl">0.5</span>)
K &lt;- (p[<span class="dv">1</span>] - <span class="dv">1</span>)/p[<span class="dv">2</span>]
sigma_g &lt;- <span class="fl">0.2</span></code></pre>
<p>We begin with a simulation method <span class="math">\(X_{t+1} = f(X_t, Z_t)\)</span>. For illustration, let us consider <span class="math">\(f(X_t, Z_t) = Z_t \frac{a X_t}{b + X_t}\)</span> with a = 1.5 and b = 0.5. We define a statespace <span class="math">\(S\)</span></p>
<pre class="sourceCode r"><code class="sourceCode r">S &lt;- <span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dt">length=</span><span class="dv">11</span>) </code></pre>
<p>as a uniform grid of 11 points from 0 to 1.<br />We also need a value function on the state space, <span class="math">\(C_t(S_t)\)</span>. For simplicity, we set the price of harvest at unity and the cost of harvesting at zero, so that <span class="math">\(C_t(S_t, x_t) = \min(x_t, S_t)\)</span>.<br />(<span class="math">\(C_t\)</span> is sometimes denoted <span class="math">\(\mathbb{\Pi}\)</span>).<br />We also need an action space <span class="math">\(\chi_t\)</span> of possible harvest values.<br />Again for simplicity we assume that harvest can be set to any possible state size, <span class="math">\(\chi_t \equiv S_t\)</span>,</p>
<pre class="sourceCode r"><code class="sourceCode r">chi &lt;- S</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">T &lt;- <span class="dv">10</span>
N &lt;- <span class="dv">10</span></code></pre>
<p>The approximate dynamic programming algorithm will perform a finite number <span class="math">\(N\)</span> = 10 iterations over a window of time <span class="math">\(T\)</span> =10 in our example. The algorithm can then be described as follows:</p>
<h2 id="algorithm-1">Algorithm (1)</h2>
<ul>
<li><p><strong>Step 0</strong></p></li>
<li><p>Initialize some value <span class="math">\(\tilde V_t^0(S_t)\)</span> for all states <span class="math">\(S_t\)</span>, where the superscripts denote iterations in the forward approximation.<br /> As we know absolutely nothing yet to base our initial guess on, we just arbitrarily set this to zero.</p></li>
</ul>
<pre class="sourceCode r"><code class="sourceCode r">V &lt;- <span class="kw">numeric</span>(<span class="kw">length</span>(S))</code></pre>
<ul>
<li>Choose some initial state <span class="math">\(S_0^1\)</span> We start at some initial state for <span class="math">\(n = 1\)</span> (superscript) and <span class="math">\(t = 0\)</span> (subscript). The choice of initial condition may come from the problem itself, otherwise we choose something arbitrarily.</li>
</ul>
<pre class="sourceCode r"><code class="sourceCode r">S_0 &lt;- <span class="fl">0.5</span></code></pre>
<ul>
<li><p>Set <span class="math">\(n = 1\)</span></p></li>
<li><p><strong>Step 1</strong>: Choose a sample path, <span class="math">\(\omega^n\)</span> (a vector of random draws)</p></li>
</ul>
<pre class="sourceCode r"><code class="sourceCode r">sigma &lt;- <span class="fl">0.2</span>
omega_n &lt;- <span class="kw">rlnorm</span>(T, <span class="dv">0</span>, sigma)</code></pre>
<ul>
<li><p><em>* Step 2</em>*: For <span class="math">\(t = 0, 1, 2, \ldots, T\)</span>, do:</p></li>
<li><p>Solve:</p></li>
</ul>
<p><span class="math">\[V_t(S_t) = \max_{x_t \in \chi_t} \left(C(S_t, x_t) + \gamma \sum_{s^{\prime} \in \mathcal{S}} \mathbb{P}(s^{\prime} | S_t^n, x_t) V_{t+1}^{n-1} s^{\prime} \right)\]</span></p>
<p>That is, choose action <span class="math">\(x_t\)</span> that maximizes the value of the next step.</p>
<p>Let’s start with <span class="math">\(t=0\)</span>, <span class="math">\(n=1\)</span> and fix an <span class="math">\(x_0\)</span> from the set of <span class="math">\(\chi\)</span> (allowing the action space to be the same in each period, we can omit the subscript on <span class="math">\(\chi\)</span>) to get started. We first compute <span class="math">\(C(S_0, x_0)\)</span>.</p>
<p><span class="math">\(S_0 = S_0^1\)</span> which we fixed in step <strong>0b</strong> arbitrarily at 0.5.</p>
<p>The profits/costs <span class="math">\(C(S_t, x_t)\)</span> are the value derived by action (harvest) <span class="math">\(x_t\)</span> at state (stock) <span class="math">\(S_t\)</span>. Assuming a fixed price and no costs to harvesting, this is just whichever number is smaller (since we cannot harvest more than the available stock,</p>
<pre class="sourceCode r"><code class="sourceCode r">C &lt;- function(S, X) <span class="kw">pmin</span>(S, X)</code></pre>
<p>(where we have used R’s vectorized form of the min function).</p>
<p>This forward dynamic programming will still rely on the one-step transition matrix, <span class="math">\(\mathbb{P}\)</span>.</p>
<p>Let’s get the transition matrices for this problem, assuming log-normal noise,</p>
<pre class="sourceCode r"><code class="sourceCode r">sdp_matrix &lt;- <span class="kw">determine_SDP_matrix</span>(f, p, <span class="dt">x_grid=</span>S, <span class="dt">h_grid=</span>chi, sigma_g)</code></pre>
<p>Which is a list of matrices, one for each harvest (action) <span class="math">\(x_t\)</span>.</p>
<p>Then we want to consider a fixed <span class="math">\(S_t^n\)</span> and fixed <span class="math">\(x_t\)</span>, and take the sum of <span class="math">\(\mathbb{P}(s^{\prime} | S_t^n, x_t)\)</span> over the <span class="math">\(s^{\prime}\)</span>, which means we want the <span class="math">\(x_t\)</span> element from the list, and then we need sum over the distribution of future states given the current state <span class="math">\(S_t^n\)</span>, e.g. a row of the matrix, e.g. <code>sdp_matrix[[x]][s,]</code>, which we (vector) multiply by <span class="math">\(V_{t+1}^{n-1}(s^{\prime})\)</span>.</p>
<p>This value <span class="math">\(V\)</span> is of course unknown, other than our initial random guess <span class="math">\(V_{t}^0\)</span>.<br />As we step through the iterations <span class="math">\(V_t^1\)</span>, <span class="math">\(V_t^2\)</span>, <span class="math">\(V_t^3\)</span>, etc., this should convgerge to something meaningful.</p>
<p>Note that the index along <span class="math">\(S\)</span> corresponding to <span class="math">\(S_t^n\)</span> is given by</p>
<pre class="sourceCode r"><code class="sourceCode r">s &lt;- <span class="kw">which.min</span>(<span class="kw">abs</span>(S-S_0))</code></pre>
<p>So our maximization across <span class="math">\(x\)</span> just involves:</p>
<pre class="sourceCode r"><code class="sourceCode r">values &lt;- 
  <span class="kw">sapply</span>(<span class="dv">1</span>:<span class="kw">length</span>(chi), function(x)
    <span class="kw">C</span>(S[s], chi[x]) + sdp_matrix[[x]][s,] %*% V
)

max_x &lt;- <span class="kw">which.max</span>(values)
v_hat &lt;- <span class="kw">max</span>(values)</code></pre>
<p>Trivially, this is just the harvest level that maximizes <span class="math">\(C\)</span> so far (which is just harvesting the <span class="math">\(S_0\)</span>, since <span class="math">\(\bar V^0_t\)</span> begins at zero:</p>
<pre class="sourceCode r"><code class="sourceCode r">chi[max_x]</code></pre>
<pre><code>[1] 0.5</code></pre>
<ul>
<li>step <strong>2b</strong> We can now update our <span class="math">\(\bar V^0_t\)</span> to get <span class="math">\(\bar V^1_t\)</span>, using the rule:</li>
</ul>
<p><span class="math">\[V_t^n(S_t) = \begin{cases} 
\hat v_t^n &amp; S_t = S_t^n \\
\bar V_t^{n-1}(S_t) &amp; \textrm{otherwise} 
\end{cases}\]</span></p>
<p>e.g. use our maximum value for the case of the state we just considered <span class="math">\(S_t = S_t^n\)</span>, otherwise leave <span class="math">\(V_t\)</span> unchanged. Our new <span class="math">\(V\)</span> is thus:</p>
<pre class="sourceCode r"><code class="sourceCode r">V[s] = v_hat</code></pre>
<ul>
<li>step <strong>2c</strong> Compute <span class="math">\(S^n_{t+1} = S^M(S_t^n, x^n_t, W_{t+1}(\omega^n))\)</span></li>
</ul>
<p>We compute the next state using our <code>max_x</code> for <span class="math">\(x^n_t\)</span>, our random samples and the transition function…</p>
<pre class="sourceCode r"><code class="sourceCode r">S_1 &lt;- omega_n[<span class="dv">1</span>] * <span class="kw">f</span>(S_0, chi[hat[<span class="st">&quot;x_nt&quot;</span>]], p)</code></pre>
<ul>
<li><strong>Step 3</strong> Let <span class="math">\(n = n+1\)</span>. if <span class="math">\(n &lt; N\)</span>, go to step 1</li>
</ul>
<h2 id="putting-this-all-together-as-a-recursive-algorithm">Putting this all together as a recursive algorithm</h2>
<pre class="sourceCode r"><code class="sourceCode r">N &lt;- <span class="dv">5000</span> <span class="co"># iterations</span>
M &lt;- <span class="dv">20</span> <span class="co"># gridsize </span>
Tmax &lt;- <span class="dv">5</span> <span class="co"># Time horizon</span>

gamma &lt;- <span class="fl">0.95</span> <span class="co"># Discount</span>
<span class="co"># f (defined above) </span>
<span class="co"># p  (defined above)</span>

sigma_g &lt;- <span class="fl">0.5</span> <span class="co"># larger variation in random draws helps</span>
chi &lt;- <span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dt">length.out =</span> M)
S &lt;- <span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dt">length.out =</span> M)

sdp_matrix &lt;- <span class="kw">determine_SDP_matrix</span>(f, p, <span class="dt">x_grid=</span>S, <span class="dt">h_grid=</span>chi, sigma_g)

V &lt;- <span class="kw">matrix</span>(<span class="dv">1</span>, M, Tmax)  <span class="co"># A* strategy</span>
<span class="co"># Fails to explore at matrix(0, M, Tmax)</span>
<span class="co"># consider: # V &lt;- matrix(rep(chi, Tmax), nrow=M) # </span>
<span class="co"># V[,1] &lt;- chi   # fails to explore if it doesn&#39;t have at least some non-zero values</span>

C &lt;- function(S, X) <span class="kw">pmin</span>(S, X)
S_0 &lt;- <span class="fl">0.5</span> 
alpha &lt;- <span class="dv">1</span> <span class="co"># learning rate</span>


for(n in <span class="dv">1</span>:N){
  
  omega_n &lt;- <span class="kw">rlnorm</span>(Tmax, <span class="dv">0</span>, sigma_g)
  S_current &lt;- S_0 <span class="co">#runif(1,0,1) # explores faster when this is random</span>

  for(t in <span class="dv">1</span>:Tmax){
    <span class="co"># index of the state we&#39;re considering</span>
    s &lt;- <span class="kw">which.min</span>(<span class="kw">abs</span>(S-S_current)) 
    
    <span class="co"># Find the action maximizing the value</span>
    values &lt;- <span class="kw">sapply</span>(<span class="dv">1</span>:<span class="kw">length</span>(chi), function(x)
      <span class="kw">C</span>(S[s], chi[x]) + gamma * sdp_matrix[[x]][s,] %*% V[,t])
    hat &lt;-  <span class="kw">c</span>(<span class="dt">x_nt =</span> <span class="kw">which.max</span>(values), <span class="dt">v_nt =</span> <span class="kw">max</span>(values))

    <span class="co"># Update value V as mixture of new value and previous value</span>
    V[hat[<span class="st">&quot;x_nt&quot;</span>], t] &lt;- (<span class="dv">1</span> - alpha) * V[hat[<span class="st">&quot;x_nt&quot;</span>],t] + alpha * hat[<span class="st">&quot;v_nt&quot;</span>] 
    
    <span class="co"># Advance the state in time along random path  </span>
    S_current &lt;- omega_n[t] * <span class="kw">f</span>(S_current, chi[hat[<span class="st">&quot;x_nt&quot;</span>]], p)

  }
}</code></pre>
<p>for comparison: the SDP solution</p>
<pre class="sourceCode r"><code class="sourceCode r">opt &lt;- <span class="kw">find_dp_optim</span>(sdp_matrix, S, chi, <span class="dv">70</span>, <span class="fl">0.5</span>, C, <span class="dv">1</span>-gamma, <span class="dt">reward=</span><span class="dv">0</span>)
opt$V</code></pre>
<pre><code> [1] 0.000 7.173 7.375 7.496 7.584 7.653 7.710 7.760 7.810 7.860 7.910
[12] 7.960 8.010 8.060 8.110 8.160 8.210 8.260 8.310 8.360</code></pre>
<h3 id="problems-arising-from-the-discretization">Problems arising from the discretization</h3>
<p>Note that after the first iteration, <span class="math">\(n=1\)</span>, the value matrix <span class="math">\(V\)</span> is no longer all zeros. There is a single state, <span class="math">\(S = S_0 =\)</span> 0.5, at which we have value. That value is lost if we set harvest <span class="math">\(x\)</span> too high, since we know we will not then end up in that state – from whence comes the incentive to consider future value. Unfortunately, the value exists only if we hit that state exactly – all other states are assumed to have zero value still.</p>
<h3 id="additional-problems">Additional problems</h3>
<p>We no longer have the loop-over-all-states problem, but we face several new or remaining issues:</p>
<ol type="1">
<li><p>We still require the use of the one-step transition matrix, with the equally troublesome sum over all states <span class="math">\(\sum_{s^{\prime}\in S} \mathbb{P}(s^{\prime} | S_t^n, x_t)\)</span>.<br />We will fix this by approximating the transitions in step 2b using random draws as well.</p></li>
<li><p>We only update the values of states we visit. We still need a way to estimate the value of states we have not visited.</p></li>
<li><p>Worse, we might not visit states that seem bad relative to states we have visited. This is particularly atrocious in this example. Since we initialize the value of all states at 0, the algorithm prefers to harvest all stock from the current state rather than risk a transition into a state starting at 0. There is no convergence guarentee that we will ever escape this cycle of avoiding states we have not seen. We can alter the initial guess of the value of course, and we could alter the starting condition to better explore.</p></li>
</ol>
<h2 id="extensions">Extensions</h2>
<p>The rest of the ADP development is designed to tackle each of these issues. This algorithm gives very poor performance, but very flexible skeleton on which to extend features that have made ADP such a successful approach for impossibly large problems.</p>
<h3 id="stochastic-value-function-sampling">Stochastic value function sampling</h3>
<p>Dealing with problem 1:</p>
<p><span class="math">\[V_t(S_t) = \max_{x_t \in \chi_t} \left(C(S_t, x_t) + \gamma \sum_{\hat \omega \in \hat \Omega^n_{t+1}} p_t+1(\hat \omega) \bar V_{t+1}^{n-1} (S_{t+1}) \right)\]</span></p>
<pre class="sourceCode r"><code class="sourceCode r">    V[hat[<span class="st">&quot;x_nt&quot;</span>], t] &lt;- (<span class="dv">1</span> - alpha) * 
                         V[hat[<span class="st">&quot;x_nt&quot;</span>],t] + 
                          alpha * hat[<span class="st">&quot;v_nt&quot;</span>] </code></pre>
<h3 id="decreasing-the-state-space-size">Decreasing the state space size</h3>
<ul>
<li>Aggregation</li>
<li>Continuous Value function approximations</li>
<li>Using the post-decision state variable (improves dealing with the expectation calc)</li>
</ul>
<h3 id="initialization-problem">Initialization problem</h3>
<ul>
<li>We do not explore if we are too pessimistic about value of visiting other states. Start optimisitc: AI’s A* alogrithm (synchronous)</li>
<li>Asynchronous updating – randomly sampling starting variables</li>
<li>RTDP (Real Time Dynamic Programming – not necessarily what it sounds like) external rule determines which states we visit</li>
</ul>
<h3 id="learning">Learning</h3>
<ul>
<li>The concepts of learning and the trade-off between exploration and exploitation are already built-in to the forward algorithm.</li>
</ul>
<h3 id="using-non-stochastic-transition-information-only-step-2b-can-be-written-as">Using Non-stochastic transition information only, step <strong>2b</strong> can be written as:</h3>
<p>Taking <span class="math">\(x_0\)</span> as the smallest harvest, <span class="math">\(\min(\chi)\)</span> = 0 and evaluating <span class="math">\(C(S_0,X_0) = \min(S_0, X_0)\)</span> gives us 0, rather trivially.<br />The next terms depend on the value <span class="math">\(\tilde V^0_1(s^{\prime})\)</span> for all <span class="math">\(s^{\prime} \in S\)</span>, which we have no idea about. Fortunately we have assumed a value for each of these in step 0a.</p>
<p>We must also come up with some values for the probability <span class="math">\(\mathbb{P}(s^{\prime} | S_1^0, x_1)\)</span> for each state, given our current state <span class="math">\(S_1^0\)</span> and considered action <span class="math">\(x_1\)</span>. This is more straight forward, since it is determined by our one-step transition function (without simulation - recall that the single step transition is given exactly).</p>
<p>To do so, we evaluate the argument for each value in our action space, <span class="math">\(x_t \in \chi_t\)</span>,</p>
<pre class="sourceCode r"><code class="sourceCode r">s &lt;- S_0
C &lt;- function(S, X) <span class="kw">pmin</span>(S, X)
arg &lt;- <span class="kw">sapply</span>(chi, function(x) <span class="kw">C</span>(s, x) + <span class="kw">f</span>(S, x, p) %*% V)
x_nt = <span class="kw">which.max</span>(arg)
v_nt = <span class="kw">max</span>(arg)
V[x_nt] = v_nt</code></pre>
 
<!-- not that raw_content depends on custom generator, 
     see _plugins/jekyll-labnotebook-plugins/raw_content --> 
</article> 
<p> <a href="/2013/05/27/exploring-approximate-dynamic-programming-approaches.html"> <em>Read more</em></a> </p>
<br />
<br />


        </div>
      
    </div>

  </div>
</div> <!--end row -->

<div class="row">
  <div class="span11 offset1">
    <div class="socialicons">
      <p> <a href="/archive.html"><i class="icon-calendar"></i> All entries by date</a></p> 
      <p> <a href="/categories.html"><i class="icon-list"></i> All entries by category</a> </p>
      <p> <a href="/tags.html"><i class="icon-tags"></i> All entries by tag</a> </p>
    </div>
  </div> <!--end span9 -->
</div> <!--end row -->




<footer class="footer">
  <!-- ************* Buttons to toggle theme CSS ********************** -->
    <div class="row">
      <div class="span12">
        <form style="font-size:10px" class="pull-right">
          <a onclick="switch_style('dark'); 
                      recordOutboundLink(this, 'Outbound Links', 'dark theme'); 
                      return false;" 
             name="theme" value="dark" id="dark" 
             class="btn btn-mini"><span class="showtooltip" 
                                        title="switch to dark theme"><i class="icon-adjust"></i>
                                   </span></a>
          
          <a onclick="switch_style('light'); 
                      recordOutboundLink(this, 'Outbound Links', 'light theme'); 
                      return false;" 
             name="theme" value="light" id="light" 
             class="btn btn-mini"><span class="showtooltip" 
                                        title="switch to light theme"><i class="icon-certificate"></i>
           <a onclick="switch_style('white'); 
                      recordOutboundLink(this, 'Outbound Links', 'white theme'); 
                      return false;" 
             name="theme" value="white" id="white" 
             class="btn btn-mini"><span class="showtooltip" 
                                        title="switch to white theme"><i class="icon-circle-blank"></i>
                                  </span></a>
                                 </span></a>
        </form>
      </div>
    </div>

<!--************** FOAF information to social networks ***************************** -->
  <div class="row">
    <div class="span3 socialicons" style="font-size:20px" typeof="foaf:Person" about="http://carlboettiger.info#me">
      <p>
          <script type="text/javascript" src="/assets/js/obfuscate-email-link.js" language="javascript"></script> 
          <a rel="foaf:account" alt="twitter" href="https://twitter.com/cboettig" 
             onclick="recordOutboundLink(this, 'Outbound Links', 'Twitter'); 
             return false;"><span class="showtooltip" title="follow me on twitter (reading, discussing)"><i class="icon-twitter"></i></span></a> 
          <a rel="foaf:account" alt="github" href="https://github.com/cboettig" 
             onclick="recordOutboundLink(this, 'Outbound Links', 'Github'); 
             return false;"><span class="showtooltip" title="follow me on Github (code, research)"><i class="icon-github"></i></span></a>
      <!--
          <a rel="foaf:account" href="https://plus.google.com/" 
             onclick="recordOutboundLink(this, 'Outbound Links', 'GPlus'); 
             return false;"><i class="icon-google-plus"></i></a>
          <a rel="foaf:account" href="http://www.mendeley.com/profiles/carl-boettiger" 
             onclick="recordOutboundLink(this, 'Outbound Links', 'Mendeley'); 
             return false;"><img src="/assets/img/icon-mendeley.png" alt="mendeley" /></a> 
           citations on google-scholar
           stackoverflow
      -->
      <a alt="rss" type="application/atom+xml" href="/atom.xml"  
         class="showtooltip" title="subscribe to RSS feeds for my open lab notebook" 
         onclick="recordOutboundLink(this, 'Outbound Links', 'RSS'); 
         return false;"><i class="icon-rss"></i></a>
       </p>
    </div>
    <!--**************** End social links **************************** -->
    <div class="span1">
      <br />
    </div>
    <div class="span4">
      <p>
      <a onclick="recordOutboundLink(this, 'Outbound Links', 'ONS_claim'); return false;" href="http://onsclaims.wikispaces.com/"><img src="http://onsclaims.wikispaces.com/file/view/ons-aci2-icon.png" alt="ONS" class="showtooltip" title="An Open Notebook Science (ONS) project claim: Entry provides all content (AC) immediately (I) or without significant delay.  See link for details"/></a>

      <a title="This site uses linked data semantics. Click to extract as RDF XML." class="btn btn-mini showtooltip" style="font-size: .8em" 
       href="http://any23.org/?format=rdfxml&validate=validate&uri=http://carlboettiger.info/lab-notebook.html"><i 
         class="icon-cloud-download"  onclick="recordOutboundLink(this, 'Outbound Links', 'RDF'); return false;"></i> RDF</a>
      </p>
    </div>
    <div class="span1">
      <br />
    </div>
    <div class="span3">
      <p>
      <a rel="license" property="http://creativecommons.org/ns#license" href="http://creativecommons.org/publicdomain/zero/1.0/" onclick="recordOutboundLink(this, 'Outbound Links', 'CC0'); return false;"><img src="http://i.creativecommons.org/l/zero/1.0/88x31.png" alt="CC0"/></a> 
      </p>
    </div>

  </div>
  
<!-- COinS metadata (for citation managers like Zotero etc), goes in body text -->
  <span
      class="Z3988" 
      title="ctx_ver=Z39.88-2004
      &amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Adc
      &amp;rfr_id=info%3Asid%2Focoins.info%3Agenerator
      &amp;rft.title=Lab Notebook
      &amp;rft.creator=Carl Boettiger
      &amp;rft.date=
      &amp;rft.language=EN
      &amp;rft.rights=CC0
      &amp;rft_id=http://carlboettiger.info/lab-notebook.html">
  </span>



</footer>




    <!-- Le javascript
    ================================================== -->

    <!-- Placed at the end of the document so the pages load faster -->
    <!-- JQuery, used on a few pages -->
    <script type="text/javascript" src="/assets/js/jquery.js"></script>
    <!-- Equations using MathJax -->
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config"> MathJax.Hub.Config({ TeX: { equationNumbers: {autoNumber: "all"} } });       </script>
    <!-- Twitter Bootstrap Javascript -->
    <script src="/assets/js/bootstrap.min.js"></script>
    <!-- Tooltip javascript -->
    <script type="text/javascript">
      $(document).ready(function (){
        $(".showtooltip").tooltip();
      });
    </script>

    <!-- Marran's Search Javascript -->
    <script type="text/javascript" src="/assets/js/porter-stemmer.js"></script>
    <script type="text/javascript" src="/assets/js/site-search.js"></script>

    <!-- Code collapse Javascript -->
    <script type="text/javascript">
    $(document).ready(function(){
      $("#toggle_code").click(function(){
        $(".highlight").toggle();
        $(".sourceCode").toggle();
      });
    });
    </script>


  <script type="text/javascript">
          var _gaq = _gaq || [];
          _gaq.push(['_setAccount', 'UA-18401403-1']);
          _gaq.push(['_trackPageview']);
          (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
          })();
  </script>



<script type="text/javascript">
function recordOutboundLink(link, category, action) {
  try {
    var pageTracker=_gat._getTracker("UA-18401403-1");
    pageTracker._trackEvent(category, action);
    setTimeout('document.location = "' + link.href + '"', 100)
  }catch(err){}
}
</script>




    


    </div>
  </body>
</html>


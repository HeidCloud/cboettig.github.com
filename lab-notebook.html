<!DOCTYPE html>
<html lang="en" xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
  <head prefix="dc: http://purl.org/dc/terms/ og: http://ogp.me/ns#">
  <meta http-equiv='Content-Type' content='text/html; charset=utf-8'/>
  <title>Lab Notebook</title>
  <meta name="author" content="Carl Boettiger" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  

<!-- Get date last modified from git log. (Uses current time if file entry not found, e.g. projects/)  -->



<!-- For posts, page.date is the date they are published under, which we use as their 'canonical' dc:date -->
 <!-- If we don't have a page.date, then use modified time (pages) -->
   


<!-- Posts declare modified timestamps in the sidebar, so would be redundant to put here. But then 
     pages don't have a dc:modified... unless we give them their own (modified) sidebar?  
-->
<!-- Ideally we would want date originally created from the _oldest_ git commit too...-->

<!-- HTML5 metadata -->
<meta name="keywords" content="" />
<meta name="description" content="" />
<meta name="resource_type" content="website"/> 
<!-- RDFa Metadata (in DublinCore) -->
<meta property="dc:title" content="Lab Notebook" />
<meta property="dc:creator" content="Carl Boettiger" />
<meta property="dc:date" content="2013-04-12T08:53:44-07:00" />
<meta property="dc:format" content="text/html" />
<meta property="dc:language" content="en" />
<meta property="dc:identifier" content="/lab-notebook.html" />
<meta property="dc:rights" content="CC0" />
<meta property="dc:source" content="Lab Notebook" />
<meta property="dc:subject" content="Ecology" /> 
<meta property="dc:type" content="website" /> 
<!-- RDFa Metadata (in OpenGraph) -->
<meta property="og:title" content="Lab Notebook" />
<meta property="og:author" content="http://carlboettiger.info/index.html#me" />  <!-- Should be Liquid? URI? -->
<meta property="http://ogp.me/ns/profile#first_name" content="Carl"/>
<meta property="http://ogp.me/ns/profile#last_name" content="Boettiger"/>
<meta property="http://ogp.me/ns/article#published_time" content="2013-04-12T08:53:44-07:00" />
<meta property="og:site_name" content="Lab Notebook" /> <!-- Same as dc:source? -->
<meta property="og:url" content="http://carlboettiger.info/lab-notebook.html" />
<meta property="og:type" content="website" /> 
<!-- Google Scholar Metadata -->
<meta name="citation_author" content="Carl Boettiger"/>
<meta name="citation_date" content="2013-04-12T08:53:44-07:00"/>
<meta name="citation_title" content="Lab Notebook"/>
<meta name="citation_journal_title" content="Lab Notebook"/>

<!--NOTE: see also the COinS Metadata in span element in footer -->




  <!-- CSS Stylesheets (toggled with javascript) -->
  <link href="/assets/css/bootstrap.css" rel="stylesheet" 
        type="text/css" title="white" />
  <link href="/assets/css/light.css" rel="alternate stylesheet"
        type="text/css" id="stl" title="light" />
  <link href="/assets/css/dark.css" rel="alternate stylesheet" 
        type="text/css" title="dark" />
  <link href="/assets/css/bootstrap-responsive.css" rel="stylesheet" 
        type="text/css"/>
  <!-- Javascript needed for theme toggle, load immediately -->
  <script type="text/javascript" src="/assets/js/switch-css.js"></script>
  <script type="text/javascript">
    set_style_from_cookie(); 
  </script>
</head>


  <body prefix="dc: http://purl.org/dc/terms/ foaf: http://xmlns.com/foaf/0.1/"> 
    <!-- Navbar  ================================================== -->
<div class="navbar navbar-fixed-top">
  <div class="navbar-inner">
    <div class="container">
      <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </a>
      <a class="brand" href="/README.html"><i style="float:right;" class="icon-info-sign" alt="info"></i></span></a>
      <div class="nav-collapse">
        <ul class="nav">
          <li>
          <a href="/index.html">Home</a></li>

          <li>
          <a href="/vita.html">Vita</a></li>

          <li>
          <a href="/research.html">Research</a></li>

          <li>
          <a href="/teaching.html">Teaching</a></li>

          <li>
          <a href="/community.html">Community</a></li>

          <li class="active">
          <a href="/lab-notebook.html">Lab Notebook</a></li>

        </ul>
      </div><!--/.nav-collapse -->

      <!-- Search site using Google's index -->
      <form class="navbar-search pull-right" method="get" action="http://google.com/search">
        <p>
          <input type="hidden" name="q" value="site:carlboettiger.info" />
          <input type="text" class="search-query" name="q" />
          <button class="btn btn-mini" type="submit"><i class="icon-search"></i></button> 
        </p>
      </form>
      <!--
      <div id="search">
      <form method="get" class="navbar-search pull-right form-search">
        <p>
        <input type="text" name="search-text" id="search-text">
         <button class="btn btn-mini" type="submit"><i class="icon-search"></i></button> 
        </p>
      </form>
      </div>
      -->
     </div> <!-- /container -->
   </div> <!-- /navbar-inner -->
 </div> <!-- /navbar -->



    <div class="container"> <!-- Responsive grid layout --> 

      <header class="jumbotron">
  <h1 class="entry-title">Lab Notebook</h1>
  <h3>(<a href="http://www.carlboettiger.info/2012/09/28/Welcome-to-my-lab-notebook.html">Introduction</a>)</h3>
</header>



<div class="row feed">
  <div class="span3 offset1">
    <h4>  <a property="account" href="https://github.com/cboettig" onclick="recordOutboundLink(this, 'Outbound Links', 'Github'); return false;"><i class="icon-github" alt="github"></i> Coding </a></h4> 
     <div class="excerpt">
        <ul><li>cboettig pushed to master at cboettig/cboettig.github.com: <em>update site</em> <a href="https://github.com/cboettig/cboettig.github.com/compare/429f8437a3...7cb287f92a">02:28 2013/06/14</a></li><li>cboettig pushed to master at cboettig/labnotebook: <em>draft added funding source post</em> <a href="https://github.com/cboettig/labnotebook/compare/11db1b391d...4e752a229c">02:11 2013/06/14</a></li><li>cboettig commented on issue cboettig/labnotebook#83: <em>thanks for the ideas. @NoamRoss talked me out of anything that requires having a particular account or introduces delays though... May just try and …</em> <a href="https://github.com/cboettig/labnotebook/issues/83#issuecomment-19433483">12:33 2013/06/14</a></li><li>cboettig commented on issue cboettig/labnotebook#63: <em>Interesting example of RDF visualization and linking to external linked-data resources. In particular, good use/example of linking to DBpedia infor…</em> <a href="https://github.com/cboettig/labnotebook/issues/63#issuecomment-19428646">10:15 2013/06/13</a></li><li>cboettig pushed to master at cboettig/nonparametric-bayes: <em>Merge branch 'master' of github.com:cboettig/nonparametric-bayes use headers for each model</em> <a href="https://github.com/cboettig/nonparametric-bayes/compare/b4f3178500...73e94e4a62">09:26 2013/06/13</a></li></ul>
    </div>
  </div>
  <div class="span3">
    <h4> <a property="account" href="https://twitter.com/cboettig" onclick="recordOutboundLink(this, 'Outbound Links', 'Twitter'); return false;"><i class="icon-twitter"></i> Discussing </a></h4> 
     <div class="excerpt">
       <ul><li><p>@lgatt0 thnx should be fixed now</p>
 <a href="http://twitter.com/cboettig/statuses/345372563582623745">07:50 2013/06/13</a> </li><li><p>Great comments from @dwbapst on software reviewing <a href="http://t.co/EIoB8QdYgd">http://t.co/EIoB8QdYgd</a></p>
 <a href="http://twitter.com/cboettig/statuses/345346933814087680">06:08 2013/06/13</a> </li><li><p>@TheAtavism @carlystrasser @mwpennell thanks!</p>
 <a href="http://twitter.com/cboettig/statuses/345337268581564417">05:29 2013/06/13</a> </li><li><p>@recology_ @mathjax @disqus yup, I&#39;m looking for alternatives, see <a href="https://t.co/RUDiXPEvht">https://t.co/RUDiXPEvht</a></p>
 <a href="http://twitter.com/cboettig/statuses/345299438010507265">02:59 2013/06/13</a> </li><li><p>@recology_ u could hack #markdown and @mathjax in @disqus before the last update... I&#39;m increasingly disappointed with @disqus ...</p>
 <a href="http://twitter.com/cboettig/statuses/345294351280246784">02:39 2013/06/13</a> </li></ul>
    </div> 
  </div> 
  <div class="span3">
    <h4> <a href="http://www.mendeley.com/groups/634301/theoretical-ecology/papers/" onClick="recordOutboundLink(this, 'Outbound Links', 'Mendeley'); return false;"><i class="icon-book"></i> Reading </a></h4> 
    <div class="excerpt">
      <ul><li>Review of Sokal and Rolf 2012 Biometry 4th Ed.: Limnology and Oceanography Bulletin (2013). Volume: 115, Issue: 2. Pages: 62-65. Stuart H. Hurlbert et al. <a href="http://www.mendeley.com/research/review-sokal-rolf-2012-biometry-4th-ed-1/">05:21 2013/06/03</a></li><li>Signature of ocean warming in global fisheries catch: Nature (2013). Volume: 497, Issue: 7449. Pages: 365-368. William W. L. Cheung, Reg Watson, Daniel Pauly et al. <a href="http://www.mendeley.com/research/signature-ocean-warming-global-fisheries-catch-7/">05:21 2013/06/03</a></li><li>Innovations in capture fisheries are an imperative for nutrition security in the developing world: Proceedings of the National Academy of Sciences (2013). Pages: 1-6. S. J. Hall, R. Hilborn, N. L. Andrew, E. H. Allison et al. <a href="http://www.mendeley.com/research/innovations-capture-fisheries-imperative-nutrition-security-developing-world/">05:21 2013/06/03</a></li><li>What early warning systems are there for environmental shocks?: Environmental Science & Policy (2013). Pages: S60-S75. Timothy M. Lenton et al. <a href="http://www.mendeley.com/research/early-warning-systems-environmental-shocks/">05:21 2013/06/03</a></li></ul>
    </div>
  </div> 
</div>

<hr>
<div class="row postpreview">
  <div class="span11 offset1">
    <div class="row">
      <h4> <a href="http://carlboettiger.info/atom.xml"
              onClick="recordOutboundLink(this,
              'Outbound Links', 'RSS'); return false;"
              style="color: inherit;"
              ><i class="icon-rss" ></i> Entries</a></h4>
      
        <div class="span3">
          <header><h4><a href="/2013/06/13/what-I-look-for-in-software-papers.html">What I look for in 'Software Papers'</a></h4></header>
<p><span>pet peeves and faux pas</span></p>
<p style="font-style:italic"> 13 Jun 2013</p>

<p style="font-style:italic"> pageviews: 159 </p>

<article>
<div class="excerpt">
<p>I am more and more frequently reviewing ‘software papers:’ which I define as publications whose primary purpose is to publicize a piece of scientific software and provide a traditional research product with hopes that it will receive citations and recognition from other researchers in grant and job reviews. To me this feels very much like hacking the publication recognition system rather than the ideal way to recognize and track the role of software in research communities, but a very practical one in the current climate. I have written two myself, so I have been on both ends of this issue. In this post, I share what I look for in such papers and what omissions I see most frequently.</p>
<h2 id="reviewing-software">Reviewing software</h2>
<p>If we are going to employ this hack of the publication system for software, we should at least use it to maximal advantage. As a reviewer, I feel that means reviewing not just the submitted manuscript but the software itself. If we can agree on nothing else, we as a community should at least be able to say:</p>
<blockquote>
<p>my review of a software paper is a review of the software</p>
</blockquote>
<p>I assume most other authors, reviewers and editors on this content share this implicit assumption, but I’d love to hear first hand from anyone else. For instance: as an editor, what would you do if your reviewers only commented on the paper directly and not on the software distributed?</p>
<p>We are not really taught to review software, any more than we are taught to write it in the first place. Most journals offer little guidance on this (though see the Journal of Open Research Software <a href="http://openresearchsoftware.metajnl.com/peer-review/">guidelines for peer review of software</a>, all though they are still rather minimal.) In the absence of a culture on software reviewing, I thought I would lay out my own perspective with the hope of hearing feedback and push back from others. Perhaps through such dialogs we can develop clearer expectations for this rapidly expanding genre.</p>
<h2 id="reviewing-the-software-paper">Reviewing the software paper</h2>
<p>I don’t include “to document” the software as a purpose, since none do so very comprehensively, and besides, documentation belongs in the software, not in a journal. “Publicize” usually includes some motivating examples that could convince many readers that the software does something useful for them without too much effort. As such, I expect the paper to:</p>
<ul>
<li>provide the journal’s audience with a clear motivation for why the package is useful, * and have at least one functioning “wow” example that I can run (by copy-paste) and understand without difficulty (e.g. without referring to code comments or the package manual to understand the function calls and their arguments).</li>
</ul>
<p>This is an intentionally low bar that I hope helps promote these kinds of contributions. Despite this, papers frequently fail the copy-paste test or the plain text explanations of the function calls. Come on people. Meanwhile, I try to focus the rest of my review on the software itself.</p>
<h2 id="my-partial-list-of-criteria">My partial list of criteria</h2>
<p>As I am almost always reviewing R packages, the software already meets some very basic standards required by submission to CRAN: dependencies and license stated, built-in documentation, passing some minimal automatic checks, etc. (See the <a href="http://cran.r-project.org/web/packages/policies.html">CRAN Policies</a> and the <a href="http://cran.r-project.org/doc/manuals/R-exts.html">Writing R Extensions Manual</a> for details). This is great, as it clears the first few hurdles of installation, etc. without much fuss, but still provides a bar that is by itself unacceptably low for published scientific software. Here is a list of the things I see that most often frustrate me. This isn’t intended as a style-guide or a comprehensive list of best practices, just my own pet peeves. I have somewhat tongue-in-cheek labeled them by severity of the review I might give; which like any other use of these terms is more of a measure of how annoyed I am then anything else. Critiques and suggestions welcome.</p>
<h3 id="edit">Edit:</h3>
<p>The comments from other reviewers, authors, and editors have been fantastic, thank you all. I particularly appreciate the opportunity to have reviewing styles critiqued, something that does not happen in normal peer review.</p>
<p>Just a note on my headings here. I do not see any of these things as “gatekeeping requirements” and have intentionally omitted the option of “<em>Reject</em>”. I would reject such a paper for methodological flaws, etc., but not for any of the reasons on my list below. The list is intended only to improve, not prevent, software publication.</p>
<p>I believe any of the decisions below typically result in a revision to the same journal, that authors judiciously choose how to respond to reviewer comments guided by the editor’s own feedback, and that it is ultimately the editor’s decision whether any of this is relevant. <code>&lt;/edit&gt;</code></p>
<h2 id="reject-and-resubmit">“Reject and resubmit”</h2>
<h3 id="automatic-tests">Automatic tests</h3>
<p>A scientific R package <em>must must must</em> have some automated tests that are run by <code>R CMD check</code>. Even if further development of the package doesn’t break anything (most likely only if further development doesn’t happen), changes to the package dependencies could still break things, and so it is crucial to have a mechanism in place to detect these problems when they arise. For code that runs quickly, the simplest way to do this is through the examples in the documentation. I don’t expect all scientific software to have a complete test suite with 100% coverage covering all the weird things that can happen if a user passes in a matrix when the function expects a data frame or has some unanticipated missing values, etc. Just some tests to make sure the basic examples execute and I’ll be happy. Longer running functions or those that need calls to external web resources shouldn’t be run in the examples (too much of a burden for CRAN’s automatic testing) so they should be marked <code>dontrun</code> and put in a separate test suite or vignette as it says in the manual.</p>
<h3 id="passing-optional-arguments">Passing optional arguments</h3>
<p>I see authors write functions like this all the time:</p>
<pre class="sourceCode r"><code class="sourceCode r">f &lt;- <span class="kw">myfunction</span>(f, p){ 
  <span class="co">#  stuff</span>
  o &lt;- <span class="kw">optim</span>(f, p)
  <span class="co">#  stuff</span>
}</code></pre>
<p>calling an existing library function like <code>optim</code> that has a whole host of very useful optional arguments that have a significant impact on how the algorithm functions. Whenever you a rich function like <code>optim</code>, please have the courtesy to make it’s arguments available to future users and developers through your function call. Yes, most users will just want the default arguments, (or your default arguments, if different), and that can be handled just fine by providing default values as optional arguments. R has a fantastic mechanism for this exact issue: the <code>...</code> argument. The above code could be fixed simply by using:</p>
<pre class="sourceCode r"><code class="sourceCode r">f &lt;- <span class="kw">myfunction</span>(f, p, ...){ 
  <span class="co">#  stuff</span>
  o &lt;- <span class="kw">optim</span>(f, p, ...)
  <span class="co">#  stuff</span>
}</code></pre>
<p>which works just they way you think it would. If you have more than one such function (ask yourself if you can write shorter functions first and then) pass optional arguments as lists,</p>
<pre class="sourceCode r"><code class="sourceCode r">f &lt;- <span class="kw">myfunction</span>(f, p, optim_options, fn2_options){
  <span class="co"># stuff</span>
  o &lt;- <span class="kw">do.call</span>(optim, <span class="kw">as.list</span>(<span class="kw">c</span>(f, p, optim_options)))
  <span class="co"># stuff</span>
  b &lt;- <span class="kw">do.call</span>(fn2, fn2_options)
  <span class="co"># stuff </span>
}</code></pre>
<p>arguments can also be extracted with <code>list(...)$arg1</code> etc.</p>
<p>A converse of this issue is not providing default arguments where it might be natural to do so. This does not bother me so much, as it is probably useful to force the user to think how many iterations <code>n</code> are appropriate for their problem rather than just assuming that <code>100</code> is good because it is the default. The only time this case is annoying is when the argument will not be changing – such as a user’s authentication token to access a web resource. Don’t make me manually pass the token to every function in the library please.</p>
<h3 id="development-site-and-bug-tracker">Development site and bug tracker</h3>
<p>I would really like to see a link to the software development page, such as r-forge or Github. The primary asset in this context is pointing reviewers to an address with a bug tracking system where issues can be assigned ticket numbers and readers can transparently see if a package is being actively maintained. A reader who comes across the paper years later who has only an email address that may or may not work has little way to determine what the latest version of the code is, whether it is actively maintained, or whether earlier versions that may have been in used in previous publications suffered from any significant bugs.</p>
<h3 id="cite-your-dependencies">Cite your dependencies!</h3>
<p>We write software papers with the sometimes vain hope that they will be cited by users, so authors of such papers should at least follow these best practices themselves. R includes a native mechanism for providing citations to packages, <code>citation(packagename)</code>, including the information for any software paper published along with it. Be sure to add your own software papers to the <code>CITATION</code> file. More information can be found in my post on <a href="http://purl.org/cboettig/2012/03/20/citing-r-packages.html">Citing R packages</a>.</p>
<h2 id="major-revisions">“Major Revisions”</h2>
<p>These are other things that commonly frustrate me, but fall on a bit more of a continuum of style rather than gross oversights. As such I’m not sure that any one of these things would justify rejection.</p>
<h3 id="functionalize-the-code">Functionalize the code</h3>
<p>Style guides will tell you to keep functions short, not more than a screen or 20 lines. Breaking large functions into a series of smaller functions and documenting those smaller functions – even if they are only used internally – is a great help to a reviewer trying to understand what a function is supposed to do and also test that it does what it says. Anyone building the code base later (most often yourself) will appreciate the reusable modules.</p>
<h3 id="stable-clean-and-complete-return-objects">Stable, clean, and complete return objects</h3>
<p>An extension of providing optional arguments to functions is to also provide access to all of their return information. To extend the example from wrapping <code>optim</code>, this would involve returning the convergence information. Using object classes and helper functions for return objects helps keep code stable and lets users leverage existing code for similar objects, such as fitting or plotting routines. More discussion on this topic based on my own experiences in the post, <a href="http://carlboettiger.info/2013/04/23/we-need-more-object-oriented-design-in-comparative-methods.html#comment-878249659">we need more object oriented design in comparative methods</a></p>
<h3 id="state-a-license">State a license</h3>
<p>Because CRAN requires this through the DESCRIPTION file, R package authors rarely neglect this entirely. A sometimes misconception is that because R itself is primarily dual-licensed under GPL-2 and GPL-3 that R packages must use a GPL license due to the “viral” clause of the GPL. This clause only applies if you are modifying existing GPL functions directly and is not a requirement for R packages, which recognize a large array of licenses. My own recommendation for authors seeking to maximize the impact of their work is to use MIT, BSD (2 clause), or CC0 license for the package. CC0 has the advantage of being suitable for and data or documentation included, but authors should do there homework and decide what is best for them.</p>
<h2 id="minor-revisions">“Minor Revisions”</h2>
<p>Consistent use of coding style, good documentation, clear examples, intelligent reuse of code, and other best practices are all areas in which any work could improve. While we can all become better developers by highlighting these issues in our reviews, they are probably best developed over time and in dialog with the user community. I also put anything extending the scope of functionality into this category – I do not have any concept of minimal contribution as long as the code meets the criteria above. Meanwhile, there’s always a few pet peeves I just cannot help mentioning. Here’s one which is particular to R packages and so commonly overlooked.</p>
<h3 id="imports-not-depends">IMPORTS not DEPENDS</h3>
<p>Many developers overlook that package dependencies that provide functions your functions will use internally should be listed as under IMPORTS rather than DEPENDS. This keeps the users namespace cleaner and avoids collisions of functions having the same name. Use DEPENDS only for those packages whose functions will be used by the end user as well.</p>
<hr />
<p>If you are an author, editor, or reviewer of R software packages, what are your pet peeves?</p>
 
<!-- not that raw_content depends on custom generator, 
     see _plugins/jekyll-labnotebook-plugins/raw_content --> 
</article> 
<p> <a href="/2013/06/13/what-I-look-for-in-software-papers.html"> <em>Read more</em></a> </p>
<br />
<br />


        </div>
      
        <div class="span3">
          <header><h4><a href="/2013/06/10/mansucript-reviews-on-github.html">manuscript reviews on github?</a></h4></header>
<p><span>examples and questions</span></p>
<p style="font-style:italic"> 10 Jun 2013</p>

<p style="font-style:italic"> pageviews: 214 </p>

<article>
<div class="excerpt">
<p>I was recently impressed to learn of Trevor Bedford’s strategy of seeking <a href="https://twitter.com/trvrb/status/334310856982671361">pre-approval</a> for posting his reviewer’s comments as Github issues. Beyond providing links to the data and source-code, I generally don’t advertise the open science nature of papers I submit – I guess I assume that if the reader or reviewers care, it should be easy enough for them to discover it. Consequently I am usually immediately frustrated to realize that upon receiving my reviews I have to create a second, private repository for the review material, our replies to reviewers, etc., as I don’t have permission to disclose that information. <sup><a href="#fn1" class="footnoteRef" id="fnref1">1</a></sup> I have recently stumbled across <a href="http://www.steinsaltz.me.uk/pnas.html">several</a> <a href="http://theseamonster.net/2013/05/are-unreasonably-harsh-reviewers-retarding-the-pace-of-coral-reef-science/">examples</a> of authors publishing to the web anonymous reviews they have received. Though anonymous, I feel the practice potentially murky without explicit permission, so I would appreciate any insight others have on this.</p>
<h3 id="asking-permission">Asking permission</h3>
<p>Trevor’s approach suggests I should consider broaching this question when first submitting my review, so I am puzzling over the best way to do so. One option would be to include such a request in the cover letter. For example,</p>
<blockquote>
<p>The authors of this manuscript would like to request that the editor and reviewers indicate in their replies if they consent or decline to have their comments posted anonymously in the public <a href="#">Issues Tracker</a> of this paper.</p>
</blockquote>
<p>Does that need more explanation? A link to examples like <a href="https://github.com/trvrb/flux/issues?labels=reviewer+1">Trevor’s</a> that have done this before? Do I need to explain the value of having this kind of transparent provenance for the paper? Should I mention how this could give the reviewer more transparent credit? Encourage them to comment directly on Github from their own account?</p>
<p>Does this need the blessing of the journal? How would you feel about such a clause as a reviewer or editor? For a recent review I had done of a paper that was similarly written on Github, I obtained the Journal’s permission to post my review as an <a href="https://github.com/weecology/data-sharing-paper/issues/71">issue</a> in their repository. I would love to see more examples of this kind of thing, if anyone has come across them.</p>
<h2 id="cover-letters-for-open-science-manuscripts">Cover letters for open science manuscripts?</h2>
<p>While I lean towards a minimal statement such as the one above, perhaps a cover letter would be a good place to document some of the other open and reproducible features of the manuscript? Or perhaps such statements should be added to the manuscript itself? Among the options, I might point out:</p>
<ol type="1">
<li>The manuscript has been written on Github. Consequently the full drafting and <strong>revision history</strong> is available, along with graphs of author contributions (which omit authors without Github accounts and may be distorted by trivial line changes)</li>
<li>The manuscript has been written with all the code necessary to repoduce the results embedded as a <a href="http://yihui.name/knitr">knitr</a> <strong>dynamic document</strong>. This helps ensure the analysis is always in synch with the results presented in the manuscript and the that the research is reproducible. The analysis, figures, and manuscript can be reassembled from scratch by typing <code>make pdf</code> in the repository directory.<br /></li>
<li><strong>Code</strong> to replicate the analysis and produce each of the figures shown can be found at: (Version-stable lnk to the appropriate Github pages? Deposit in Figshare/Dryad first?)<br /></li>
<li><strong>Data</strong> to replicate the analysis and data shown in each of the figures can be found at: (Easiest to link to Github, since the code and data already reside there.<br /><em>Alternatively I could deposit these in <a href="http://figshare.com">Figshare</a> or <a href="http://datadryad.org">Dryad</a> first…)</em></li>
<li>The manuscript, code, data, and documentation are available <strong>as an R package in the Github repository</strong>.<br /></li>
<li>The <strong>issues tracker</strong> associated with the manuscript’s repository provides a record of this research, including lines of investigation that were resolved into the results presented here, lines that were closed as dead-ends or null results, and outstanding issues for further investigation.<br /></li>
<li>The <strong>daily lab notebook entries</strong> accompanying this research can be found under the <a href="/tags">project-tag</a> between dates of XX and XX.</li>
</ol>
<p>Listing all of these would make for a somewhat lengthy cover letter, which might be a bit overwhelming to be useful (or seem more promotional than valuable). Are any of the seven things above worth highlighting in particular?</p>
<p>Perhaps these details could be deferred to a README file in the project’s Github repo, and the cover letter could simply provide a link to the project repository? What, if anything, would appear most useful and accessible to a reviewer unfamiliar with this approach or its potential value? Though elements of this approach have been discussed in the published literature, e.g. <span class="showtooltip" title="Gentleman R and Temple Lang D (2007). Statistical Analyses And
Reproducible Research. _Journal of Computational And Graphical
Statistics_, *16*. ISSN 1061-8600, 
http://dx.doi.org/10.1198/106186007X178663."><a href="http://dx.doi.org/10.1198/106186007X178663" rel="http://purl.org/spar/cito/citesAsEvidence" >Gentleman &amp; Temple Lang (2007)</a></span> ‘compendium’ concept, <span class="showtooltip" title="Stodden V (2009). Enabling Reproducible Research: Open Licensing
for Scientific Innovation. 
http://papers.ssrn.com/sol3/papers.cfm?abstract_id=1362040. 
http://papers.ssrn.com/sol3/papers.cfm?abstract_id=1362040."><a href="http://papers.ssrn.com/sol3/papers.cfm?abstract_id=1362040" rel="http://purl.org/spar/cito/citesAsEvidence" >Stodden (2009)</a></span> RRS concept, or <span class="showtooltip" title="Peng R (2011). Reproducible Research in Computational Science.
_Science_, *334*. ISSN 0036-8075, 
http://dx.doi.org/10.1126/science.1213847."><a href="http://dx.doi.org/10.1126/science.1213847" rel="http://purl.org/spar/cito/citesAsEvidence" >Peng (2011)</a></span> reproducible papers in the Journal of Biostatistics, I’m unsure if pointing a reviewer to these references would be more valuable or more confusing. Let me know what you think.</p>
<h2 id="references">References</h2>
<ul>
<li>Robert Gentleman, Duncan Temple Lang, (2007) Statistical Analyses And Reproducible Research. <em>Journal of Computational And Graphical Statistics</em> <strong>16</strong> <a href="http://dx.doi.org/10.1198/106186007X178663">10.1198/106186007X178663</a></li>
<li>R. D. Peng, (2011) Reproducible Research in Computational Science. <em>Science</em> <strong>334</strong> <a href="http://dx.doi.org/10.1126/science.1213847">10.1126/science.1213847</a></li>
<li>Victoria Stodden, (2009) Enabling Reproducible Research: Open Licensing for Scientific Innovation. <a href="http://papers.ssrn.com/sol3/papers.cfm?abstract_id=1362040">http://papers.ssrn.com/sol3/papers.cfm?abstract_id=1362040</a></li>
</ul>
<section class="footnotes">
<hr />
<ol>
<li id="fn1"><p>Strictly speaking the edits to the manuscript in the open repository could also be considered confidential, though at that stage I haven’t yet signed the copyright agreements that come with publication, which tend to be quite reasonable even for the traditional subscription based journals I work with<a href="#fnref1">↩</a></p></li>
</ol>
</section>
 
<!-- not that raw_content depends on custom generator, 
     see _plugins/jekyll-labnotebook-plugins/raw_content --> 
</article> 
<p> <a href="/2013/06/10/mansucript-reviews-on-github.html"> <em>Read more</em></a> </p>
<br />
<br />


        </div>
      
        <div class="span3">
          <header><h4><a href="/2013/06/05/semi-analytic-posteriors.html">Semi Analytic Posteriors</a></h4></header>
<p><span></span></p>
<p style="font-style:italic"> 05 Jun 2013</p>

<p style="font-style:italic"> pageviews: 19 </p>

<article>
<div class="excerpt">
<p>The difficulty in comparing the nonparametric Bayesian inference against parametric Bayesian inference is ensuring that the poorer performance of the latter is not do to numerical limitations of the MCMC (no one is quite so worried about the cases where the mcmc solution appears to work well…) Convergence is almost impossible to truly establish, and lots of pathologies (correlations between variables, particularly without simulataneous updating) can frustrate it considerably. While multiple chains and long run times are the reasonable default, for simple enough models we can take a more direct approach.</p>
<ul>
<li>Script matches commit <a href="https://github.com/cboettig/nonparametric-bayes/blob/26d84c5c147d853a075dc5b1c1be593a38d04f10/inst/examples/semi-analytic-posteriors.md">26d84c/semi-analytic-posteriors.md</a></li>
</ul>
<h3 id="generating-model-and-parameters">Generating Model and parameters</h3>
<p>Ricker model, parameterized as</p>
<p><span class="math">\[X_{t+1} = X_t r e^{-\beta X_t + \sigma Z_t}\]</span></p>
<p>for random unit normal <span class="math">\(Z_t\)</span></p>
<pre class="sourceCode r"><code class="sourceCode r">f &lt;- function(x,h,p)  x * p[<span class="dv">1</span>] * <span class="kw">exp</span>(-x * p[<span class="dv">2</span>]) 
p &lt;- <span class="kw">c</span>(<span class="kw">exp</span>(<span class="dv">1</span>), <span class="dv">1</span>/<span class="dv">10</span>)
K &lt;- <span class="dv">10</span>  <span class="co"># approx, a li&#39;l&#39; less</span>
Xo &lt;- <span class="dv">1</span> <span class="co"># approx, a li&#39;l&#39; less</span></code></pre>
<pre class="sourceCode r"><code class="sourceCode r">sigma_g &lt;- <span class="fl">0.1</span>
z_g &lt;- function() <span class="kw">rlnorm</span>(<span class="dv">1</span>,<span class="dv">0</span>, sigma_g)
x_grid &lt;- <span class="kw">seq</span>(<span class="dv">0</span>, <span class="fl">1.5</span> * K, <span class="dt">length=</span><span class="dv">50</span>)
N &lt;- <span class="dv">40</span>
<span class="kw">set.seed</span>(<span class="dv">123</span>)</code></pre>
<h3 id="sample-data">Sample Data</h3>
<pre class="sourceCode r"><code class="sourceCode r">x &lt;- <span class="kw">numeric</span>(N)
x[<span class="dv">1</span>] &lt;- Xo
for(t in <span class="dv">1</span>:(N<span class="dv">-1</span>))
  x[t<span class="dv">+1</span>] = <span class="kw">z_g</span>() * <span class="kw">f</span>(x[t], <span class="dt">h=</span><span class="dv">0</span>, <span class="dt">p=</span>p)
<span class="kw">qplot</span>(<span class="dv">1</span>:N, x)</code></pre>
<figure>
<img src="http://farm9.staticflickr.com/8279/8962756154_f2a4fa4257_o.png" />
</figure>
<h2 id="compute-the-posterior-after-marginalizing-over-r-and-sigma-parameters">Compute the posterior after marginalizing over <span class="math">\(r\)</span> and <span class="math">\(\sigma\)</span> parameters:</h2>
<p><span class="math">\[P(\beta | X) \]</span></p>
<pre class="sourceCode r"><code class="sourceCode r">Mt &lt;- function(t, beta) <span class="kw">log</span>(x[t<span class="dv">+1</span>]) - <span class="kw">log</span>(x[t]) + beta * x[t]
beta_grid = <span class="kw">seq</span>(<span class="fl">1e-5</span>, <span class="dv">2</span>, <span class="dt">by=</span><span class="fl">1e-3</span>)

P_B.X &lt;- <span class="kw">sapply</span>(beta_grid, function(beta){
  Mt_vec = <span class="kw">sapply</span>(<span class="dv">1</span>:(N<span class="dv">-1</span>), Mt, beta)
  sum_of_squares &lt;- <span class="kw">sum</span>(Mt_vec^<span class="dv">2</span>)
  square_of_sums &lt;- <span class="kw">sum</span>(Mt_vec)^<span class="dv">2</span>
  <span class="fl">0.5</span> ^ (N/<span class="dv">2-1</span>) * (sum_of_squares - square_of_sums/(N<span class="dv">-1</span>)) ^ (N/<span class="dv">2-1</span>) / <span class="kw">gamma</span>(N/<span class="dv">2-1</span>)
  })

<span class="kw">qplot</span>(beta_grid, -<span class="kw">log</span>(P_B.X))</code></pre>
<figure>
<img src="http://farm4.staticflickr.com/3800/8962756744_a8e8471f32_o.png" />
</figure>
<p>Posterior mode is at:</p>
<pre class="sourceCode r"><code class="sourceCode r">beta_grid[<span class="kw">which.min</span>(P_B.X)]</code></pre>
<pre><code>[1] 0.09801</code></pre>
<p>Estimating the Myers model on this data:</p>
<p><span class="math">\[X_{t+1} = Z_t \frac{r X_t^{\theta}}{1 + X_t^{\theta} / K}\]</span></p>
<p>With <span class="math">\(Z_t\)</span> lognormal, unit mean, std <span class="math">\(\sigma\)</span>.</p>
<p>Marginal distribution over the remaining parameters is a 2D grid:</p>
<pre class="sourceCode r"><code class="sourceCode r">Mt &lt;- function(t, theta, K) <span class="kw">log</span>(x[t<span class="dv">+1</span>]) - theta * <span class="kw">log</span>(x[t]) + <span class="kw">log</span>(<span class="dv">1</span> + x[t] ^ theta / K) 
theta_grid = <span class="kw">seq</span>(<span class="fl">1e-5</span>, <span class="dv">5</span>, <span class="dt">length=</span><span class="dv">100</span>)
K_grid = <span class="kw">seq</span>(<span class="fl">1e-5</span>, <span class="dv">30</span>, <span class="dt">length=</span><span class="dv">100</span>)

prob &lt;- function(theta, K){
  Mt_vec = <span class="kw">sapply</span>(<span class="dv">1</span>:(N<span class="dv">-1</span>), Mt, theta, K)
  sum_of_squares &lt;- <span class="kw">sum</span>(Mt_vec^<span class="dv">2</span>)
  square_of_sums &lt;- <span class="kw">sum</span>(Mt_vec)^<span class="dv">2</span>
  <span class="fl">0.5</span> ^ (N/<span class="dv">2-1</span>) * (sum_of_squares - square_of_sums/(N<span class="dv">-1</span>)) ^ (N/<span class="dv">2-1</span>) / <span class="kw">gamma</span>(N/<span class="dv">2-1</span>)
}



P_theta_K.X &lt;- <span class="kw">sapply</span>(theta_grid, function(theta)
                <span class="kw">sapply</span>(K_grid, function(k) <span class="kw">prob</span>(theta, k)))


<span class="kw">require</span>(reshape2)</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">df = <span class="kw">melt</span>(P_theta_K.X)
<span class="kw">names</span>(df) = <span class="kw">c</span>(<span class="st">&quot;theta&quot;</span>, <span class="st">&quot;K&quot;</span>, <span class="st">&quot;lik&quot;</span>)
<span class="kw">ggplot</span>(df, <span class="kw">aes</span>(theta_grid[theta], K_grid[K], <span class="dt">z=</span>-<span class="kw">log</span>(lik))) + <span class="kw">stat_contour</span>(<span class="kw">aes</span>(<span class="dt">color=</span>..level..), <span class="dt">binwidth=</span><span class="dv">3</span>)</code></pre>
<figure>
<img src="http://farm3.staticflickr.com/2806/8961561559_66a72a0ecc_o.png" />
</figure>
 
<!-- not that raw_content depends on custom generator, 
     see _plugins/jekyll-labnotebook-plugins/raw_content --> 
</article> 
<p> <a href="/2013/06/05/semi-analytic-posteriors.html"> <em>Read more</em></a> </p>
<br />
<br />


        </div>
      
    </div>

    <div class="row">
      
        <div class="span3">
          <header><h4><a href="/2013/06/04/sensitivity-of-gp-comparisons-in-further-examples.html">Sensitivity Of Gp Comparisons In Further Examples</a></h4></header>
<p><span></span></p>
<p style="font-style:italic"> 04 Jun 2013</p>

<p style="font-style:italic"> pageviews: (not calculated) </p>

<article>
<div class="excerpt">
<h1 id="comparison-of-nonparametric-bayesian-gaussian-process-estimates-to-standard-the-parametric-bayesian-approach">Comparison of Nonparametric Bayesian Gaussian Process estimates to standard the Parametric Bayesian approach</h1>
<p>Plotting and knitr options, (can generally be ignored)</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">require</span>(modeest)
posterior.mode &lt;- function(x) {
  <span class="kw">mlv</span>(x, <span class="dt">method=</span><span class="st">&quot;shorth&quot;</span>)$M
}</code></pre>
<h3 id="model-and-parameters">Model and parameters</h3>
<p>Uses the model derived in <code>citet(&quot;10.1080/10236190412331335373&quot;)</code>, of a Ricker-like growth curve with an allee effect, defined in the pdgControl package,</p>
<pre class="sourceCode r"><code class="sourceCode r">f &lt;- RickerAllee
p &lt;- <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">8</span>, <span class="dv">5</span>)
K &lt;- <span class="dv">10</span>  <span class="co"># approx, a li&#39;l&#39; less</span>
allee &lt;- <span class="dv">5</span> <span class="co"># approx, a li&#39;l&#39; less</span></code></pre>
<p>Various parameters defining noise dynamics, grid, and policy costs.</p>
<pre class="sourceCode r"><code class="sourceCode r">sigma_g &lt;- <span class="fl">0.05</span>
sigma_m &lt;- <span class="fl">0.0</span>
z_g &lt;- function() <span class="kw">rlnorm</span>(<span class="dv">1</span>, <span class="dv">0</span>, sigma_g)
z_m &lt;- function() <span class="dv">1</span>+(<span class="dv">2</span>*<span class="kw">runif</span>(<span class="dv">1</span>, <span class="dv">0</span>,  <span class="dv">1</span>)-<span class="dv">1</span>) * sigma_m
x_grid &lt;- <span class="kw">seq</span>(<span class="dv">0</span>, <span class="fl">1.5</span> * K, <span class="dt">length=</span><span class="dv">50</span>)
h_grid &lt;- x_grid
profit &lt;- function(x,h) <span class="kw">pmin</span>(x, h)
delta &lt;- <span class="fl">0.01</span>
OptTime &lt;- <span class="dv">50</span>  <span class="co"># stationarity with unstable models is tricky thing</span>
reward &lt;- <span class="dv">0</span>
xT &lt;- <span class="dv">0</span>
Xo &lt;-  allee<span class="fl">+.5</span><span class="co"># observations start from</span>
x0 &lt;- K <span class="co"># simulation under policy starts from</span>
Tobs &lt;- <span class="dv">40</span></code></pre>
<h3 id="sample-data">Sample Data</h3>
<pre class="sourceCode r"><code class="sourceCode r">  <span class="kw">set.seed</span>(<span class="dv">1234</span>)
  <span class="co">#harvest &lt;- sort(rep(seq(0, .5, length=7), 5))</span>
  x &lt;- <span class="kw">numeric</span>(Tobs)
  x[<span class="dv">1</span>] &lt;- Xo
  nz &lt;- <span class="dv">1</span>
  for(t in <span class="dv">1</span>:(Tobs<span class="dv">-1</span>))
    x[t<span class="dv">+1</span>] = <span class="kw">z_g</span>() * <span class="kw">f</span>(x[t], <span class="dt">h=</span><span class="dv">0</span>, <span class="dt">p=</span>p)
  obs &lt;- <span class="kw">data.frame</span>(<span class="dt">x =</span> <span class="kw">c</span>(<span class="kw">rep</span>(<span class="dv">0</span>,nz), 
                          <span class="kw">pmax</span>(<span class="kw">rep</span>(<span class="dv">0</span>,Tobs<span class="dv">-1</span>), x[<span class="dv">1</span>:(Tobs<span class="dv">-1</span>)])), 
                    <span class="dt">y =</span> <span class="kw">c</span>(<span class="kw">rep</span>(<span class="dv">0</span>,nz), 
                          x[<span class="dv">2</span>:Tobs]))
raw_plot &lt;- <span class="kw">ggplot</span>(<span class="kw">data.frame</span>(<span class="dt">time =</span> <span class="dv">1</span>:Tobs, <span class="dt">x=</span>x), <span class="kw">aes</span>(time,x)) + <span class="kw">geom_line</span>()
raw_plot</code></pre>
<figure>
<img src="http://farm8.staticflickr.com/7406/8954616307_5e7a9d3e27_o.png" alt="plot of chunk obs" /><figcaption>plot of chunk obs</figcaption>
</figure>
<h2 id="maximum-likelihood">Maximum Likelihood</h2>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">12345</span>)
estf &lt;- function(p){ 
    mu &lt;- <span class="kw">f</span>(obs$x,<span class="dv">0</span>,p)
    -<span class="kw">sum</span>(<span class="kw">dlnorm</span>(obs$y, <span class="kw">log</span>(mu), p[<span class="dv">4</span>]), <span class="dt">log=</span><span class="ot">TRUE</span>)
}
par &lt;- <span class="kw">c</span>(p[<span class="dv">1</span>]*<span class="kw">rlnorm</span>(<span class="dv">1</span>,<span class="dv">0</span>,.<span class="dv">4</span>), 
         p[<span class="dv">2</span>]*<span class="kw">rlnorm</span>(<span class="dv">1</span>,<span class="dv">0</span>,.<span class="dv">3</span>), 
         p[<span class="dv">3</span>]*<span class="kw">rlnorm</span>(<span class="dv">1</span>,<span class="dv">0</span>, .<span class="dv">3</span>), 
         sigma_g * <span class="kw">rlnorm</span>(<span class="dv">1</span>,<span class="dv">0</span>,.<span class="dv">3</span>))
o &lt;- <span class="kw">optim</span>(par, estf, <span class="dt">method=</span><span class="st">&quot;L&quot;</span>, <span class="dt">lower=</span><span class="kw">c</span>(<span class="fl">1e-5</span>,<span class="fl">1e-5</span>,<span class="fl">1e-5</span>,<span class="fl">1e-5</span>))
f_alt &lt;- f
p_alt &lt;- <span class="kw">c</span>(<span class="kw">as.numeric</span>(o$par[<span class="dv">1</span>]), <span class="kw">as.numeric</span>(o$par[<span class="dv">2</span>]), <span class="kw">as.numeric</span>(o$par[<span class="dv">3</span>]))
sigma_g_alt &lt;- <span class="kw">as.numeric</span>(o$par[<span class="dv">4</span>])

est &lt;- <span class="kw">list</span>(<span class="dt">f =</span> f_alt, <span class="dt">p =</span> p_alt, <span class="dt">sigma_g =</span> sigma_g_alt, <span class="dt">mloglik=</span>o$value)</code></pre>
<p>Mean predictions</p>
<pre class="sourceCode r"><code class="sourceCode r">true_means &lt;- <span class="kw">sapply</span>(x_grid, f, <span class="dv">0</span>, p)
est_means &lt;- <span class="kw">sapply</span>(x_grid, est$f, <span class="dv">0</span>, est$p)</code></pre>
<h2 id="non-parametric-bayes">Non-parametric Bayes</h2>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co">#inv gamma has mean b / (a - 1) (assuming a&gt;1) and variance b ^ 2 / ((a - 2) * (a - 1) ^ 2) (assuming a&gt;2)</span>
s2.p &lt;- <span class="kw">c</span>(<span class="dv">5</span>,<span class="dv">5</span>)  
d.p = <span class="kw">c</span>(<span class="dv">10</span>, <span class="dv">1</span>/<span class="fl">0.1</span>)</code></pre>
<p>Estimate the Gaussian Process (nonparametric Bayesian fit)</p>
<pre class="sourceCode r"><code class="sourceCode r">gp &lt;- <span class="kw">gp_mcmc</span>(obs$x, <span class="dt">y=</span>obs$y, <span class="dt">n=</span><span class="fl">1e5</span>, <span class="dt">s2.p =</span> s2.p, <span class="dt">d.p =</span> d.p)
gp_dat &lt;- <span class="kw">gp_predict</span>(gp, x_grid, <span class="dt">burnin=</span><span class="fl">1e4</span>, <span class="dt">thin=</span><span class="dv">300</span>)</code></pre>
<p>Show traces and posteriors against priors</p>
<pre class="sourceCode r"><code class="sourceCode r">plots &lt;- <span class="kw">summary_gp_mcmc</span>(gp, <span class="dt">burnin=</span><span class="fl">1e4</span>, <span class="dt">thin=</span><span class="dv">300</span>)</code></pre>
<p><img src="figure/process-noise-only-gp_traces_densities1.png" alt="plot of chunk gp_traces_densities" /> <img src="http://farm4.staticflickr.com/3687/8954616527_4c7cefe499_o.png" alt="plot of chunk gp_traces_densities" /></p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Summarize the GP model</span>
tgp_dat &lt;- 
    <span class="kw">data.frame</span>(  <span class="dt">x =</span> x_grid, 
                 <span class="dt">y =</span> gp_dat$E_Ef, 
                 <span class="dt">ymin =</span> gp_dat$E_Ef - <span class="dv">2</span> * <span class="kw">sqrt</span>(gp_dat$E_Vf), 
                 <span class="dt">ymax =</span> gp_dat$E_Ef + <span class="dv">2</span> * <span class="kw">sqrt</span>(gp_dat$E_Vf) )</code></pre>
<h2 id="parametric-bayesian-models">Parametric Bayesian Models</h2>
<p>We use the JAGS Gibbs sampler, a recent open source BUGS implementation with an R interface that works on most platforms. We initialize the usual MCMC parameters; see <code>?jags</code> for details.</p>
<p>All parametric Bayesian estimates use the following basic parameters for the JAGS MCMC:</p>
<pre class="sourceCode r"><code class="sourceCode r">y &lt;- x 
N &lt;- <span class="kw">length</span>(x);
jags.data &lt;- <span class="kw">list</span>(<span class="st">&quot;N&quot;</span>,<span class="st">&quot;y&quot;</span>)
n.chains &lt;- <span class="dv">6</span>
n.iter &lt;- <span class="fl">1e6</span>
n.burnin &lt;- <span class="kw">floor</span>(<span class="dv">10000</span>)
n.thin &lt;- <span class="kw">max</span>(<span class="dv">1</span>, <span class="kw">floor</span>(n.chains * (n.iter - n.burnin)/<span class="dv">1000</span>))
n.update &lt;- <span class="dv">10</span></code></pre>
<p>We will use the same priors for process and observation noise in each model,</p>
<pre class="sourceCode r"><code class="sourceCode r">stdQ_prior_p &lt;- <span class="kw">c</span>(<span class="fl">1e-6</span>, <span class="dv">100</span>)
stdR_prior_p &lt;- <span class="kw">c</span>(<span class="fl">1e-6</span>, .<span class="dv">1</span>)
stdQ_prior  &lt;- function(x) <span class="kw">dunif</span>(x, stdQ_prior_p[<span class="dv">1</span>], stdQ_prior_p[<span class="dv">2</span>])
stdR_prior  &lt;- function(x) <span class="kw">dunif</span>(x, stdR_prior_p[<span class="dv">1</span>], stdR_prior_p[<span class="dv">2</span>])</code></pre>
<h3 id="parametric-bayes-of-correct-allen-model">Parametric Bayes of correct (Allen) model</h3>
<p>We initiate the MCMC chain (<code>init_p</code>) using the true values of the parameters <code>p</code> from the simulation. While impossible in real data, this gives the parametric Bayesian approach the best chance at succeeding. <code>y</code> is the timeseries (recall <code>obs</code> has the <span class="math">\(x_t\)</span>, <span class="math">\(x_{t+1}\)</span> pairs)</p>
<p>The actual model is defined in a <code>model.file</code> that contains an R function that is automatically translated into BUGS code by <em>R2WinBUGS</em>. The file defines the priors and the model. We write the file from R as follows:</p>
<pre class="sourceCode r"><code class="sourceCode r">K_prior_p &lt;- <span class="kw">c</span>(<span class="fl">0.01</span>, <span class="fl">40.0</span>)
logr0_prior_p &lt;- <span class="kw">c</span>(-<span class="fl">6.0</span>, <span class="fl">6.0</span>)
logtheta_prior_p &lt;- <span class="kw">c</span>(-<span class="fl">6.0</span>, <span class="fl">6.0</span>)

bugs.model &lt;- 
<span class="kw">paste</span>(<span class="kw">sprintf</span>(
<span class="st">&quot;model{</span>
<span class="st">  K     ~ dunif(%s, %s)</span>
<span class="st">  logr0    ~ dunif(%s, %s)</span>
<span class="st">  logtheta ~ dunif(%s, %s)</span>
<span class="st">  stdQ ~ dunif(%s, %s)&quot;</span>, 
  K_prior_p[<span class="dv">1</span>], K_prior_p[<span class="dv">2</span>],
  logr0_prior_p[<span class="dv">1</span>], logr0_prior_p[<span class="dv">2</span>],
  logtheta_prior_p[<span class="dv">1</span>], logtheta_prior_p[<span class="dv">2</span>],
  stdQ_prior_p[<span class="dv">1</span>], stdQ_prior_p[<span class="dv">2</span>]),

  <span class="st">&quot;</span>
<span class="st">  iQ &lt;- 1 / (stdQ * stdQ);</span>
<span class="st">  r0 &lt;- exp(logr0)</span>
<span class="st">  theta &lt;- exp(logtheta)</span>
<span class="st">  y[1] ~ dunif(0, 10)</span>
<span class="st">  for(t in 1:(N-1)){</span>
<span class="st">    mu[t] &lt;- y[t] * exp(r0 * (1 - y[t]/K)* (y[t] - theta) / K )</span>
<span class="st">    y[t+1] ~ dnorm(mu[t], iQ) </span>
<span class="st">  }</span>
<span class="st">}&quot;</span>)
<span class="kw">writeLines</span>(bugs.model, <span class="st">&quot;allen_process.bugs&quot;</span>)</code></pre>
<p>Write the priors into a list for later reference</p>
<pre class="sourceCode r"><code class="sourceCode r">K_prior     &lt;- function(x) <span class="kw">dunif</span>(x, K_prior_p[<span class="dv">1</span>], K_prior_p[<span class="dv">2</span>])
logr0_prior &lt;- function(x) <span class="kw">dunif</span>(x, logr0_prior_p[<span class="dv">1</span>], logr0_prior_p[<span class="dv">2</span>])
logtheta_prior &lt;- function(x) <span class="kw">dunif</span>(x, logtheta_prior_p[<span class="dv">1</span>], logtheta_prior_p[<span class="dv">2</span>])
par_priors  &lt;- <span class="kw">list</span>(<span class="dt">K =</span> K_prior, <span class="dt">deviance =</span> function(x) <span class="dv">0</span> * x, 
                    <span class="dt">logr0 =</span> logr0_prior, <span class="dt">logtheta =</span> logtheta_prior,
                    <span class="dt">stdQ =</span> stdQ_prior)</code></pre>
<p>We define which parameters to keep track of, and set the initial values of parameters in the transformed space used by the MCMC. We use logarithms to maintain strictly positive values of parameters where appropriate.</p>
<pre class="sourceCode r"><code class="sourceCode r">jags.params=<span class="kw">c</span>(<span class="st">&quot;K&quot;</span>,<span class="st">&quot;logr0&quot;</span>,<span class="st">&quot;logtheta&quot;</span>,<span class="st">&quot;stdQ&quot;</span>) <span class="co"># be sensible about the order here</span>
jags.inits &lt;- function(){
  <span class="kw">list</span>(<span class="st">&quot;K&quot;</span>= <span class="dv">8</span> * <span class="kw">rlnorm</span>(<span class="dv">1</span>,<span class="dv">0</span>, <span class="fl">0.1</span>),
       <span class="st">&quot;logr0&quot;</span>=<span class="kw">log</span>(<span class="dv">2</span> * <span class="kw">rlnorm</span>(<span class="dv">1</span>,<span class="dv">0</span>, <span class="fl">0.1</span>) ),
       <span class="st">&quot;logtheta&quot;</span>=<span class="kw">log</span>(  <span class="dv">5</span> * <span class="kw">rlnorm</span>(<span class="dv">1</span>,<span class="dv">0</span>, <span class="fl">0.1</span>) ), 
       <span class="st">&quot;stdQ&quot;</span>= <span class="kw">abs</span>( <span class="fl">0.1</span> * <span class="kw">rlnorm</span>(<span class="dv">1</span>,<span class="dv">0</span>, <span class="fl">0.1</span>)),
       <span class="dt">.RNG.name=</span><span class="st">&quot;base::Wichmann-Hill&quot;</span>, <span class="dt">.RNG.seed=</span><span class="dv">123</span>)
}

<span class="kw">set.seed</span>(<span class="dv">1234</span>)
<span class="co"># parallel refuses to take variables as arguments (e.g. n.iter = 1e5 works, but n.iter = n doesn&#39;t)</span>
allen_jags &lt;- <span class="kw">do.call</span>(jags.parallel, <span class="kw">list</span>(<span class="dt">data=</span>jags.data, <span class="dt">inits=</span>jags.inits, 
                                      jags.params, <span class="dt">n.chains=</span>n.chains, 
                                      <span class="dt">n.iter=</span>n.iter, <span class="dt">n.thin=</span>n.thin, 
                                      <span class="dt">n.burnin=</span>n.burnin, 
                                      <span class="dt">model.file=</span><span class="st">&quot;allen_process.bugs&quot;</span>))

<span class="co"># Run again iteratively if we haven&#39;t met the Gelman-Rubin convergence criterion</span>
<span class="kw">recompile</span>(allen_jags) <span class="co"># required for parallel</span>
allen_jags &lt;- <span class="kw">do.call</span>(autojags, <span class="kw">list</span>(<span class="dt">object=</span>allen_jags, <span class="dt">n.update=</span>n.update, 
                                     <span class="dt">n.iter=</span>n.iter, <span class="dt">n.thin =</span> n.thin))</code></pre>
<h4 id="convergence-diagnostics-for-allen-model">Convergence diagnostics for Allen model</h4>
<p>R notes: this strips classes from the <code>mcmc.list</code> object (so that we have list of matrices; objects that <code>reshape2::melt</code> can handle intelligently), and then combines chains into one array. In this array each parameter is given its value at each sample from the posterior (index) for each chain.</p>
<pre class="sourceCode r"><code class="sourceCode r">tmp &lt;- <span class="kw">lapply</span>(<span class="kw">as.mcmc</span>(allen_jags), as.matrix) <span class="co"># strip classes the hard way...</span>
allen_posteriors &lt;- <span class="kw">melt</span>(tmp, <span class="dt">id =</span> <span class="kw">colnames</span>(tmp[[<span class="dv">1</span>]])) 
<span class="kw">names</span>(allen_posteriors) = <span class="kw">c</span>(<span class="st">&quot;index&quot;</span>, <span class="st">&quot;variable&quot;</span>, <span class="st">&quot;value&quot;</span>, <span class="st">&quot;chain&quot;</span>)
<span class="kw">ggplot</span>(allen_posteriors) + <span class="kw">geom_line</span>(<span class="kw">aes</span>(index, value)) + 
  <span class="kw">facet_wrap</span>(~ variable, <span class="dt">scale=</span><span class="st">&quot;free&quot;</span>, <span class="dt">ncol=</span><span class="dv">1</span>)</code></pre>
<figure>
<img src="http://farm8.staticflickr.com/7432/8954617241_ee7c8ab2c6_o.png" alt="plot of chunk allen-traces" /><figcaption>plot of chunk allen-traces</figcaption>
</figure>
<pre class="sourceCode r"><code class="sourceCode r">allen_priors &lt;- <span class="kw">ddply</span>(allen_posteriors, <span class="st">&quot;variable&quot;</span>, function(dd){
    grid &lt;- <span class="kw">seq</span>(<span class="kw">min</span>(dd$value), <span class="kw">max</span>(dd$value), <span class="dt">length =</span> <span class="dv">100</span>) 
    <span class="kw">data.frame</span>(<span class="dt">value =</span> grid, <span class="dt">density =</span> par_priors[[dd$variable[<span class="dv">1</span>]]](grid))
})

<span class="kw">ggplot</span>(allen_posteriors, <span class="kw">aes</span>(value)) + 
  <span class="kw">stat_density</span>(<span class="dt">geom=</span><span class="st">&quot;path&quot;</span>, <span class="dt">position=</span><span class="st">&quot;identity&quot;</span>, <span class="dt">alpha=</span><span class="fl">0.7</span>) +
  <span class="kw">geom_line</span>(<span class="dt">data=</span>allen_priors, <span class="kw">aes</span>(<span class="dt">x=</span>value, <span class="dt">y=</span>density), <span class="dt">col=</span><span class="st">&quot;red&quot;</span>) + 
  <span class="kw">facet_wrap</span>(~ variable, <span class="dt">scale=</span><span class="st">&quot;free&quot;</span>, <span class="dt">ncol=</span><span class="dv">3</span>)</code></pre>
<figure>
<img src="http://farm9.staticflickr.com/8128/8954617519_134c3da154_o.png" alt="plot of chunk allen-posteriors" /><figcaption>plot of chunk allen-posteriors</figcaption>
</figure>
<p>Reshape the posterior parameter distribution data, transform back into original space, and calculate the mean parameters and mean function</p>
<pre class="sourceCode r"><code class="sourceCode r">A &lt;- allen_posteriors
A$index &lt;- A$index + A$chain * <span class="kw">max</span>(A$index) <span class="co"># Combine samples across chains by renumbering index </span>
pardist &lt;- <span class="kw">acast</span>(A, index ~ variable)
<span class="co"># pardist &lt;- acast(allen_posteriors[2:3], 1:table(allen_posteriors$variable)[1] ~ variable) # NOT SURE WHY THIS FAILS </span>
<span class="co"># transform model parameters back first</span>
pardist[,<span class="st">&quot;logr0&quot;</span>] = <span class="kw">exp</span>(pardist[,<span class="st">&quot;logr0&quot;</span>]) 
pardist[,<span class="st">&quot;logtheta&quot;</span>] = <span class="kw">exp</span>(pardist[,<span class="st">&quot;logtheta&quot;</span>])
<span class="kw">colnames</span>(pardist)[<span class="kw">colnames</span>(pardist)==<span class="st">&quot;logtheta&quot;</span>] = <span class="st">&quot;theta&quot;</span>
<span class="kw">colnames</span>(pardist)[<span class="kw">colnames</span>(pardist)==<span class="st">&quot;logr0&quot;</span>] = <span class="st">&quot;r0&quot;</span>
bayes_coef &lt;- <span class="kw">apply</span>(pardist,<span class="dv">2</span>, posterior.mode) 
bayes_pars &lt;- <span class="kw">unname</span>(<span class="kw">c</span>(bayes_coef[<span class="st">&quot;r0&quot;</span>], bayes_coef[<span class="st">&quot;K&quot;</span>], bayes_coef[<span class="st">&quot;theta&quot;</span>])) <span class="co"># parameters formatted for f</span>
allen_f &lt;- function(x,h,p) <span class="kw">unname</span>(<span class="kw">RickerAllee</span>(x,h, <span class="kw">unname</span>(p[<span class="kw">c</span>(<span class="st">&quot;r0&quot;</span>, <span class="st">&quot;K&quot;</span>, <span class="st">&quot;theta&quot;</span>)])))
allen_means &lt;- <span class="kw">sapply</span>(x_grid, f, <span class="dv">0</span>, bayes_pars)
bayes_pars</code></pre>
<pre><code>[1] 0.01929 7.72010 0.06654</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(pardist)</code></pre>
<pre><code>         K deviance       r0    theta   stdQ
170 21.327    45.03 0.010484 3.826031 0.3737
171 14.261    45.02 0.029587 0.019707 0.4387
172  7.828    40.50 0.129248 2.769482 0.3795
173 29.450    45.66 0.044378 0.006615 0.4461
174 37.580    44.89 0.006334 1.252886 0.3766
175 20.168    45.05 0.033854 0.144171 0.4294</code></pre>
<h2 id="parametric-bayes-based-on-the-structurally-wrong-model-ricker">Parametric Bayes based on the structurally wrong model (Ricker)</h2>
<pre class="sourceCode r"><code class="sourceCode r">K_prior_p &lt;- <span class="kw">c</span>(<span class="fl">0.01</span>, <span class="fl">40.0</span>)
logr0_prior_p &lt;- <span class="kw">c</span>(-<span class="fl">6.0</span>, <span class="fl">6.0</span>)

bugs.model &lt;- 
<span class="kw">paste</span>(<span class="kw">sprintf</span>(
<span class="st">&quot;model{</span>
<span class="st">  K    ~ dunif(%s, %s)</span>
<span class="st">  logr0    ~ dunif(%s, %s)</span>
<span class="st">  stdQ ~ dunif(%s, %s)&quot;</span>, 
  K_prior_p[<span class="dv">1</span>], K_prior_p[<span class="dv">2</span>],
  logr0_prior_p[<span class="dv">1</span>], logr0_prior_p[<span class="dv">2</span>],
  stdQ_prior_p[<span class="dv">1</span>], stdQ_prior_p[<span class="dv">2</span>]),

  <span class="st">&quot;</span>
<span class="st">  iQ &lt;- 1 / (stdQ * stdQ);</span>
<span class="st">  r0 &lt;- exp(logr0)</span>
<span class="st">  y[1] ~ dunif(0, 10)</span>
<span class="st">  for(t in 1:(N-1)){</span>
<span class="st">    mu[t] &lt;- y[t] * exp(r0 * (1 - y[t]/K) )</span>
<span class="st">    y[t+1] ~ dnorm(mu[t], iQ) </span>
<span class="st">  }</span>
<span class="st">}&quot;</span>)
<span class="kw">writeLines</span>(bugs.model, <span class="st">&quot;ricker_process.bugs&quot;</span>)</code></pre>
<p>Compute prior curves</p>
<pre class="sourceCode r"><code class="sourceCode r">K_prior     &lt;- function(x) <span class="kw">dunif</span>(x, K_prior_p[<span class="dv">1</span>], K_prior_p[<span class="dv">2</span>])
logr0_prior &lt;- function(x) <span class="kw">dunif</span>(x, logr0_prior_p[<span class="dv">1</span>], logr0_prior_p[<span class="dv">2</span>])
par_priors &lt;- <span class="kw">list</span>(<span class="dt">K =</span> K_prior, <span class="dt">deviance =</span> function(x) <span class="dv">0</span> * x, 
                   <span class="dt">logr0 =</span> logr0_prior, <span class="dt">stdQ =</span> stdQ_prior)</code></pre>
<p>We define which parameters to keep track of, and set the initial values of parameters in the transformed space used by the MCMC. We use logarithms to maintain strictly positive values of parameters where appropriate.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Uniform priors on standard deviation terms</span>
jags.params=<span class="kw">c</span>(<span class="st">&quot;K&quot;</span>,<span class="st">&quot;logr0&quot;</span>, <span class="st">&quot;stdQ&quot;</span>)
jags.inits &lt;- function(){
  <span class="kw">list</span>(<span class="st">&quot;K&quot;</span>=<span class="dv">10</span> * <span class="kw">rlnorm</span>(<span class="dv">1</span>,<span class="dv">0</span>,.<span class="dv">5</span>),
       <span class="st">&quot;logr0&quot;</span>=<span class="kw">log</span>(<span class="dv">1</span>) * <span class="kw">rlnorm</span>(<span class="dv">1</span>,<span class="dv">0</span>,.<span class="dv">5</span>),
       <span class="st">&quot;stdQ&quot;</span>=<span class="kw">sqrt</span>(<span class="fl">0.05</span>) * <span class="kw">rlnorm</span>(<span class="dv">1</span>,<span class="dv">0</span>,.<span class="dv">5</span>),
       <span class="dt">.RNG.name=</span><span class="st">&quot;base::Wichmann-Hill&quot;</span>, <span class="dt">.RNG.seed=</span><span class="dv">123</span>)
}
<span class="kw">set.seed</span>(<span class="dv">12345</span>) 
ricker_jags &lt;- <span class="kw">do.call</span>(jags.parallel, 
                       <span class="kw">list</span>(<span class="dt">data=</span>jags.data, <span class="dt">inits=</span>jags.inits, 
                            jags.params, <span class="dt">n.chains=</span>n.chains, 
                            <span class="dt">n.iter=</span>n.iter, <span class="dt">n.thin=</span>n.thin, <span class="dt">n.burnin=</span>n.burnin,
                            <span class="dt">model.file=</span><span class="st">&quot;ricker_process.bugs&quot;</span>))
<span class="kw">recompile</span>(ricker_jags)</code></pre>
<pre><code>Compiling model graph
   Resolving undeclared variables
   Allocating nodes
   Graph Size: 251

Initializing model

Compiling model graph
   Resolving undeclared variables
   Allocating nodes
   Graph Size: 251

Initializing model

Compiling model graph
   Resolving undeclared variables
   Allocating nodes
   Graph Size: 251

Initializing model

Compiling model graph
   Resolving undeclared variables
   Allocating nodes
   Graph Size: 251

Initializing model

Compiling model graph
   Resolving undeclared variables
   Allocating nodes
   Graph Size: 251

Initializing model

Compiling model graph
   Resolving undeclared variables
   Allocating nodes
   Graph Size: 251

Initializing model</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">ricker_jags &lt;- <span class="kw">do.call</span>(autojags, 
                       <span class="kw">list</span>(<span class="dt">object=</span>ricker_jags, <span class="dt">n.update=</span>n.update, <span class="dt">n.iter=</span>n.iter, 
                            <span class="dt">n.thin =</span> n.thin, <span class="dt">progress.bar=</span><span class="st">&quot;none&quot;</span>))</code></pre>
<h4 id="convergence-diagnostics-for-parametric-bayes-ricker-model">Convergence diagnostics for parametric bayes Ricker model</h4>
<pre class="sourceCode r"><code class="sourceCode r">tmp &lt;- <span class="kw">lapply</span>(<span class="kw">as.mcmc</span>(ricker_jags), as.matrix) <span class="co"># strip classes the hard way...</span>
ricker_posteriors &lt;- <span class="kw">melt</span>(tmp, <span class="dt">id =</span> <span class="kw">colnames</span>(tmp[[<span class="dv">1</span>]])) 
<span class="kw">names</span>(ricker_posteriors) = <span class="kw">c</span>(<span class="st">&quot;index&quot;</span>, <span class="st">&quot;variable&quot;</span>, <span class="st">&quot;value&quot;</span>, <span class="st">&quot;chain&quot;</span>)

<span class="kw">ggplot</span>(ricker_posteriors) + <span class="kw">geom_line</span>(<span class="kw">aes</span>(index, value)) + 
  <span class="kw">facet_wrap</span>(~ variable, <span class="dt">scale=</span><span class="st">&quot;free&quot;</span>, <span class="dt">ncol=</span><span class="dv">1</span>)</code></pre>
<figure>
<img src="http://farm8.staticflickr.com/7354/8954617787_8743f7915f_o.png" alt="plot of chunk ricker-traces" /><figcaption>plot of chunk ricker-traces</figcaption>
</figure>
<pre class="sourceCode r"><code class="sourceCode r">ricker_priors &lt;- <span class="kw">ddply</span>(ricker_posteriors, <span class="st">&quot;variable&quot;</span>, function(dd){
    grid &lt;- <span class="kw">seq</span>(<span class="kw">min</span>(dd$value), <span class="kw">max</span>(dd$value), <span class="dt">length =</span> <span class="dv">100</span>) 
    <span class="kw">data.frame</span>(<span class="dt">value =</span> grid, <span class="dt">density =</span> par_priors[[dd$variable[<span class="dv">1</span>]]](grid))
})
<span class="co"># plot posterior distributions</span>
<span class="kw">ggplot</span>(ricker_posteriors, <span class="kw">aes</span>(value)) + 
  <span class="kw">stat_density</span>(<span class="dt">geom=</span><span class="st">&quot;path&quot;</span>, <span class="dt">position=</span><span class="st">&quot;identity&quot;</span>, <span class="dt">alpha=</span><span class="fl">0.7</span>) +
  <span class="kw">geom_line</span>(<span class="dt">data=</span>ricker_priors, <span class="kw">aes</span>(<span class="dt">x=</span>value, <span class="dt">y=</span>density), <span class="dt">col=</span><span class="st">&quot;red&quot;</span>) + 
  <span class="kw">facet_wrap</span>(~ variable, <span class="dt">scale=</span><span class="st">&quot;free&quot;</span>, <span class="dt">ncol=</span><span class="dv">2</span>)</code></pre>
<figure>
<img src="http://farm6.staticflickr.com/5326/8954618029_911b481fc8_o.png" alt="plot of chunk ricker-posteriors" /><figcaption>plot of chunk ricker-posteriors</figcaption>
</figure>
<p>Reshape posteriors data, transform back, calculate mode and corresponding function.</p>
<pre class="sourceCode r"><code class="sourceCode r">A &lt;- ricker_posteriors
A$index &lt;- A$index + A$chain * <span class="kw">max</span>(A$index) <span class="co"># Combine samples across chains by renumbering index </span>
ricker_pardist &lt;- <span class="kw">acast</span>(A, index ~ variable)
ricker_pardist[,<span class="st">&quot;logr0&quot;</span>] = <span class="kw">exp</span>(ricker_pardist[,<span class="st">&quot;logr0&quot;</span>]) <span class="co"># transform model parameters back first</span>
<span class="kw">colnames</span>(ricker_pardist)[<span class="kw">colnames</span>(ricker_pardist)==<span class="st">&quot;logr0&quot;</span>] = <span class="st">&quot;r0&quot;</span>
bayes_coef &lt;- <span class="kw">apply</span>(ricker_pardist,<span class="dv">2</span>, posterior.mode) <span class="co"># much better estimates from mode then mean</span>
ricker_bayes_pars &lt;- <span class="kw">unname</span>(<span class="kw">c</span>(bayes_coef[<span class="st">&quot;r0&quot;</span>], bayes_coef[<span class="st">&quot;K&quot;</span>]))

ricker_f &lt;- function(x,h,p){
  <span class="kw">sapply</span>(x, function(x){ 
    x &lt;- <span class="kw">pmax</span>(<span class="dv">0</span>, x-h) 
    <span class="kw">pmax</span>(<span class="dv">0</span>, x * <span class="kw">exp</span>(p[<span class="st">&quot;r0&quot;</span>] * (<span class="dv">1</span> - x / p[<span class="st">&quot;K&quot;</span>] )) )
  })
}
ricker_means &lt;- <span class="kw">sapply</span>(x_grid, Ricker, <span class="dv">0</span>, ricker_bayes_pars[<span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>)])

<span class="kw">head</span>(ricker_pardist)</code></pre>
<pre><code>         K deviance       r0   stdQ
170 30.871    44.59 0.011138 0.4164
171 15.920    44.30 0.003492 0.4062
172  8.630    46.04 0.040291 0.4962
173  7.935    37.59 0.172355 0.3977
174  8.622    42.76 0.096497 0.3325
175  8.279    40.48 0.143866 0.4316</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">ricker_bayes_pars</code></pre>
<pre><code>[1] 0.008073 8.011228</code></pre>
<h2 id="myers-parametric-bayes">Myers Parametric Bayes</h2>
<pre class="sourceCode r"><code class="sourceCode r">logr0_prior_p &lt;- <span class="kw">c</span>(-<span class="fl">6.0</span>, <span class="fl">6.0</span>)
logtheta_prior_p &lt;- <span class="kw">c</span>(-<span class="fl">6.0</span>, <span class="fl">6.0</span>)
logK_prior_p &lt;- <span class="kw">c</span>(-<span class="fl">6.0</span>, <span class="fl">6.0</span>)

bugs.model &lt;- 
<span class="kw">paste</span>(<span class="kw">sprintf</span>(
<span class="st">&quot;model{</span>
<span class="st">  logr0    ~ dunif(%s, %s)</span>
<span class="st">  logtheta    ~ dunif(%s, %s)</span>
<span class="st">  logK    ~ dunif(%s, %s)</span>
<span class="st">  stdQ ~ dunif(%s, %s)&quot;</span>, 
  logr0_prior_p[<span class="dv">1</span>], logr0_prior_p[<span class="dv">2</span>],
  logtheta_prior_p[<span class="dv">1</span>], logtheta_prior_p[<span class="dv">2</span>],
  logK_prior_p[<span class="dv">1</span>], logK_prior_p[<span class="dv">2</span>],
  stdQ_prior_p[<span class="dv">1</span>], stdQ_prior_p[<span class="dv">2</span>]),

  <span class="st">&quot;</span>
<span class="st">  iQ &lt;- 1 / (stdQ * stdQ);</span>
<span class="st">  r0 &lt;- exp(logr0)</span>
<span class="st">  theta &lt;- exp(logtheta)</span>
<span class="st">  K &lt;- exp(logK)</span>

<span class="st">  y[1] ~ dunif(0, 10)</span>
<span class="st">  for(t in 1:(N-1)){</span>
<span class="st">    mu[t] &lt;- r0 * pow(abs(y[t]), theta) / (1 + pow(abs(y[t]), theta) / K)</span>
<span class="st">    y[t+1] ~ dnorm(mu[t], iQ) </span>
<span class="st">  }</span>
<span class="st">}&quot;</span>)
<span class="kw">writeLines</span>(bugs.model, <span class="st">&quot;myers_process.bugs&quot;</span>)</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">logK_prior     &lt;- function(x) <span class="kw">dunif</span>(x, logK_prior_p[<span class="dv">1</span>], logK_prior_p[<span class="dv">2</span>])
logr_prior     &lt;- function(x) <span class="kw">dunif</span>(x, logr0_prior_p[<span class="dv">1</span>], logr0_prior_p[<span class="dv">2</span>])
logtheta_prior &lt;- function(x) <span class="kw">dunif</span>(x, logtheta_prior_p[<span class="dv">1</span>], logtheta_prior_p[<span class="dv">2</span>])
par_priors &lt;- <span class="kw">list</span>( <span class="dt">deviance =</span> function(x) <span class="dv">0</span> * x, <span class="dt">logK =</span> logK_prior,
                    <span class="dt">logr0 =</span> logr_prior, <span class="dt">logtheta =</span> logtheta_prior, 
                    <span class="dt">stdQ =</span> stdQ_prior)</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">jags.params=<span class="kw">c</span>(<span class="st">&quot;logr0&quot;</span>, <span class="st">&quot;logtheta&quot;</span>, <span class="st">&quot;logK&quot;</span>, <span class="st">&quot;stdQ&quot;</span>)
jags.inits &lt;- function(){
  <span class="kw">list</span>(<span class="st">&quot;logr0&quot;</span>=<span class="kw">log</span>(<span class="kw">rlnorm</span>(<span class="dv">1</span>,<span class="dv">0</span>,.<span class="dv">1</span>)), 
       <span class="st">&quot;logK&quot;</span>=<span class="kw">log</span>(<span class="dv">10</span> * <span class="kw">rlnorm</span>(<span class="dv">1</span>,<span class="dv">0</span>,.<span class="dv">1</span>)),
       <span class="st">&quot;logtheta&quot;</span> = <span class="kw">log</span>(<span class="dv">2</span> * <span class="kw">rlnorm</span>(<span class="dv">1</span>,<span class="dv">0</span>,.<span class="dv">1</span>)),  
       <span class="st">&quot;stdQ&quot;</span>=<span class="kw">sqrt</span>(<span class="fl">0.5</span>) * <span class="kw">rlnorm</span>(<span class="dv">1</span>,<span class="dv">0</span>,.<span class="dv">1</span>),
       <span class="dt">.RNG.name=</span><span class="st">&quot;base::Wichmann-Hill&quot;</span>, <span class="dt">.RNG.seed=</span><span class="dv">123</span>)
}
<span class="kw">set.seed</span>(<span class="dv">12345</span>)
myers_jags &lt;- <span class="kw">do.call</span>(jags.parallel, 
                      <span class="kw">list</span>(<span class="dt">data=</span>jags.data, <span class="dt">inits=</span>jags.inits, jags.params, 
                           <span class="dt">n.chains=</span>n.chains, <span class="dt">n.iter=</span>n.iter, <span class="dt">n.thin=</span>n.thin,
                           <span class="dt">n.burnin=</span>n.burnin, <span class="dt">model.file=</span><span class="st">&quot;myers_process.bugs&quot;</span>))
<span class="kw">recompile</span>(myers_jags)</code></pre>
<pre><code>Compiling model graph
   Resolving undeclared variables
   Allocating nodes
   Graph Size: 291

Initializing model

Compiling model graph
   Resolving undeclared variables
   Allocating nodes
   Graph Size: 291

Initializing model

Compiling model graph
   Resolving undeclared variables
   Allocating nodes
   Graph Size: 291

Initializing model

Compiling model graph
   Resolving undeclared variables
   Allocating nodes
   Graph Size: 291

Initializing model

Compiling model graph
   Resolving undeclared variables
   Allocating nodes
   Graph Size: 291

Initializing model

Compiling model graph
   Resolving undeclared variables
   Allocating nodes
   Graph Size: 291

Initializing model</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">myers_jags &lt;- <span class="kw">do.call</span>(autojags, 
                      <span class="kw">list</span>(myers_jags, <span class="dt">n.update=</span>n.update, <span class="dt">n.iter=</span>n.iter, 
                           <span class="dt">n.thin =</span> n.thin, <span class="dt">progress.bar=</span><span class="st">&quot;none&quot;</span>))</code></pre>
<p>Convergence diagnostics for parametric bayes</p>
<pre class="sourceCode r"><code class="sourceCode r">tmp &lt;- <span class="kw">lapply</span>(<span class="kw">as.mcmc</span>(myers_jags), as.matrix) <span class="co"># strip classes the hard way...</span>
myers_posteriors &lt;- <span class="kw">melt</span>(tmp, <span class="dt">id =</span> <span class="kw">colnames</span>(tmp[[<span class="dv">1</span>]])) 
<span class="kw">names</span>(myers_posteriors) = <span class="kw">c</span>(<span class="st">&quot;index&quot;</span>, <span class="st">&quot;variable&quot;</span>, <span class="st">&quot;value&quot;</span>, <span class="st">&quot;chain&quot;</span>)

<span class="kw">ggplot</span>(myers_posteriors) + <span class="kw">geom_line</span>(<span class="kw">aes</span>(index, value)) +
  <span class="kw">facet_wrap</span>(~ variable, <span class="dt">scale=</span><span class="st">&quot;free&quot;</span>, <span class="dt">ncol=</span><span class="dv">1</span>)</code></pre>
<figure>
<img src="http://farm9.staticflickr.com/8134/8955814112_feb5f6abb2_o.png" alt="plot of chunk myers-traces" /><figcaption>plot of chunk myers-traces</figcaption>
</figure>
<pre class="sourceCode r"><code class="sourceCode r">par_prior_curves &lt;- <span class="kw">ddply</span>(myers_posteriors, <span class="st">&quot;variable&quot;</span>, function(dd){
    grid &lt;- <span class="kw">seq</span>(<span class="kw">min</span>(dd$value), <span class="kw">max</span>(dd$value), <span class="dt">length =</span> <span class="dv">100</span>) 
    <span class="kw">data.frame</span>(<span class="dt">value =</span> grid, <span class="dt">density =</span> par_priors[[dd$variable[<span class="dv">1</span>]]](grid))
})

<span class="kw">ggplot</span>(myers_posteriors, <span class="kw">aes</span>(value)) + 
  <span class="kw">stat_density</span>(<span class="dt">geom=</span><span class="st">&quot;path&quot;</span>, <span class="dt">position=</span><span class="st">&quot;identity&quot;</span>, <span class="dt">alpha=</span><span class="fl">0.7</span>) +
  <span class="kw">geom_line</span>(<span class="dt">data=</span>par_prior_curves, <span class="kw">aes</span>(<span class="dt">x=</span>value, <span class="dt">y=</span>density), <span class="dt">col=</span><span class="st">&quot;red&quot;</span>) + 
  <span class="kw">facet_wrap</span>(~ variable, <span class="dt">scale=</span><span class="st">&quot;free&quot;</span>, <span class="dt">ncol=</span><span class="dv">3</span>)</code></pre>
<figure>
<img src="http://farm4.staticflickr.com/3772/8955814344_b654594c98_o.png" alt="plot of chunk myers-posteriors" /><figcaption>plot of chunk myers-posteriors</figcaption>
</figure>
<pre class="sourceCode r"><code class="sourceCode r">A &lt;- myers_posteriors
A$index &lt;- A$index + A$chain * <span class="kw">max</span>(A$index) <span class="co"># Combine samples across chains by renumbering index </span>
myers_pardist &lt;- <span class="kw">acast</span>(A, index ~ variable)
### myers_pardist &lt;- acast(myers_posteriors[2:3], 1:table(myers_posteriors$variable) ~ variable) 
myers_pardist[,<span class="st">&quot;logK&quot;</span>] = <span class="kw">exp</span>(myers_pardist[,<span class="st">&quot;logK&quot;</span>]) <span class="co"># transform model parameters back first</span>
myers_pardist[,<span class="st">&quot;logr0&quot;</span>] = <span class="kw">exp</span>(myers_pardist[,<span class="st">&quot;logr0&quot;</span>]) <span class="co"># transform model parameters back first</span>
myers_pardist[,<span class="st">&quot;logtheta&quot;</span>] = <span class="kw">exp</span>(myers_pardist[,<span class="st">&quot;logtheta&quot;</span>]) <span class="co"># transform model parameters back first</span>
<span class="kw">colnames</span>(myers_pardist)[<span class="kw">colnames</span>(myers_pardist)==<span class="st">&quot;logK&quot;</span>] = <span class="st">&quot;K&quot;</span>
<span class="kw">colnames</span>(myers_pardist)[<span class="kw">colnames</span>(myers_pardist)==<span class="st">&quot;logr0&quot;</span>] = <span class="st">&quot;r0&quot;</span>
<span class="kw">colnames</span>(myers_pardist)[<span class="kw">colnames</span>(myers_pardist)==<span class="st">&quot;logtheta&quot;</span>] = <span class="st">&quot;theta&quot;</span>


bayes_coef &lt;- <span class="kw">apply</span>(myers_pardist,<span class="dv">2</span>, posterior.mode) <span class="co"># much better estimates</span>
myers_bayes_pars &lt;- <span class="kw">unname</span>(<span class="kw">c</span>(bayes_coef[<span class="dv">2</span>], bayes_coef[<span class="dv">3</span>], bayes_coef[<span class="dv">1</span>]))
myers_means &lt;- <span class="kw">sapply</span>(x_grid, Myer_harvest, <span class="dv">0</span>, myers_bayes_pars)
myers_f &lt;- function(x,h,p) <span class="kw">Myer_harvest</span>(x, h, p[<span class="kw">c</span>(<span class="st">&quot;r0&quot;</span>, <span class="st">&quot;theta&quot;</span>, <span class="st">&quot;K&quot;</span>)])
<span class="kw">head</span>(myers_pardist)</code></pre>
<pre><code>    deviance      K      r0 theta   stdQ
170    37.69  32.42 0.32913 2.156 0.2818
171    32.99  51.72 0.20896 2.373 0.3612
172    40.26  52.83 0.22398 2.260 0.4654
173    32.80  76.54 0.12968 2.749 0.3711
174    32.81 216.04 0.04136 3.512 0.3907
175    32.55 330.07 0.02654 3.813 0.3118</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">myers_bayes_pars</code></pre>
<pre><code>[1] 31.8192  0.1065 34.4760</code></pre>
<h3 id="phase-space-diagram-of-the-expected-dynamics">Phase-space diagram of the expected dynamics</h3>
<pre class="sourceCode r"><code class="sourceCode r">models &lt;- <span class="kw">data.frame</span>(<span class="dt">x=</span>x_grid, 
                     <span class="dt">GP=</span>tgp_dat$y, 
                     <span class="dt">True=</span>true_means, 
                     <span class="dt">MLE=</span>est_means, 
                     <span class="dt">Ricker=</span>ricker_means, 
                     <span class="dt">Allen =</span> allen_means,
                     <span class="dt">Myers =</span> myers_means)
models &lt;- <span class="kw">melt</span>(models, <span class="dt">id=</span><span class="st">&quot;x&quot;</span>)

<span class="co"># some labels</span>
<span class="kw">names</span>(models) &lt;- <span class="kw">c</span>(<span class="st">&quot;x&quot;</span>, <span class="st">&quot;method&quot;</span>, <span class="st">&quot;value&quot;</span>)

<span class="co"># labels for the colorkey too</span>
model_names = <span class="kw">c</span>(<span class="st">&quot;GP&quot;</span>, <span class="st">&quot;True&quot;</span>, <span class="st">&quot;MLE&quot;</span>, <span class="st">&quot;Ricker&quot;</span>, <span class="st">&quot;Allen&quot;</span>, <span class="st">&quot;Myers&quot;</span>)
colorkey=cbPalette
<span class="kw">names</span>(colorkey) = model_names </code></pre>
<pre class="sourceCode r"><code class="sourceCode r">plot_gp &lt;- <span class="kw">ggplot</span>(tgp_dat) + <span class="kw">geom_ribbon</span>(<span class="kw">aes</span>(x,y,<span class="dt">ymin=</span>ymin,<span class="dt">ymax=</span>ymax), <span class="dt">fill=</span><span class="st">&quot;gray80&quot;</span>) +
    <span class="kw">geom_line</span>(<span class="dt">data=</span>models, <span class="kw">aes</span>(x, value, <span class="dt">col=</span>method), <span class="dt">lwd=</span><span class="dv">1</span>, <span class="dt">alpha=</span><span class="fl">0.8</span>) + 
    <span class="kw">geom_point</span>(<span class="dt">data=</span>obs, <span class="kw">aes</span>(x,y), <span class="dt">alpha=</span><span class="fl">0.8</span>) + 
    <span class="kw">xlab</span>(<span class="kw">expression</span>(X[t])) + <span class="kw">ylab</span>(<span class="kw">expression</span>(X[t<span class="dv">+1</span>])) +
    <span class="kw">scale_colour_manual</span>(<span class="dt">values=</span>cbPalette) 
<span class="kw">print</span>(plot_gp)</code></pre>
<figure>
<img src="http://farm4.staticflickr.com/3820/8954618731_61ebc877be_o.png" alt="plot of chunk Figure1" /><figcaption>plot of chunk Figure1</figcaption>
</figure>
<h2 id="goodness-of-fit">Goodness of fit</h2>
<p>This shows only the mean predictions. For the Bayesian cases, we can instead loop over the posteriors of the parameters (or samples from the GP posterior) to get the distribution of such curves in each case.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">require</span>(MASS)
step_ahead &lt;- function(x, f, p){
  h = <span class="dv">0</span>
  x_predict &lt;- <span class="kw">sapply</span>(x, f, h, p)
  n &lt;- <span class="kw">length</span>(x_predict) - <span class="dv">1</span>
  y &lt;- <span class="kw">c</span>(x[<span class="dv">1</span>], x_predict[<span class="dv">1</span>:n])
  y
}
step_ahead_posteriors &lt;- function(x){
gp_f_at_obs &lt;- <span class="kw">gp_predict</span>(gp, x, <span class="dt">burnin=</span><span class="fl">1e4</span>, <span class="dt">thin=</span><span class="dv">300</span>)
df_post &lt;- <span class="kw">melt</span>(<span class="kw">lapply</span>(<span class="kw">sample</span>(<span class="dv">100</span>), 
  function(i){
    <span class="kw">data.frame</span>(<span class="dt">time =</span> <span class="dv">1</span>:<span class="kw">length</span>(x), <span class="dt">stock =</span> x, 
                <span class="dt">GP =</span> <span class="kw">mvrnorm</span>(<span class="dv">1</span>, gp_f_at_obs$Ef_posterior[,i], gp_f_at_obs$Cf_posterior[[i]]),
                <span class="dt">True =</span> <span class="kw">step_ahead</span>(x,f,p),  
                <span class="dt">MLE =</span> <span class="kw">step_ahead</span>(x,f,est$p), 
                <span class="dt">Allen =</span> <span class="kw">step_ahead</span>(x, allen_f, pardist[i,]), 
                <span class="dt">Ricker =</span> <span class="kw">step_ahead</span>(x, ricker_f, ricker_pardist[i,]), 
                <span class="dt">Myers =</span> <span class="kw">step_ahead</span>(x, myers_f, myers_pardist[i,]))
  }), <span class="dt">id=</span><span class="kw">c</span>(<span class="st">&quot;time&quot;</span>, <span class="st">&quot;stock&quot;</span>))
}

df_post &lt;- <span class="kw">step_ahead_posteriors</span>(x)

<span class="kw">ggplot</span>(df_post) + <span class="kw">geom_point</span>(<span class="kw">aes</span>(time, stock)) + 
  <span class="kw">geom_line</span>(<span class="kw">aes</span>(time, value, <span class="dt">col=</span>variable, <span class="dt">group=</span><span class="kw">interaction</span>(L1,variable)), <span class="dt">alpha=</span>.<span class="dv">1</span>) + 
  <span class="kw">scale_colour_manual</span>(<span class="dt">values=</span>colorkey, <span class="dt">guide =</span> <span class="kw">guide_legend</span>(<span class="dt">override.aes =</span> <span class="kw">list</span>(<span class="dt">alpha =</span> <span class="dv">1</span>))) </code></pre>
<figure>
<img src="http://farm4.staticflickr.com/3792/8954618965_9b92db0892_o.png" alt="plot of chunk Figureb" /><figcaption>plot of chunk Figureb</figcaption>
</figure>
<h2 id="optimal-policies-by-value-iteration">Optimal policies by value iteration</h2>
<p>Compute the optimal policy under each model using stochastic dynamic programming. We begin with the policy based on the GP model,</p>
<pre class="sourceCode r"><code class="sourceCode r">MaxT = <span class="dv">1000</span>
<span class="co"># uses expected values from GP, instead of integrating over posterior</span>
<span class="co">#matrices_gp &lt;- gp_transition_matrix(gp_dat$E_Ef, gp_dat$E_Vf, x_grid, h_grid)</span>

<span class="co"># Integrate over posteriors </span>
matrices_gp &lt;- <span class="kw">gp_transition_matrix</span>(gp_dat$Ef_posterior, gp_dat$Vf_posterior, x_grid, h_grid) 

<span class="co"># Solve the SDP using the GP-derived transition matrix</span>
opt_gp &lt;- <span class="kw">value_iteration</span>(matrices_gp, x_grid, h_grid, MaxT, xT, profit, delta, reward)</code></pre>
<p>Determine the optimal policy based on the allen and MLE models</p>
<pre class="sourceCode r"><code class="sourceCode r">matrices_true &lt;- <span class="kw">f_transition_matrix</span>(f, p, x_grid, h_grid, sigma_g)
opt_true &lt;- <span class="kw">value_iteration</span>(matrices_true, x_grid, h_grid, <span class="dt">OptTime=</span>MaxT, xT, profit, <span class="dt">delta=</span>delta)

matrices_estimated &lt;- <span class="kw">f_transition_matrix</span>(est$f, est$p, x_grid, h_grid, est$sigma_g)
opt_estimated &lt;- <span class="kw">value_iteration</span>(matrices_estimated, x_grid, h_grid, <span class="dt">OptTime=</span>MaxT, xT, profit, <span class="dt">delta=</span>delta)</code></pre>
<p>Determine the optimal policy based on Bayesian Allen model</p>
<pre class="sourceCode r"><code class="sourceCode r">matrices_allen &lt;- <span class="kw">parameter_uncertainty_SDP</span>(allen_f, x_grid, h_grid, pardist, <span class="dv">4</span>)
opt_allen &lt;- <span class="kw">value_iteration</span>(matrices_allen, x_grid, h_grid, <span class="dt">OptTime=</span>MaxT, xT, profit, <span class="dt">delta=</span>delta)</code></pre>
<p>Bayesian Ricker</p>
<pre class="sourceCode r"><code class="sourceCode r">matrices_ricker &lt;- <span class="kw">parameter_uncertainty_SDP</span>(ricker_f, x_grid, h_grid, <span class="kw">as.matrix</span>(ricker_pardist), <span class="dv">3</span>)
opt_ricker &lt;- <span class="kw">value_iteration</span>(matrices_ricker, x_grid, h_grid, <span class="dt">OptTime=</span>MaxT, xT, profit, <span class="dt">delta=</span>delta)</code></pre>
<p>Bayesian Myers model</p>
<pre class="sourceCode r"><code class="sourceCode r">matrices_myers &lt;- <span class="kw">parameter_uncertainty_SDP</span>(myers_f, x_grid, h_grid, <span class="kw">as.matrix</span>(myers_pardist), <span class="dv">4</span>)
myers_alt &lt;- <span class="kw">value_iteration</span>(matrices_myers, x_grid, h_grid, <span class="dt">OptTime=</span>MaxT, xT, profit, <span class="dt">delta=</span>delta)</code></pre>
<p>Assemble the data</p>
<pre class="sourceCode r"><code class="sourceCode r">OPT = <span class="kw">data.frame</span>(<span class="dt">GP =</span> opt_gp$D, <span class="dt">True =</span> opt_true$D, <span class="dt">MLE =</span> opt_estimated$D, <span class="dt">Ricker =</span> opt_ricker$D, <span class="dt">Allen =</span> opt_allen$D, <span class="dt">Myers =</span> myers_alt$D)
colorkey=cbPalette
<span class="kw">names</span>(colorkey) = <span class="kw">names</span>(OPT) </code></pre>
<h2 id="graph-of-the-optimal-policies">Graph of the optimal policies</h2>
<pre class="sourceCode r"><code class="sourceCode r">policies &lt;- <span class="kw">melt</span>(<span class="kw">data.frame</span>(<span class="dt">stock=</span>x_grid, <span class="kw">sapply</span>(OPT, function(x) x_grid[x])), <span class="dt">id=</span><span class="st">&quot;stock&quot;</span>)
<span class="kw">names</span>(policies) &lt;- <span class="kw">c</span>(<span class="st">&quot;stock&quot;</span>, <span class="st">&quot;method&quot;</span>, <span class="st">&quot;value&quot;</span>)

<span class="kw">ggplot</span>(policies, <span class="kw">aes</span>(stock, stock - value, <span class="dt">color=</span>method)) +
  <span class="kw">geom_line</span>(<span class="dt">lwd=</span><span class="fl">1.2</span>, <span class="dt">alpha=</span><span class="fl">0.8</span>) + <span class="kw">xlab</span>(<span class="st">&quot;stock size&quot;</span>) + <span class="kw">ylab</span>(<span class="st">&quot;escapement&quot;</span>)  +
  <span class="kw">scale_colour_manual</span>(<span class="dt">values=</span>colorkey)</code></pre>
<figure>
<img src="http://farm8.staticflickr.com/7348/8954619233_e007f06eab_o.png" alt="plot of chunk Figure2" /><figcaption>plot of chunk Figure2</figcaption>
</figure>
<h2 id="simulate-100-realizations-managed-under-each-of-the-policies">Simulate 100 realizations managed under each of the policies</h2>
<pre class="sourceCode r"><code class="sourceCode r">sims &lt;- <span class="kw">lapply</span>(OPT, function(D){
  <span class="kw">set.seed</span>(<span class="dv">1</span>)
  <span class="kw">lapply</span>(<span class="dv">1</span>:<span class="dv">100</span>, function(i) 
    <span class="kw">ForwardSimulate</span>(f, p, x_grid, h_grid, x0, D, z_g, <span class="dt">profit=</span>profit, <span class="dt">OptTime=</span>OptTime)
  )
})

dat &lt;- <span class="kw">melt</span>(sims, <span class="dt">id=</span><span class="kw">names</span>(sims[[<span class="dv">1</span>]][[<span class="dv">1</span>]]))
dt &lt;- <span class="kw">data.table</span>(dat)
<span class="kw">setnames</span>(dt, <span class="kw">c</span>(<span class="st">&quot;L1&quot;</span>, <span class="st">&quot;L2&quot;</span>), <span class="kw">c</span>(<span class="st">&quot;method&quot;</span>, <span class="st">&quot;reps&quot;</span>)) 
<span class="co"># Legend in original ordering please, not alphabetical: </span>
dt$method = <span class="kw">factor</span>(dt$method, <span class="dt">ordered=</span><span class="ot">TRUE</span>, <span class="dt">levels=</span><span class="kw">names</span>(OPT))</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(dt) + 
  <span class="kw">geom_line</span>(<span class="kw">aes</span>(time, fishstock, <span class="dt">group=</span><span class="kw">interaction</span>(reps,method), <span class="dt">color=</span>method), <span class="dt">alpha=</span>.<span class="dv">1</span>) +
  <span class="kw">scale_colour_manual</span>(<span class="dt">values=</span>colorkey, <span class="dt">guide =</span> <span class="kw">guide_legend</span>(<span class="dt">override.aes =</span> <span class="kw">list</span>(<span class="dt">alpha =</span> <span class="dv">1</span>)))</code></pre>
<figure>
<img src="http://farm4.staticflickr.com/3808/8955815586_814e0c50d6_o.png" alt="plot of chunk Figure3" /><figcaption>plot of chunk Figure3</figcaption>
</figure>
<pre class="sourceCode r"><code class="sourceCode r">Profit &lt;- dt[, <span class="kw">sum</span>(profit), by=<span class="kw">c</span>(<span class="st">&quot;reps&quot;</span>, <span class="st">&quot;method&quot;</span>)]
Profit[, <span class="kw">mean</span>(V1), by=<span class="st">&quot;method&quot;</span>]</code></pre>
<pre><code>   method     V1
1:     GP 24.908
2:   True 26.532
3:    MLE  4.420
4: Ricker  8.363
5:  Allen  7.041
6:  Myers  7.347</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(Profit, <span class="kw">aes</span>(V1)) + <span class="kw">geom_histogram</span>() + 
  <span class="kw">facet_wrap</span>(~method, <span class="dt">scales =</span> <span class="st">&quot;free_y&quot;</span>) + <span class="kw">guides</span>(<span class="dt">legend.position =</span> <span class="st">&quot;none&quot;</span>) + <span class="kw">xlab</span>(<span class="st">&quot;Total profit by replicate&quot;</span>)</code></pre>
<figure>
<img src="http://farm3.staticflickr.com/2881/8954620001_2722b7d9d9_o.png" alt="plot of chunk totalprofits" /><figcaption>plot of chunk totalprofits</figcaption>
</figure>
<pre class="sourceCode r"><code class="sourceCode r">allen_deviance &lt;- <span class="kw">posterior.mode</span>(pardist[,<span class="st">&#39;deviance&#39;</span>])
ricker_deviance &lt;- <span class="kw">posterior.mode</span>(ricker_pardist[,<span class="st">&#39;deviance&#39;</span>])
myers_deviance &lt;- <span class="kw">posterior.mode</span>(myers_pardist[,<span class="st">&#39;deviance&#39;</span>])
true_deviance &lt;- <span class="dv">2</span>*<span class="kw">estf</span>(<span class="kw">c</span>(p, sigma_g))
mle_deviance &lt;- <span class="dv">2</span>*<span class="kw">estf</span>(<span class="kw">c</span>(est$p, est$sigma_g))

<span class="kw">c</span>(<span class="dt">allen =</span> allen_deviance, <span class="dt">ricker=</span>ricker_deviance, <span class="dt">myers=</span>myers_deviance, <span class="dt">true=</span>true_deviance, <span class="dt">mle=</span>mle_deviance)</code></pre>
<pre><code>  allen  ricker   myers    true     mle 
  45.26   44.78   34.48  -61.08 -287.60 </code></pre>
 
<!-- not that raw_content depends on custom generator, 
     see _plugins/jekyll-labnotebook-plugins/raw_content --> 
</article> 
<p> <a href="/2013/06/04/sensitivity-of-gp-comparisons-in-further-examples.html"> <em>Read more</em></a> </p>
<br />
<br />


        </div>
      
        <div class="span3">
          <header><h4><a href="/2013/06/04/analytic-marginalizing-for-posteriors.html">Analytic Marginalizing For Posteriors</a></h4></header>
<p><span></span></p>
<p style="font-style:italic"> 04 Jun 2013</p>

<p style="font-style:italic"> pageviews: 2 </p>

<article>
<div class="excerpt">
<p>Consider the model</p>
<p><span class="math">\[ X_{t+1} = X_t r e^{-\beta X_t + \sigma Z_t } \]</span></p>
<p>with <span class="math">\(Z_t\)</span> a unit normal random variable. The likelihood of the sequence of <span class="math">\(T\)</span> observations of <span class="math">\(X\)</span> under this model is thus</p>
<p><span class="math">\[P(r, \beta, \sigma | X) = \frac{1}{\sqrt{2 \pi \sigma^2}^{T-1}} \exp\left(\frac{\sum_t^{T-1} \left(\log X_{t+1} - \log X_t - \log r + \beta X_t\right)^2 }{2 \sigma^2}\right) \]</span></p>
<p>To integrate out <span class="math">\(r\)</span>, <span class="math">\(\int P(r, \beta, \sigma | X) P(r) dr\)</span>, we’ll make this look like a Gaussian in <span class="math">\(\log r\)</span> by completing the square; getting the square on the outside of the sum. First we collect all the other terms as the factor, <span class="math">\(M_t\)</span>;</p>
<p><span class="math">\[M_t := \log X_{t+1} - \log X_t + \beta X_t\]</span></p>
<p>Also define <span class="math">\(a = \log r\)</span>, then after expanding the square inside the sum we have</p>
<p><span class="math">\[\sum_t^{T-1} \left(\log r - M_t\right)^2 = \sum_t^{T-1} a^2 - 2 \sum_t^{T-1} a M_t + \sum_t^{T-1} M_t^2 \]</span></p>
<p>(using the linearity of the summation operator). Use the trick of adding and subtracting <span class="math">\(\left( \sum M_t \right)^2/(T-1)\)</span>, to get:</p>
<p><span class="math">\[ = -\sum_t^{T-1} M_t^2 -\frac{\left(\sum_t^{T-1} M_t\right)^2}{T-1}  + \frac{\left(\sum_t^{T-1} M_t\right)^2}{T-1} - 2 a \sum M_t + (T-1)a^2\]</span></p>
<p><span class="math">\[ =  -\sum_t^{T-1} M_t^2 -\frac{\left(\sum_t^{T-1} M_t\right)^2}{T-1}  +(T-1)\left( \left(\frac{\sum_t^{T-1} M_t}{T-1}\right)^2 - \frac{2 a \sum M_t}{T-1} + a^2\right)\]</span></p>
<p><span class="math">\[ = -\sum_t^{T-1} M_t^2 -\frac{\left(\sum_t^{T-1} M_t\right)^2}{T-1}  +(T-1)\left( \frac{\sum_t^{T-1} M_t}{T-1} - a\right)^2\]</span></p>
<p>Returning this expression into our exponential in place of the sum of squares, we have</p>
<p><span class="math">\[P(r, \beta, \sigma | X) = \frac{1}{\sqrt{2 \pi \sigma^2}^{T-1}} \exp\left(\frac{(T-1)\left( \frac{\sum_t^{T-1} M_t}{T-1} - a\right)^2}{2 \sigma^2}\right) \exp\left(\frac{-\sum_t^{T-1} M_t^2 -\frac{\left(\sum_t^{T-1} M_t\right)^2}{T-1} }{2 \sigma^2}\right) \]</span></p>
<p>Note that the second <span class="math">\(\exp\)</span> term does not depend on <span class="math">\(a\)</span>. The remaining argument has Gaussian form in <span class="math">\(da\)</span>, so after pulling out the constant terms we can easily integrate this over <span class="math">\(da\)</span>. (Note that we have an implicit uniform prior on <span class="math">\(a\)</span> here).</p>
<p><span class="math">\[ \int \exp\left(\frac{-\left(\frac{\sum_t^{T-1} M_t}{T-1} - a \right)^2}{2 \sigma^1 (T-1)^{-1} } \right) d a  = \sqrt{\frac{2\pi\sigma^2}{T-1}}\]</span></p>
<p>which we can combine with the remaining terms to recover</p>
<p>$  ( )$$</p>
<h2 id="marginalizing-over-sigma">marginalizing over <span class="math">\(\sigma\)</span></h2>
<p>Now that we have effectively eliminated the parameter <span class="math">\(r\)</span> from our posterior calculation, we wish to also integrate out the second parameter, <span class="math">\(\sigma\)</span>. Once again we can “integrate by analogy;” the expression above in the variable <span class="math">\(\sigma^2\)</span> looks like a Gamma distribution,</p>
<p><span class="math">\[ \int x^{\alpha - 1} e^{-\beta x} dx = \frac{\beta^{\alpha}}{\Gamma(\alpha)} \]</span></p>
<p>Where we take</p>
<p><span class="math">\[ \alpha = T/2\]</span></p>
<p>and</p>
<p><span class="math">\[ \beta = \frac{1}{2} \left( \sum M_t^2 - \frac{ \left( \sum M_t \right)^2}{T - 1}\right) \]</span>,</p>
<p>leaving us with</p>
<p><span class="math">\[\frac{1}{(T-1)\sqrt{2 \pi}^{T-2} } \frac{\tfrac{1}{2}^{T/2} \left( \sum M_t^2 - \frac{ \left( \sum M_t \right)^2}{T - 1}\right)^{T/2}}{\Gamma(T/2)} \]</span></p>
<h2 id="additional-recruitment-functions">Additional recruitment functions</h2>
<p>The above derivation can be followed identically for the three-parameter recruitment functions I refer to as the Allen and Myers models after an appropriate choice of <span class="math">\(M_t\)</span>. In both the Ricker and Allen models we must first reparamaterize the models to isolate the <span class="math">\(\alpha\)</span> term correctly.</p>
<h4 id="ricker">Ricker</h4>
<p>The original parameterization</p>
<p><span class="math">\[ X_{t+1} = X_t e^{r \left( 1 - \frac{X_t}{K}\right)}\]</span> does not partition into the form above. Taking <span class="math">\(\beta =  \tfrac{r}{K}\)</span> and <span class="math">\(a = r\)</span>, we can write <span class="math">\(M_t\)</span> as above,</p>
<p><span class="math">\[M_t := \log X_{t+1} - \log X_t + \beta X_t\]</span></p>
<h4 id="myers">Myers</h4>
<p><span class="math">\[ X_{t+1} = \frac{ r X_t^{\theta} }{1 + \frac{X_t^{\theta}}{K} } Z_t\]</span></p>
<p>For <span class="math">\(Z_t\)</span> lognormal with log-mean zero and log-standard-deviation <span class="math">\(\sigma\)</span>, The log-likelihood takes the form</p>
<p>and thus we can write <span class="math">\(M_t\)</span> as</p>
<p><span class="math">\[M_t := \log X_{t+1} - \theta \log X_t + \log\left(1 +  \frac{X_t^{\theta}}{K} \right)\]</span></p>
<h4 id="allen">Allen</h4>
<p>The original parameterization</p>
<p><span class="math">\[ X_{t+1} = Z_t X_t e^{r \left( 1 - \frac{X_t}{K} \right) \frac{\left(X_t - \theta\right)}{K}} \]</span></p>
<p>does not let us isolate an additive constant (log-mean term) as we did in the example above. Writing the argument of the exponent in standard quadratic form,</p>
<p><span class="math">\[ X_{t+1} = Z_t X_t e^{c + b X+t + a X_t^2} \]</span></p>
<p>Where</p>
<p><span class="math">\[c = \tfrac{-rC}{K}\]</span> <span class="math">\[b = \tfrac{r}{K}\left(\tfrac{C}{K} + 1\right)\]</span> <span class="math">\[a = \tfrac{r}{K^2}\]</span></p>
<p>then</p>
<p><span class="math">\[M_t := \log X_{t+1} - \log X_t - b X_t + a X_t^2 \]</span></p>
 
<!-- not that raw_content depends on custom generator, 
     see _plugins/jekyll-labnotebook-plugins/raw_content --> 
</article> 
<p> <a href="/2013/06/04/analytic-marginalizing-for-posteriors.html"> <em>Read more</em></a> </p>
<br />
<br />


        </div>
      
        <div class="span3">
          <header><h4><a href="/2013/06/03/DOI-citable.html">DOI != citable</a></h4></header>
<p><span></span></p>
<p style="font-style:italic"> 03 Jun 2013</p>

<p style="font-style:italic"> pageviews: 350 </p>

<article>
<div class="excerpt">
<p>I feel I see this kind of comment almost daily:</p>
<blockquote class="twitter-tweet" data-partner="tweetdeck"><p>
Is there a way to obtain DOI for a <a href="https://twitter.com/github">@github</a> repository? (for citing <a href="https://twitter.com/search?q=%23opensource&amp;src=hash">#opensource</a> software packages, similar to <a href="https://twitter.com/figshare">@figshare</a> objects) <a href="https://twitter.com/search?q=%23git&amp;src=hash">#git</a>
</p>
— Ahmed Moustafa (@AhmedMoustafa) <a href="https://twitter.com/AhmedMoustafa/statuses/339727912896954369">May 29, 2013</a>
</blockquote>
<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script>

<p>Again and again, researchers suggest that DOI to makes something “citable”. And this <a href="https://twitter.com/cboettig/status/337986074624282624">frustrates me</a>.</p>
<p>Don’t get me wrong. I love DOIs, and I love CrossRef. And I bang on the table when I have some old journal article that doesn’t yet have a DOI. I use DOIs every day in many ways. I use CrossRef’s APIs all the time to draw in metadata for citations in my notebook (through my <a href="http://github.com/cboettig/knitcitations">knitcitations</a> package), and to import metadata into my reference manager, Mendeley. I’ve written my own implementations in R and ruby, and keep an eye on their exciting new tools on the <a href="https://github.com/crossref">Crossref Github page</a>. I wrote to bibsonomy when I realized they were not using the CrossRef API to look up metadata by DOIs, and they have now implemented this feature. I use DOIs to look up papers I’ve come across, and to share content I am reading. (Crossref’s <a href="http://shortdoi.org/">DOI shortener</a> is great for this). I even use DOI-based links to <a href="http://carlboettiger.info/2013/02/22/semantic-citations-for-the-notebook-and-knitr.html">embed semantic information</a> into links and citations of articles.</p>
<p>But I still have no idea what researchers mean when they suggest that this makes something <em>citable</em>.</p>
<h3 id="some-background-on-dois">Some background on DOIs</h3>
<p>At its heart, a DOI is a very simple concept. It is a “permanent identifier”. All this means is that is is really just a URL redirect. Type http://dx.doi.org/mnn into any browser and get redirected to where the article actually lives. Why does that make it permanent? Because if the journal decides to change their URL structure, the DOI’s redirect can just be mapped to the new address and voila, it still works. That is, a DOI is simply a tool to fight <a href="https://en.wikipedia.org/wiki/Link_rot">link-rot</a>.</p>
<p>So you might ask, why does the ability to remap the address have anything to do with being “permanent?” It doesn’t, really. The permanence comes not so much from the technology as from the social contract that goes with it. As CrossRef’s <a href="http://blogs.plos.org/mfenner/2009/02/17/interview_with_geoffrey_bilder/">Geoffery Bilder eloquently explains</a>, a publisher can only receive DOIs if they promise to keep these redirects up-to-date. A publisher who fails to maintain this responsibility would presumably lose their right to receive DOIs. A brilliant, simple, social incentive.</p>
<p>This still does not guarantee permanence – e.g. what would happen to the content if the publisher disappears. That problem is not addressed by the DOI technology itself, but by a robust backup archiving solution, such as <a href="http://clockss.org">CLOCKSS</a>, which provides a geo-politically distributed network of backup copies for many journals. Again the social contract comes into play – presumably CrossRef would not provide a publisher with DOIs if they did not have such a robust archival solution in place.</p>
<p>So far we have seen two crucial functions of the DOI – as a permanent identifier that can be used to reach the content despite link rot, and as an incentive to maintain good archival backups of the content and the links to it.</p>
<h3 id="what-do-we-mean-by-citations-anyway">What do we mean by citations, anyway?</h3>
<p>So what does this have to do with being citable? Obviously these are nice properties to have for things we cite – but they are by no means a requirement. (As <a href="https://twitter.com/noamross/status/337987521243918337">Noam Ross observes</a>, try finding a permanent identifier for “Personal Communication”). Books, reports, and other grey literature frequently appear in citations, as do links to websites. MLA even has guidelines on the proper format to <a href="http://www.mla.org/style/handbook_faq/cite_a_tweet">cite a tweet</a> (which, incidentally, come closer to having a permanent identifier and an archival strategy than most other things in this list). So what do we mean by citable anyway?</p>
<p>But what about the reference list? While a publisher may be just fine including some link to your software, is it really cited if it isn’t in the reference list? Journals restrict what appears in the reference list because these references are indexed by the infamous citation counters like Thompson-Reuters. (A frequent complaint is that many journals do not similarly index citations appearing in the reference list of the supplementary materials, making it difficult or impossible to give appropriate attribution to large numbers of data providers, for instance). Does having a DOI address this problem?</p>
<h4 id="citation-counts-in-dois">Citation counts in DOIs</h4>
<p>Counting citations depends on who is counting them. The most well-known is Thompson-Reuters, which has their own process for deciding what gets counted (based on publisher), so no guarantee there. Meanwhile Google Scholar counts anything meeting it’s <a href="http://carlboettiger.info/2012/11/23/citing-lab-notebook-entries.html">indexing requirements &amp; arbitrary selection</a>. I have recently learned that CrossRef just launched it’s own <a href="https://github.com/articlemetrics/alm/wiki/Crossref">internal citation counting</a>, which is available from the CrossRef metadata (totals only for the public, publishers can resolve which articles did the citing…). However, most proposals to make some alternative research product “citable” by giving it a DOI use DataCite DOIs (e.g. fig<strong>share</strong>, PeerJ Preprints), which lag behind in this feature. Moving the control of citation data beyond the grasp of particular publishing companies like TR is undoubtedly an important step forward. The <a href="http://www.jisc.ac.uk/whatwedo/programmes/inf11/jiscexpo/jiscopencitation.aspx">Open Citation Project</a> is a more comprehensive, if very young, move in this direct. (Hat tip to Martin Fenner for explaining CrossRef citations to me).</p>
<h3 id="additional-metadata">Additional Metadata</h3>
<p>In addition to resolving links, DOI providers also serve a rich collection of metadata about the publication that can be <a href="http://www.crosscite.org/cn/">queried by DOI</a> or by <a href="https://github.com/CrossRef/cr-search">other elements</a> like author and title. Rich semantic formats and disambiguation of author names by connections to ORCID IDs are among the many advantages of this. Because many of these tools are publicly accessible by through their APIs, it is easy for other developers to build services upon them.</p>
<h2 id="conclusions">Conclusions</h2>
<p>While DOI providers have done an excellent job in ensuring persistent URLs, archived content, and valuable metadata, these things are largely the product of the social contract between publisher and the DOI provider. It is not possible for an author or organization to simply “get DOIs” for all their content. But it is not the only way to provide these features, either. While I understand the value in providing a simple and reliable way to encapsulate each of these concepts as “has a DOI,” it also appears to put these features beyond the reach of individual researchers. If issues of persistent URLs, archived content, and rich metadata tools are always reduced to “has a DOI,” publishers become the only path to achieve these ends. On the contrary, a rich collection of tools is available to researchers.</p>
<p>So what do we mean when we say a DOI makes something ‘citable?’ If this is shorthand for the properties we would want in something citable: persistent identifier, archival content, machine-readable metadata, than we should start to recognize other things that share these features. Further innovation requires valuing the features the DOI provides, not simply a “brand name” researchers recognize.</p>
<h2 id="alternative-tools">Alternative tools</h2>
<p>In a <a href="http://purl.org/cboettig/2013/05/31/notebook-features-digital-archiving">recent post</a> in a series on technical features of my open notebook, I discuss some of the tools available to address these challenges. In particular:</p>
<ul>
<li>The use of <a href="http://en.wikipedia.org/wiki/Persistent_uniform_resource_locator">PURLs</a> for persistent identifiers</li>
<li>Git for archival redundancy</li>
<li><a href="http://greycite.knowledgeblog.org">Greycite</a> for metadata extraction</li>
</ul>
<p>Of course, if you ever need a DOI for a research product, there is always <a href="http://figshare.com">figshare</a>.</p>
 
<!-- not that raw_content depends on custom generator, 
     see _plugins/jekyll-labnotebook-plugins/raw_content --> 
</article> 
<p> <a href="/2013/06/03/DOI-citable.html"> <em>Read more</em></a> </p>
<br />
<br />


        </div>
      
    </div>

    <div class="row">
      
        <div class="span3">
          <header><h4><a href="/2013/06/03/ADMB-basic-example.html">Admb Basic Example</a></h4></header>
<p><span></span></p>
<p style="font-style:italic"> 03 Jun 2013</p>

<p style="font-style:italic"> pageviews: 10 </p>

<article>
<div class="excerpt">
<p>After a few <a href="https://github.com/cboettig/nonparametric-bayes/commits/b4576cfc0b5a0c87701348976875c8657f0fd048/inst/examples/admb-example.md">iterations</a> I have a working minimal example (below). Hoping that ADMB is a bit more robust than vanilla <code>optim</code> out of R as I loop over data sets for the sensitivity analysis (<a href="https://github.com/cboettig/nonparametric-bayes/issues/32">#32</a>). Does not seem to hold in simple example here, not sure why.</p>
<ul>
<li>These notes correspond to script <a href="https://github.com/cboettig/nonparametric-bayes/blob/84a1025854987ef659b4ef17e172933d72547f6d/inst/examples/admb-example.md">84a102/admb-example.md</a></li>
</ul>
<h1 id="learning-admb">Learning ADMB</h1>
<p>Plotting and knitr options, (can generally be ignored)</p>
<h3 id="model-and-parameters">Model and parameters</h3>
<pre class="sourceCode r"><code class="sourceCode r">f &lt;- function(x,h,p)  x * <span class="kw">exp</span>(p[<span class="dv">1</span>] * (<span class="dv">1</span> - x / p[<span class="dv">2</span>]) * (x - p[<span class="dv">3</span>]) / p[<span class="dv">2</span>] ) 
p &lt;- <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">10</span>, <span class="dv">5</span>)
K &lt;- <span class="dv">10</span>  <span class="co"># approx, a li&#39;l&#39; less</span>
Xo &lt;- <span class="dv">6</span> <span class="co"># approx, a li&#39;l&#39; less</span></code></pre>
<p>Various parameters defining noise dynamics, grid, and policy costs.</p>
<pre class="sourceCode r"><code class="sourceCode r">sigma_g &lt;- <span class="fl">0.1</span>
z_g &lt;- function() <span class="kw">rlnorm</span>(<span class="dv">1</span>,<span class="dv">0</span>, sigma_g)
x_grid &lt;- <span class="kw">seq</span>(<span class="dv">0</span>, <span class="fl">1.5</span> * K, <span class="dt">length=</span><span class="dv">50</span>)
Tobs &lt;- <span class="dv">40</span>
<span class="kw">set.seed</span>(<span class="dv">123</span>)</code></pre>
<h3 id="sample-data">Sample Data</h3>
<pre class="sourceCode r"><code class="sourceCode r">x &lt;- <span class="kw">numeric</span>(Tobs)
x[<span class="dv">1</span>] &lt;- Xo
for(t in <span class="dv">1</span>:(Tobs<span class="dv">-1</span>))
  x[t<span class="dv">+1</span>] = <span class="kw">z_g</span>() * <span class="kw">f</span>(x[t], <span class="dt">h=</span><span class="dv">0</span>, <span class="dt">p=</span>p)
<span class="kw">qplot</span>(<span class="dv">1</span>:Tobs, x)</code></pre>
<figure>
<img src="http://farm3.staticflickr.com/2807/8956942302_0d7d47ea49_o.png" alt="plot of chunk obs" /><figcaption>plot of chunk obs</figcaption>
</figure>
<h2 id="maximum-likelihood-by-hand">Maximum Likelihood “by hand”</h2>
<pre class="sourceCode r"><code class="sourceCode r">STABLIZE = <span class="fl">1e-10</span>
n = <span class="kw">length</span>(x)
mloglik &lt;- function(pars){ 
  r = pars[<span class="dv">1</span>]; k = pars[<span class="dv">2</span>]; c = pars[<span class="dv">3</span>]; s = pars[<span class="dv">4</span>];
  mu = (x+STABLIZE) * <span class="kw">exp</span>( r * (<span class="dv">1</span> - x / (k+STABLIZE)) * (x - c) / (k + STABLIZE));
  mu = <span class="kw">pmin</span>(<span class="fl">1e100</span>, mu) <span class="co"># avoid infinite values </span>
  f = <span class="fl">0.5</span> * n * <span class="kw">log</span>(<span class="dv">2</span> * pi) + n * <span class="kw">log</span>(s + STABLIZE) + <span class="fl">0.5</span> * <span class="kw">sum</span>(x - mu + STABLIZE)^<span class="dv">2</span>/ (s + STABLIZE)^<span class="dv">2</span>;

  f
  }</code></pre>
<p>Starting from the true values we mostly just shrink the noise parameter:</p>
<pre class="sourceCode r"><code class="sourceCode r">init &lt;- <span class="kw">c</span>(p, sigma_g)
<span class="kw">mloglik</span>(init) <span class="co">#true minus loglik</span></code></pre>
<pre><code>[1] -35.72</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">o &lt;- <span class="kw">optim</span>(init, mloglik, <span class="dt">method=</span><span class="st">&quot;L&quot;</span>, <span class="dt">lower=</span><span class="fl">1e-5</span>, <span class="dt">upper=</span><span class="fl">1e5</span>)
o$value</code></pre>
<pre><code>[1] -247.6</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">o$par</code></pre>
<pre><code>[1] 0.9967297 9.9813554 5.1742699 0.0008183</code></pre>
<p>While starting from arbitrary values we still find the optim.</p>
<pre class="sourceCode r"><code class="sourceCode r">init &lt;- <span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>)  
init &lt;- <span class="kw">c</span>(p, sigma_g)
<span class="kw">mloglik</span>(init) <span class="co">#true minus loglik</span></code></pre>
<pre><code>[1] -35.72</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">o &lt;- <span class="kw">optim</span>(init, mloglik, <span class="dt">method=</span><span class="st">&quot;L&quot;</span>, <span class="dt">lower=</span><span class="fl">1e-5</span>, <span class="dt">upper=</span><span class="fl">1e5</span>)
o$value</code></pre>
<pre><code>[1] -247.6</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">o$par</code></pre>
<pre><code>[1] 0.9967297 9.9813554 5.1742699 0.0008183</code></pre>
<p>Okay, now lets try admb. We use R2admb which is just a convenient way to write our data and parameters into an admb file.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># install_github(&quot;R2admb&quot;, &quot;bbolker&quot;, subdir=&quot;R2admb&quot;) # dev version</span>
<span class="kw">library</span>(R2admb)</code></pre>
<h2 id="admb-definition">ADMB definition</h2>
<p>We still need to define the model using ADMB notation in the procedure section. This is mostly like R or C++, with the exception of special functions like <code>square</code> in place of <code>^2</code>, <code>norm2</code> for the sum of squares, and <code>elem_prod</code> istead of <code>*</code> for the element-wise product of two arrays. The constant <code>pi</code> is given as <code>M_PI</code>, as typical of C/C++ libraries. Where these other functions are defined I’m not sure, but some useful guides to <a href="http://fish.washington.edu/research/MPAM/resources/ADMB_Minte-Vera.pdf">ADMB vector/matrix operations</a> or an (undefined) list of <a href="http://www.admb-project.org/developers/contribute-documentation/functions/keywords.txt/view">keywords</a>…</p>
<p>The equivalent model</p>
<pre class="sourceCode r"><code class="sourceCode r">model &lt;- 
<span class="kw">paste</span>(<span class="st">&quot;</span>
<span class="st">PARAMETER_SECTION</span>
<span class="st">  vector mu(1,n) // per capita mort prob</span>
<span class="st">      </span>
<span class="st">PROCEDURE_SECTION</span>
<span class="st">  mu = log(x) + r * elem_prod((1 - x / k), (x - c) / k);</span>
<span class="st">  f = 0.5 * n * log(2 * M_PI) + n * log(s) + 0.5 * norm2(x - exp(mu)) / square(s);</span>
<span class="st">&quot;</span>)
<span class="kw">writeLines</span>(model, <span class="st">&quot;model.tpl&quot;</span>)</code></pre>
<p>Without explicit handling of the overflow errors, ADMB does not give us reliable estimates with arbitrary starting conditions</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">setup_admb</span>(<span class="st">&quot;/var/admb&quot;</span>)</code></pre>
<pre><code>[1] &quot;/var/admb&quot;</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">
df &lt;- <span class="kw">data.frame</span>(<span class="dt">x=</span>x)
params &lt;- <span class="kw">list</span>(<span class="dt">r =</span> <span class="dv">1</span>, <span class="dt">k =</span> <span class="dv">1</span>, <span class="dt">c =</span> <span class="dv">1</span>, <span class="dt">s =</span> <span class="dv">1</span>) ## starting parameters
bounds &lt;- <span class="kw">list</span>(<span class="dt">r =</span> <span class="kw">c</span>(<span class="fl">1e-10</span>, <span class="fl">1e3</span>), <span class="dt">k=</span><span class="kw">c</span>(<span class="fl">1e-10</span>, <span class="fl">1e3</span>), <span class="dt">c=</span><span class="kw">c</span>(<span class="fl">1e-10</span>, <span class="fl">1e3</span>), <span class="dt">s =</span> <span class="kw">c</span>(<span class="fl">1e-5</span>,<span class="fl">1e3</span>)) ## bounds
dat &lt;- <span class="kw">c</span>(<span class="kw">list</span>(<span class="dt">n =</span> <span class="kw">nrow</span>(df)), df)
m1 &lt;- <span class="kw">do_admb</span>(<span class="st">&quot;model&quot;</span>,
              <span class="dt">data =</span> dat,
              <span class="dt">params =</span> params,
              <span class="dt">bounds =</span> bounds,
              <span class="dt">run.opts =</span> <span class="kw">run.control</span>(<span class="dt">checkparam=</span><span class="st">&quot;write&quot;</span>,
                                     <span class="dt">checkdata=</span><span class="st">&quot;write&quot;</span>, <span class="dt">clean=</span><span class="ot">FALSE</span>))
m1</code></pre>
<pre><code>Model file: model_gen 
Negative log-likelihood: 146.5 
Coefficients:
     r      k      c      s 
0.9992 1.0023 1.0004 9.4369 </code></pre>
<p>But does fine with good starting values. Hmm.. thought that was supposed to be the other way around…</p>
<pre class="sourceCode r"><code class="sourceCode r">params &lt;- <span class="kw">list</span>(<span class="dt">r =</span> <span class="dv">1</span>, <span class="dt">k =</span> <span class="dv">10</span>, <span class="dt">c =</span> <span class="dv">5</span>, <span class="dt">s =</span> .<span class="dv">1</span>) ## starting parameters

m1 &lt;- <span class="kw">do_admb</span>(<span class="st">&quot;model&quot;</span>,
              <span class="dt">data =</span> dat,
              <span class="dt">params =</span> params,
              <span class="dt">bounds =</span> bounds,
              <span class="dt">run.opts =</span> <span class="kw">run.control</span>(<span class="dt">checkparam=</span><span class="st">&quot;write&quot;</span>,
                                     <span class="dt">checkdata=</span><span class="st">&quot;write&quot;</span>))</code></pre>
<pre><code>Warning: running command &#39;./model_gen &gt; model_gen.out&#39; had status 1</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">m1</code></pre>
<pre><code>Model file: model_gen 
Negative log-likelihood: -423.8 
Coefficients:
        r         k         c         s 
2.025e-10 9.498e+00 1.051e+01 1.000e-05 </code></pre>
<p>Which finds a better optim (though substantailly overfit in reality)</p>
<p>Hans suggests adding an error term in the function definitions rather than in limiting the bounds or log transforming the variables:</p>
<blockquote>
<p>The most common plase where this goes wrong is 1/0, log(0), sqrt(0), pow(0,1) etc. Your suggestion is OK, but usually I prefer to put in log(1e-10+my_expression), sqrt(1e-10+my_expression), pow(1e-10+my_expression,1)</p>
</blockquote>
<h2 id="misc">Misc</h2>
<ul>
<li><p>Finished off posts regarding DOIs and digital archiving. A shorter version appears in my answer to <a href="http://opendata.stackexchange.com/questions/694/preservation-of-blog-posts-articles-and-essays/719#719">opendata.stackexchange</a> on blog archiving.</p></li>
<li><p>Interesting discussion on using PURL redirects with SHA hash to link to repositories. For instance, the commit matching our arXiv submission of the ews-review paper is found at <a href="http://purl.org/cboettig/ews-review/33dfb58e24ceb5861dad7cf756cffe2c5d66a655">cboettig/ews-review/33dfb58e24ceb5861dad7cf756cffe2c5d66a655</a>. If the hash shown in the PURL doesn’t match the one at the repository then we know something has gone wrong, since it is impossible to change the contents without changing the hash. This gives us a version-stable identifier that can always be remapped to this commit, even if Github should disappear. Of course nothing guarentees that the PURL maintainer / package author does this updating, but in principle the system is more robust than simply linking to Github.</p></li>
<li><p>In other news, I should add some <a href="https://github.com/cboettig/labnotebook/issues/94">automatic link checking, #94</a> to the notebook.</p></li>
</ul>
 
<!-- not that raw_content depends on custom generator, 
     see _plugins/jekyll-labnotebook-plugins/raw_content --> 
</article> 
<p> <a href="/2013/06/03/ADMB-basic-example.html"> <em>Read more</em></a> </p>
<br />
<br />


        </div>
      
        <div class="span3">
          <header><h4><a href="/2013/05/31/notebook-features-digital-archiving.html">Notebook features: digital archiving</a></h4></header>
<p><span></span></p>
<p style="font-style:italic"> 31 May 2013</p>

<p style="font-style:italic"> pageviews: 21 </p>

<article>
<div class="excerpt">
<p>Note: this entry is part of a <a href="http://carlboettiger.info/2013/04/26/notebook-features-introduction.html">series of posts</a> which explain some of the technical features of my lab notebook.</p>
<p>Archival preservation of digital scholarly content is an important challenge throughout the research community. As the notebook is the permanent record of my regular scholarly endeavors, this provides the opportunity to experiment with tools and techniques for digital archiving while also better preserving the notebook. In the experimental spirit that drives all my exploration here, I am testing several ways to accomplish this. In so doing, I learn which approaches are easiest to implement, to use, and gather feedback from, while also hedging my bets in the event that any given strategy should fail.</p>
<p>Archiving digital content involves two fundamental challenges that can be difficult to satisfy simultaneously: providing a robust backup copy of the <em>content</em>, and providing a consistent location (such as a URL) where the content can be retrieved.</p>
<h2 id="a-custom-domain">A custom domain</h2>
<p>The simplest archival measure employed in the notebook comes from hosting through my own domain, <a href="http://carlboettiger.info">carlboettiger.info</a> rather than an external server. By controlling the domain structure myself, I am not tied to a University server that can be altered by an IT department without my knowledge, thereby breaking my links. When I choose to move platforms, as I did in migrating from <a href="/2012/09/19/migrating-from-wordpress-to-jekyll.html">Wordpress to Jekyll</a>, I could ensure that links would be appropriately mapped. This was not the case when I started my open notebook on the OpenWetWare platform, since links are all mapped to the <a href="http://openwetware.org">openwetware.org</a> domain which I obviously cannot control, even though I could at least migrate my content. <a href="https://github.com/cboettig/labnotebook/blob/8481569132142c850e585a2fc8c12a671527cd4f/_plugins/redirects.rb">HTML redirects</a> make sure links still resolve when I change structure (e.g. <a href="/archives/211">carlboettiger.info/archives/211</a>). I don’t have to worry about moving my domain when I change institutions, and can seamlessly migrate to a different server or DNS provider to get better rates or uptime performance.</p>
<p>Of course these advantages are also the greatest weaknesses of this approach – they all depend entirely on me. I could make or forget to make any number of changes that could cause this all to break. Time has shown that even the best-intentioned researchers are not the best curators of there own data, and no doubt I am no exception. How can the content and its identifying addresses outlive me or my interest in it?</p>
<h2 id="purls-preserving-identifiers">PURLs: preserving identifiers</h2>
<p><a href="http://purl.org">PURLs</a>, or Persistent Uniform Resource Locators, provide a DOI-like mechanism for addressing the challenge of link-rot. As <a href="http://blogs.plos.org/mfenner/2009/02/17/interview_with_geoffrey_bilder/">Geoffrey Bilder eloquently argues</a>, the technological solution is quite simple, the real challenge lies on the social side of the implementation – a social contract that promises content providers will maintain their identifiers if they want to continue to receive identifiers. Though users must register to be able to create PURLs, PURL does not provide such enforcement.</p>
<p>The PURLs solution is a bit more web-native solution than DOIs, in being more democratic, using a URL structure, and being built upon widely distributed servers and open-source web technology. Not surprisingly, other web-native systems such as most of the major semantic web ontology providers rely on PURLs, e.g. Dublin Core uses <a href="http://purl.org/dc/terms/">purl.org/dc/terms/</a>. The PURL <a href="http://purl.oclc.org/docs/faq.html">FAQ</a> provides a great overview.</p>
<p>Implementing PURLs for the notebook was very straight-forward. After registering as a user at <a href="http://purl.org">purl.org</a> I applied for my own top-level domain: <code>cboettig</code>, which I then mapped to my current domain, <a href="http://carlboettiger.info">carlboettiger.info</a> By enabling partial redirects, each page on my site will also be resolved using this top-level domain followed by my existing page structure. Following my existing structure is not necessary – I could map each page to an arbitrary path in my domain, but would have to enter these somewhat manually. While the partial redirect is simpler to implement, it does require that I maintain the rest of the link structure.</p>
<p>In this way, <a href="http://purl.org/cboettig/lab-notebook.html">purl.org/cboettig/lab-notebook.html</a> now resolves to <a href="http://carlboettiger.info/lab-notebook.html">carlboettiger.info/lab-notebook.html</a>. Likewise, each page in the notebook can be similarly resolved from the purl.org domain instead of my personal carlboettiger.info domain. Should I ever somehow lose control of carlboettiger.info, I could re-assign my PURL to redirect to my new domain URL. This provides DOI-like technology of permanent identifiers for every page in the notebook.</p>
<h2 id="github-preserving-content-and-versions">GitHub: preserving content and versions</h2>
<p>Committing content to an external repository is the recommended way to avoid link-rot from the user errors and website changes that so frequently plague self-archiving of scholarly content. Keeping multiple copies of content in geographically distinct locations is the time-honored approach of digital archiving. Git and GitHub make this easy. Not only does this mean that a backup copy is publicly available and forkable online, but it is also easy to clone copies on each of the machines I work on and rely on git to keep them in sync. Should Github disappear, a little <code>git remote add</code> and everything will be effortlessly deployed with complete history elsewhere.</p>
<p>The notebook has two Github repositories: the “source-code” consisting of plain-text (markdown) content and Jekyll-based templates on <a href="http://github.com/cboettig/labnotebook">labnotebook</a>, and a second for the rendered HTML <a href="http://github.com/cboettig/cboettig.github.com">cboettig.github.com</a> (which also now hosts the website).</p>
<p>While a custom domain and PURLs provide persistent <em>locators</em> for the content, distributed copies on Git help archive the content itself. Should my domain vanish or Github disappear, copies of the content, complete with version history, would remain distributed across various machines with a copy of the repository. Links to Github would break in that process, unless we had remapped all links from the notebook to Github using PURLs.</p>
<h2 id="greycite-programmatic-access-and-indexing-of-metadata">Greycite: Programmatic access and indexing of metadata</h2>
<p>I think of good metadata as the third leg to proper digital archiving, in addition to permanent identifiers and backup of content. We want to be able to point a tool at the permanent identifier / URL of an entry and extract reliable information on the author, time published and last modified, title, author, key words, etc. that might be useful in citing or categorizing the content. Providing this information is really the subject of adding <a href="http://carlboettiger.info/2012/10/23/semantic-markup-examples-for-the-lab-notebook.html">Semantic metadata</a> to the site, and is covered in another entry in this series. Meanwhile, the <a href="http://greycite.knowledgeblog.org">Greycite</a> tool and it’s API are an excellent way to extract this metadata into a variety of useful formats, working much the same way that CrossRef’s tool does using DOIs. Here is an <a href="http://greycite.knowledgeblog.org/?uri=http%3A%2F%2Fpurl.org%2Fcboettig%2F2012%2F10%2F23%2Fsemantic-markup-examples-for-the-lab-notebook.html">example query</a></p>
<figure>
<img src="http://farm6.staticflickr.com/5325/8940923396_fcf4941197.jpg" />
</figure>
<h2 id="robust-archiving-with-figshare"><strong>Robust archiving</strong> with fig<strong>share</strong></h2>
<p>Depositing a copy of the notebook on fig<strong>share</strong> is one of the most robust archival solutions of which I am currently aware. Not so much because it has the coveted DOI solution to the permanent identifier problem but because it has the promise of <a href="http://clocks.org">CLOCKSS</a> archiving, should anything ever happen to fig<strong>share</strong>.</p>
<p>Nevertheless, it raises several challenges. The native home for the content is as rendered HTML at my domain, not as raw HTML on an archive completely unassociated with that domain, difficult to view, and divorced from my usual workflow, unlike my usual publishing source-code to Github and website to my domain. It also raises questions of just what to archive and when. I discuss some of these strengths and challenges as a separate post, <a href="http://purl.org/cboettig/2013/05/31/notebook-features-archiving-with-figshare">archiving the lab notebook on figshare: advantages and challenges</a>.</p>
<h2 id="conclusions">Conclusions</h2>
<p>Digital archiving is a challenging problem that is not completely addressed by any one of these approaches. In the end, robust archiving will be best left in the hands of its experts. Unfortunately, the best examples currently available (such as CLOCKSS, national libraries, etc.) will not archive a researcher’s web page directly. The solutions explored here are not perfect, but they are free and simple to implement. I’d love to hear what others think.</p>
<h3 id="see-also">See also</h3>
<ul>
<li><a href="http://www.digitalpreservation.gov/ndsa/">DigitalPreservation.gov</a></li>
<li><a href="http://internetarchive.org">The Internet Archive</a></li>
</ul>
 
<!-- not that raw_content depends on custom generator, 
     see _plugins/jekyll-labnotebook-plugins/raw_content --> 
</article> 
<p> <a href="/2013/05/31/notebook-features-digital-archiving.html"> <em>Read more</em></a> </p>
<br />
<br />


        </div>
      
        <div class="span3">
          <header><h4><a href="/2013/05/31/notebook-features-archiving-with-figshare.html">Archiving the lab notebook on figshare</a></h4></header>
<p><span>Advantages and challenges</span></p>
<p style="font-style:italic"> 31 May 2013</p>

<p style="font-style:italic"> pageviews: 12 </p>

<article>
<div class="excerpt">
<h2 id="robust-archiving-through-clockss">Robust archiving through CLOCKSS</h2>
<p>One of the most comprehensive approaches I have come across so far uses fig<strong>share</strong>. This offers the most promising avenue for content preservation, but is weakest in managing the URIs and associating them with the original content. All fig<strong>share</strong> content is archived by <a href="http://clockss.org">CLOCKSS</a>, an international library cooperation providing redundant and geopolitically distributed backup of the archives around the world (and used by many academic journals, both subscription based &amp; open access). Should fig<strong>share</strong> vanish from the face of the planet, it will trigger the release of all of its content to resolve through the CLOCKSS servers, with the same appearance and resolving at the same URLs as the original figshare content. Presumably the DOIs provided to figshare content will also continue to resolve there.</p>
<h2 id="challenges">Challenges</h2>
<p>It would certainly be preferable to have the notebook archived by CLOCKSS directly, since the association between the original online content at carlboettiger.info is lost in archiving the entries on figshare. More problematically, the content as archived on fig<strong>share</strong> is not recognized by search engines, etc., as a separate HTML pages to index, but merely as a bundle of attached text files. On the upside, the content becomes part of the global scientific datasets preserved and indexed by fig<strong>share</strong> with appropriate metadata, etc., increasing the chances for discovery through that venue. Also, fig<strong>share</strong> provides a convenient API that can help automate deposition.</p>
<h3 id="what-content-what-format">What content? What format?</h3>
<p>Deciding just what to archive in the fig<strong>share</strong> database is also less straight forward than it may seem. I have gone through a few iterations:</p>
<ol type="1">
<li>Archiving the markdown.<br /></li>
<li>Archiving external images with Data URIs.<br /></li>
<li>Archiving the HTML versions of pages alone</li>
<li>Archiving the whole git repository, <code>_site</code> HTML included (?)</li>
</ol>
<p>I began by archiving the markdown files that I write to create each entry. These are plain-text files that can be easily read in any text editor, even if the conventions for rendering them as HTML are lost. Like HTML, figures are linked to external files, and are thus not captured by this solution. To work around this, I adopted the trick of using <a href="http://carlboettiger.info/2013/01/24/Data-URIs-for-image-archives.html">Data URIs</a> to embed images. This places a binary encoding of the image in the text itself, which can be rendered by almost any browser as the appropriate image. While this keeps the content together, the long data URI strings are rather out-of-place inside a plain text document. Further, the markdown loses all of the valuable semantics that are automatically added to each page when Jekyll renders them to HTML. As Phil Lord argues, if there’s any format that future archivists can read successfully – it will be HTML. Consequently I’ve settled on archiving the HTML versions of each notebook entry, with images embedded as Data URIs. Each HTML file contains rich metadata in the header, sidebar, and footer, that give more information about the content and its context in the notebook (relative path, categories and tags, timestamps and SHA hashes, etc). I have archived these entries in annual chunks following the year/month/day directory structure already employed on the site.</p>
<h3 id="how-about-site-assets">How about site assets?</h3>
<p>There is still additional external content used to render the site – CSS and javascript files – that are not captured in this approach. Though entries actually render <a href="http://stackoverflow.com/questions/14046738">just fine without the css</a>, it would certainly be possible to include this material in the archive (though some Javascript comes from external CDNs). This does make for a bit larger and more cluttered archive, and more to the point is a rather crude solution to a problem already solved by Internet archiving programs such as CLOCKSS or internetarchive.org.</p>
<h3 id="versioning">Versioning?</h3>
<p>Lastly there is the concern of preserving the version history of entries. Though fig<strong>share</strong> provides versioning of its content, this doesn’t capture finer resolution of individual page changes available through the Github repository. At the expense of creating an ever more cumbersome archival object, one could include the <code>.git</code> history, either for the HTML rendered version (which lives at <a href="https://github.com/cboettig/cboettig.github.com/">cboettig.github.com</a>) or the source files used to create it (<a href="https://github.com/cboettig/labnotebook">labnotebook</a>).</p>
<h3 id="connecting-to-the-original-instances">Connecting to the original instances?</h3>
<p>Of course this fails to address the preservation of externally linked content. The most frequent outbound links point to other publications through, usually their DOIs, which we hope will take care of themselves. The most important externally linked content in the notebook entries are the links to scripts, functions, and manuscripts in the various project repositories on Github. The simplest solution is to embed the most important scripts in the notebook entries themselves. Archiving the project repositories is an additional challenge, but if a user can recover a copy of the project repository (along with it’s <code>.git</code> history) then it would be possible to identify the linked file using the SHA hash from these links (by matching it against the SHAs in the log). See my entry on <a href="/2013/05/03/notebook-features-hashes-providing-an-immutable-and-verifiable-research-record.html">SHA hashes</a> for more on this topic.</p>
<h2 id="links-to-the-archives">Links to the archives</h2>
<p>Current and previous archives of my lab notebook can be found on figshare by year. Older versions of these archives have taken a different approach, including just archiving the markdown files. The links use the DOI and point to the most recent version. (At this time linking to explicit versions with FigShare’s DataCite DOI links doesn’t appear to be working)</p>
<ul>
<li><a href="http://dx.doi.org/10.6084/m9.figshare.96916">Lab Notebook, 2010</a></li>
<li><a href="http://dx.doi.org/10.6084/m9.figshare.96919">Lab Notebook, 2011</a></li>
<li><a href="http://dx.doi.org/10.6084/m9.figshare.106620">Lab Notebook, 2012</a></li>
</ul>
 
<!-- not that raw_content depends on custom generator, 
     see _plugins/jekyll-labnotebook-plugins/raw_content --> 
</article> 
<p> <a href="/2013/05/31/notebook-features-archiving-with-figshare.html"> <em>Read more</em></a> </p>
<br />
<br />


        </div>
      
    </div>

  </div>
</div> <!--end row -->

<div class="row">
  <div class="span11 offset1">
    <div class="socialicons">
      <p> <a href="/archive.html"><i class="icon-calendar"></i> All entries by date</a></p> 
      <p> <a href="/categories.html"><i class="icon-list"></i> All entries by category</a> </p>
      <p> <a href="/tags.html"><i class="icon-tags"></i> All entries by tag</a> </p>
    </div>
  </div> <!--end span9 -->
</div> <!--end row -->




<footer class="footer">
  <!-- ************* Buttons to toggle theme CSS ********************** -->
    <div class="row">
      <div class="span12">
        <form style="font-size:10px" class="pull-right">
          <a onclick="switch_style('dark'); 
                      recordOutboundLink(this, 'Outbound Links', 'dark theme'); 
                      return false;" 
             name="theme" value="dark" id="dark" 
             class="btn btn-mini"><span class="showtooltip" 
                                        title="switch to dark theme"><i class="icon-adjust"></i>
                                   </span></a>
          
          <a onclick="switch_style('light'); 
                      recordOutboundLink(this, 'Outbound Links', 'light theme'); 
                      return false;" 
             name="theme" value="light" id="light" 
             class="btn btn-mini"><span class="showtooltip" 
                                        title="switch to light theme"><i class="icon-certificate"></i>
           <a onclick="switch_style('white'); 
                      recordOutboundLink(this, 'Outbound Links', 'white theme'); 
                      return false;" 
             name="theme" value="white" id="white" 
             class="btn btn-mini"><span class="showtooltip" 
                                        title="switch to white theme"><i class="icon-circle-blank"></i>
                                  </span></a>
                                 </span></a>
        </form>
      </div>
    </div>

<!--************** FOAF information to social networks ***************************** -->
  <div class="row">
    <div class="span3 socialicons" style="font-size:20px" typeof="foaf:Person" about="http://carlboettiger.info#me">
      <p>
          <script type="text/javascript" src="/assets/js/obfuscate-email-link.js" language="javascript"></script> 
          <a rel="foaf:account" alt="twitter" href="https://twitter.com/cboettig" 
             onclick="recordOutboundLink(this, 'Outbound Links', 'Twitter'); 
             return false;"><span class="showtooltip" title="follow me on twitter (reading, discussing)"><i class="icon-twitter"></i></span></a> 
          <a rel="foaf:account" alt="github" href="https://github.com/cboettig" 
             onclick="recordOutboundLink(this, 'Outbound Links', 'Github'); 
             return false;"><span class="showtooltip" title="follow me on Github (code, research)"><i class="icon-github"></i></span></a>
      <!--
          <a rel="foaf:account" href="https://plus.google.com/" 
             onclick="recordOutboundLink(this, 'Outbound Links', 'GPlus'); 
             return false;"><i class="icon-google-plus"></i></a>
          <a rel="foaf:account" href="http://www.mendeley.com/profiles/carl-boettiger" 
             onclick="recordOutboundLink(this, 'Outbound Links', 'Mendeley'); 
             return false;"><img src="/assets/img/icon-mendeley.png" alt="mendeley" /></a> 
           citations on google-scholar
           stackoverflow
      -->
      <a alt="rss" type="application/atom+xml" href="/atom.xml"  
         class="showtooltip" title="subscribe to RSS feeds for my open lab notebook" 
         onclick="recordOutboundLink(this, 'Outbound Links', 'RSS'); 
         return false;"><i class="icon-rss"></i></a>
       </p>
    </div>
    <!--**************** End social links **************************** -->
    <div class="span1">
      <br />
    </div>
    <div class="span4">
      <p>
      <a onclick="recordOutboundLink(this, 'Outbound Links', 'ONS_claim'); return false;" href="http://onsclaims.wikispaces.com/"><img src="http://onsclaims.wikispaces.com/file/view/ons-aci2-icon.png" alt="ONS" class="showtooltip" title="An Open Notebook Science (ONS) project claim: Entry provides all content (AC) immediately (I) or without significant delay.  See link for details"/></a>

      <a title="This site uses linked data semantics. Click to extract as RDF XML." class="btn btn-mini showtooltip" style="font-size: .8em" 
       href="http://any23.org/?format=rdfxml&validate=validate&uri=http://carlboettiger.info/lab-notebook.html"><i 
         class="icon-cloud-download"  onclick="recordOutboundLink(this, 'Outbound Links', 'RDF'); return false;"></i> RDF</a>
      </p>
    </div>
    <div class="span1">
      <br />
    </div>
    <div class="span3">
      <p>
      <a rel="license" property="http://creativecommons.org/ns#license" href="http://creativecommons.org/publicdomain/zero/1.0/" onclick="recordOutboundLink(this, 'Outbound Links', 'CC0'); return false;"><img src="http://i.creativecommons.org/l/zero/1.0/88x31.png" alt="CC0"/></a> 
      </p>
    </div>

  </div>
  
<!-- COinS metadata (for citation managers like Zotero etc), goes in body text -->
  <span
      class="Z3988" 
      title="ctx_ver=Z39.88-2004
      &amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Adc
      &amp;rfr_id=info%3Asid%2Focoins.info%3Agenerator
      &amp;rft.title=Lab Notebook
      &amp;rft.creator=Carl Boettiger
      &amp;rft.date=
      &amp;rft.language=EN
      &amp;rft.rights=CC0
      &amp;rft_id=http://carlboettiger.info/lab-notebook.html">
  </span>



</footer>




    <!-- Le javascript
    ================================================== -->

    <!-- Placed at the end of the document so the pages load faster -->
    <!-- JQuery, used on a few pages -->
    <script type="text/javascript" src="/assets/js/jquery.js"></script>
    <!-- Equations using MathJax -->
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config"> MathJax.Hub.Config({ TeX: { equationNumbers: {autoNumber: "all"} } });       </script>
    <!-- Twitter Bootstrap Javascript -->
    <script src="/assets/js/bootstrap.min.js"></script>
    <!-- Tooltip javascript -->
    <script type="text/javascript">
      $(document).ready(function (){
        $(".showtooltip").tooltip();
      });
    </script>

    <!-- Marran's Search Javascript -->
    <script type="text/javascript" src="/assets/js/porter-stemmer.js"></script>
    <script type="text/javascript" src="/assets/js/site-search.js"></script>

    <!-- Code collapse Javascript -->
    <script type="text/javascript">
    $(document).ready(function(){
      $("#toggle_code").click(function(){
        $(".highlight").toggle();
        $(".sourceCode").toggle();
      });
    });
    </script>


  <script type="text/javascript">
          var _gaq = _gaq || [];
          _gaq.push(['_setAccount', 'UA-18401403-1']);
          _gaq.push(['_trackPageview']);
          (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
          })();
  </script>



<script type="text/javascript">
function recordOutboundLink(link, category, action) {
  try {
    var pageTracker=_gat._getTracker("UA-18401403-1");
    pageTracker._trackEvent(category, action);
    setTimeout('document.location = "' + link.href + '"', 100)
  }catch(err){}
}
</script>




    


    </div>
  </body>
</html>


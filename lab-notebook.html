<!DOCTYPE html>
<html lang="en" xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
  <head prefix="dc: http://purl.org/dc/terms/ og: http://ogp.me/ns#">
  <meta http-equiv='Content-Type' content='text/html; charset=utf-8'/>
  <title>Lab Notebook</title>
  <meta name="author" content="Carl Boettiger" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  

<!-- Some liquid code so that pages get the site.time creation date 
      Would be nice to use github modified times, but doesn't handle 
      the path for pages -->







<!-- HTML5 metadata -->
<meta name="keywords" content="" />
<meta name="description" content="" />
<meta name="resource_type" content="website"/> 
<!-- RDFa Metadata (in DublinCore) -->
<meta property="dc:title" content="Lab Notebook" />
<meta property="dc:creator" content="Carl Boettiger" />
<meta property="dc:date" content="2013-06-03T14:13:38-07:00" />
<meta property="dc:format" content="text/html" />
<meta property="dc:language" content="en" />
<meta property="dc:identifier" content="/lab-notebook.html" />
<meta property="dc:rights" content="CC0" />
<meta property="dc:source" content="Lab Notebook" />
<meta property="dc:subject" content="Ecology" /> 
<meta property="dc:type" content="website" /> 
<!-- RDFa Metadata (in OpenGraph) -->
<meta property="og:title" content="Lab Notebook" />
<meta property="og:author" content="http://www.carlboettiger.info/index.html#me" />  <!-- Should be Liquid? URI? -->
<meta property="http://ogp.me/ns/profile#first_name" content="Carl"/>
<meta property="http://ogp.me/ns/profile#last_name" content="Boettiger"/>
<meta property="http://ogp.me/ns/article#published_time" content="2013-06-03T14:13:38-07:00" />
<meta property="og:site_name" content="Lab Notebook" /> <!-- Same as dc:source? -->
<meta property="og:url" content="http://www.carlboettiger.info/lab-notebook.html" />
<meta property="og:type" content="website" /> 
<!-- Google Scholar Metadata -->
<meta name="citation_author" content="Carl Boettiger"/>
<meta name="citation_date" content="2013-06-03T14:13:38-07:00"/>
<meta name="citation_title" content="Lab Notebook"/>
<meta name="citation_journal_title" content="Lab Notebook"/>

<!--NOTE: see also the COinS Metadata in span element in footer -->




  <!-- CSS Stylesheets (toggled with javascript) -->
  <link href="/assets/css/bootstrap.css" rel="stylesheet" 
        type="text/css" title="white" />
  <link href="/assets/css/light.css" rel="alternate stylesheet"
        type="text/css" id="stl" title="light" />
  <link href="/assets/css/dark.css" rel="alternate stylesheet" 
        type="text/css" title="dark" />
  <link href="/assets/css/bootstrap-responsive.css" rel="stylesheet" 
        type="text/css"/>
  <!-- Javascript needed for theme toggle, load immediately -->
  <script type="text/javascript" src="/assets/js/switch-css.js"></script>
  <script type="text/javascript">
    set_style_from_cookie(); 
  </script>
</head>


  <body prefix="dc: http://purl.org/dc/terms/ foaf: http://xmlns.com/foaf/0.1/"> 
    <!-- Navbar  ================================================== -->
<div class="navbar navbar-fixed-top">
  <div class="navbar-inner">
    <div class="container">
      <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </a>
      <a class="brand" href="/README.html"><i style="float:right;" class="icon-info-sign" alt="info"></i></span></a>
      <div class="nav-collapse">
        <ul class="nav">
          <li>
          <a href="/index.html">Home</a></li>

          <li>
          <a href="/vita.html">Vita</a></li>

          <li>
          <a href="/research.html">Research</a></li>

          <li>
          <a href="/teaching.html">Teaching</a></li>

          <li>
          <a href="/community.html">Community</a></li>

          <li class="active">
          <a href="/lab-notebook.html">Lab Notebook</a></li>

        </ul>
      </div><!--/.nav-collapse -->

      <!-- Search site using Google's index -->
      <form class="navbar-search pull-right" method="get" action="http://google.com/search">
        <p>
          <input type="hidden" name="q" value="site:carlboettiger.info" />
          <input type="text" class="search-query" name="q" />
          <button class="btn btn-mini" type="submit"><i class="icon-search"></i></button> 
        </p>
      </form>
      <!--
      <div id="search">
      <form method="get" class="navbar-search pull-right form-search">
        <p>
        <input type="text" name="search-text" id="search-text">
         <button class="btn btn-mini" type="submit"><i class="icon-search"></i></button> 
        </p>
      </form>
      </div>
      -->
     </div> <!-- /container -->
   </div> <!-- /navbar-inner -->
 </div> <!-- /navbar -->



    <div class="container"> <!-- Responsive grid layout --> 

      <header class="jumbotron">
  <h1 class="entry-title">Lab Notebook</h1>
  <h3>(<a href="http://www.carlboettiger.info/2012/09/28/Welcome-to-my-lab-notebook.html">Introduction</a>)</h3>
</header>



<div class="row feed">
  <div class="span3 offset1">
    <h4>  <a property="account" href="https://github.com/cboettig" onclick="recordOutboundLink(this, 'Outbound Links', 'Github'); return false;"><i class="icon-github" alt="github"></i> Coding </a></h4> 
     <div class="excerpt">
        <ul><li>cboettig pushed to master at cboettig/labnotebook: <em>fixed typos links added to new posts touch up and post</em> <a href="https://github.com/cboettig/labnotebook/compare/e7eadcb98e...a3fe998746">09:13 2013/06/03</a></li><li>cboettig pushed to master at cboettig/nonparametric-bayes: <em>Merge branch 'master' of github.com:cboettig/nonparametric-bayes admb file</em> <a href="https://github.com/cboettig/nonparametric-bayes/compare/4911dc47b4...1b74018b4f">06:19 2013/06/03</a></li><li>cboettig pushed to master at cboettig/nonparametric-bayes: <em>fix ricker chunk creation of ricker_pardist</em> <a href="https://github.com/cboettig/nonparametric-bayes/compare/80ee481902...4911dc47b4">04:17 2013/06/03</a></li><li>cboettig pushed to master at cboettig/nonparametric-bayes: <em>admb example</em> <a href="https://github.com/cboettig/nonparametric-bayes/compare/20d2f24852...80ee481902">01:39 2013/06/01</a></li><li>cboettig pushed to master at cboettig/nonparametric-bayes: <em>Merge branch 'master' of github.com:cboettig/nonparametric-bayes learning ADMB. not working yet.</em> <a href="https://github.com/cboettig/nonparametric-bayes/compare/64e0ab4dc2...20d2f24852">01:36 2013/06/01</a></li></ul>
    </div>
  </div>
  <div class="span3">
    <h4> <a property="account" href="https://twitter.com/cboettig" onclick="recordOutboundLink(this, 'Outbound Links', 'Twitter'); return false;"><i class="icon-twitter"></i> Discussing </a></h4> 
     <div class="excerpt">
       <ul><li><p>btw, was written entirely over @github. Shoulda linked the repo from the preprint? <a href="https://t.co/zcy2cNygqY">https://t.co/zcy2cNygqY</a> Standard practice for this?</p>
 <a href="http://twitter.com/cboettig/statuses/341644554820272128">12:56 2013/06/03</a> </li><li><p>Thanks to @pkedrosky and @wilbanks for mentioning my recent paper w/ the awesome @noamross <a href="http://t.co/B6mHDmThiu">http://t.co/B6mHDmThiu</a></p>
 <a href="http://twitter.com/cboettig/statuses/341642610949103616">12:48 2013/06/03</a> </li><li><p>Thanks! RT @wilbanks: That last paper by the awesome @cboettig BTW. Also, how nice is the arxiv as a way to convey information?</p>
 <a href="http://twitter.com/cboettig/statuses/341640539847929857">12:40 2013/06/03</a> </li><li><p>my answer to opendata.stackexchange on &quot;Preservation of blog posts, articles and essays&quot; <a href="http://t.co/9pwIYQTAVt">http://t.co/9pwIYQTAVt</a></p>
 <a href="http://twitter.com/cboettig/statuses/341638214135734272">12:31 2013/06/03</a> </li><li><p>@adaptive<em>plant @recology</em> yup, that&#39;s why I mentioned getting it from <a href="http://t.co/rV2TamnLOr">http://t.co/rV2TamnLOr</a>; also on github <a href="https://t.co/XFgareTv0u">https://t.co/XFgareTv0u</a></p>
 <a href="http://twitter.com/cboettig/statuses/341340246648176642">04:47 2013/06/02</a> </li></ul>
    </div> 
  </div> 
  <div class="span3">
    <h4> <a href="http://www.mendeley.com/groups/634301/theoretical-ecology/papers/" onClick="recordOutboundLink(this, 'Outbound Links', 'Mendeley'); return false;"><i class="icon-book"></i> Reading </a></h4> 
    <div class="excerpt">
      <ul><li>Review of Sokal and Rolf 2012 Biometry 4th Ed.: Limnology and Oceanography Bulletin (2013). Volume: 115, Issue: 2. Pages: 62-65. Stuart H. Hurlbert et al. <a href="http://www.mendeley.com/research/review-sokal-rolf-2012-biometry-4th-ed-1/">05:21 2013/06/03</a></li><li>Signature of ocean warming in global fisheries catch: Nature (2013). Volume: 497, Issue: 7449. Pages: 365-368. William W. L. Cheung, Reg Watson, Daniel Pauly et al. <a href="http://www.mendeley.com/research/signature-ocean-warming-global-fisheries-catch-7/">05:21 2013/06/03</a></li><li>Innovations in capture fisheries are an imperative for nutrition security in the developing world: Proceedings of the National Academy of Sciences (2013). Pages: 1-6. S. J. Hall, R. Hilborn, N. L. Andrew, E. H. Allison et al. <a href="http://www.mendeley.com/research/innovations-capture-fisheries-imperative-nutrition-security-developing-world/">05:21 2013/06/03</a></li><li>What early warning systems are there for environmental shocks?: Environmental Science & Policy (2013). Pages: S60-S75. Timothy M. Lenton et al. <a href="http://www.mendeley.com/research/early-warning-systems-environmental-shocks/">05:21 2013/06/03</a></li></ul>
    </div>
  </div> 
</div>

<hr>
<div class="row postpreview">
  <div class="span11 offset1">
    <div class="row">
      <h4> <a href="http://www.carlboettiger.info/atom.xml"
              onClick="recordOutboundLink(this,
              'Outbound Links', 'RSS'); return false;"
              style="color: inherit;"
              ><i class="icon-rss" ></i> Entries</a></h4>
      
        <div class="span3">
          <header><h4><a href="/2013/06/03/DOI-citable.html">DOI != citable</a></h4></header>
<p><span></span></p>
<p style="font-style:italic"> 03 Jun 2013</p>

<p style="font-style:italic"> pageviews: (not calculated) </p>

<article>
<div class="excerpt">
<p>I feel I see this kind of comment almost daily:</p>
<blockquote class="twitter-tweet" data-partner="tweetdeck"><p>
Is there a way to obtain DOI for a <a href="https://twitter.com/github">@github</a> repository? (for citing <a href="https://twitter.com/search?q=%23opensource&amp;src=hash">#opensource</a> software packages, similar to <a href="https://twitter.com/figshare">@figshare</a> objects) <a href="https://twitter.com/search?q=%23git&amp;src=hash">#git</a>
</p>
— Ahmed Moustafa (@AhmedMoustafa) <a href="https://twitter.com/AhmedMoustafa/statuses/339727912896954369">May 29, 2013</a>
</blockquote>
<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script>

<p>Again and again, researchers suggest that DOI to makes something “citable”. And this <a href="https://twitter.com/cboettig/status/337986074624282624">frustrates me</a>.</p>
<p>Don’t get me wrong. I love DOIs, and I love CrossRef. And I bang on the table when I have some old journal article that doesn’t yet have a DOI. I use DOIs every day in many ways. I use CrossRef’s APIs all the time to draw in metadata for citations in my notebook (through my <a href="http://github.com/cboettig/knitcitations">knitcitations</a> package), and to import metadata into my reference manager, Mendeley. I’ve written my own implementations in R and ruby, and keep an eye on their exciting new tools on the <a href="https://github.com/crossref">Crossref Github page</a>. I wrote to bibsonomy when I realized they were not using the CrossRef API to look up metadata by DOIs, and they have now implemented this feature. I use DOIs to look up papers I’ve come across, and to share content I am reading. (Crossref’s <a href="http://shortdoi.org/">DOI shortener</a> is great for this). I even use DOI-based links to <a href="http://carlboettiger.info/2013/02/22/semantic-citations-for-the-notebook-and-knitr.html">embed semantic information</a> into links and citations of articles.</p>
<p>But I still have no idea what researchers mean when they suggest that this makes something <em>citable</em>.</p>
<h3 id="some-background-on-dois">Some background on DOIs</h3>
<p>At its heart, a DOI is a very simple concept. It is a “permanent identifier”. All this means is that is is really just a URL redirect. Type http://dx.doi.org/mnn into any browser and get redirected to where the article actually lives. Why does that make it permanent? Because if the journal decides to change their URL structure, the DOI’s redirect can just be mapped to the new address and voila, it still works. That is, a DOI is simply a tool to fight <a href="https://en.wikipedia.org/wiki/Link_rot">link-rot</a>.</p>
<p>So you might ask, why does the ability to remap the address have anything to do with being “permanent?” It doesn’t, really. The permanence comes not so much from the technology as from the social contract that goes with it. As CrossRef’s <a href="http://blogs.plos.org/mfenner/2009/02/17/interview_with_geoffrey_bilder/">Geoffery Bilder eloquently explains</a>, a publisher can only receive DOIs if they promise to keep these redirects up-to-date. A publisher who fails to maintain this responsibility would presumably lose their right to receive DOIs. A brilliant, simple, social incentive.</p>
<p>This still does not guarantee permanence – e.g. what would happen to the content if the publisher disappears. That problem is not addressed by the DOI technology itself, but by a robust backup archiving solution, such as <a href="http://clocks.org">CLOCKSS</a>, which provides a geo-politically distributed network of backup copies for many journals. Again the social contract comes into play – presumably CrossRef would not provide a publisher with DOIs if they did not have such a robust archival solution in place.</p>
<p>So far we have seen two crucial functions of the DOI – as a permanent identifier that can be used to reach the content despite link rot, and as an incentive to maintain good archival backups of the content and the links to it.</p>
<h3 id="what-do-we-mean-by-citations-anyway">What do we mean by citations, anyway?</h3>
<p>So what does this have to do with being citable? Obviously these are nice properties to have for things we cite – but they are by no means a requirement. (As <a href="https://twitter.com/noamross/status/337987521243918337">Noam Ross observes</a>, try finding a permanent identifier for “Personal Communication”). Books, reports, and other grey literature frequently appear in citations, as do links to websites. MLA even has guidelines on the proper format to <a href="www.mla.org/style/handbook_faq/cite_a_tweet">cite a tweet</a> (which, incidentally, come closer to having a permanent identifier and an archival strategy than most other things in this list). So what do we mean by citable anyway?</p>
<p>But what about the reference list? While a publisher may be just fine including some link to your software, is it really cited if it isn’t in the reference list? Journals restrict what appears in the reference list because these references are indexed by the infamous citation counters like Thompson-Reuters. (A frequent complaint is that many journals do not similarly index citations appearing in the reference list of the supplementary materials, making it difficult or impossible to give appropriate attribution to large numbers of data providers, for instance). Does having a DOI address this problem?</p>
<h4 id="citation-counts-in-dois">Citation counts in DOIs</h4>
<p>Counting citations depends on who is counting them. The most well-known is Thompson-Reuters, which has their own process for deciding what gets counted (based on publisher), so no guarantee there. Meanwhile Google Scholar counts anything meeting it’s <a href="http://carlboettiger.info/2012/11/23/citing-lab-notebook-entries.html">indexing requirements &amp; arbitrary selection</a>. I have recently learned that CrossRef just launched it’s own <a href="https://github.com/articlemetrics/alm/wiki/Crossref">internal citation counting</a>, which is available from the CrossRef metadata (totals only for the public, publishers can resolve which articles did the citing…). However, most proposals to make some alternative research product “citable” by giving it a DOI use DataCite DOIs (e.g. fig<strong>share</strong>, PeerJ Preprints), which lag behind in this feature. Moving the control of citation data beyond the grasp of particular publishing companies like TR is undoubtedly an important step forward. The <a href="http://www.jisc.ac.uk/whatwedo/programmes/inf11/jiscexpo/jiscopencitation.aspx">Open Citation Project</a> is a more comprehensive, if very young, move in this direct. (Hat tip to Martin Fenner for explaining CrossRef citations to me).</p>
<h3 id="additional-metadata">Additional Metadata</h3>
<p>In addition to resolving links, DOI providers also serve a rich collection of metadata about the publication that can be <a href="http://www.crosscite.org/cn/">queried by DOI</a> or by <a href="https://github.com/CrossRef/cr-search">other elements</a> like author and title. Rich semantic formats and disambiguation of author names by connections to ORCID IDs are among the many advantages of this. Because many of these tools are publicly accessible by through their APIs, it is easy for other developers to build services upon them.</p>
<h2 id="conclusions">Conclusions</h2>
<p>While DOI providers have done an excellent job in ensuring persistent URLs, archived content, and valuable metadata, these things are largely the product of the social contract between publisher and the DOI provider. It is not possible for an author or organization to simply “get DOIs” for all their content. But it is not the only way to provide these features, either. While I understand the value in providing a simple and reliable way to encapsulate each of these concepts as “has a DOI,” it also appears to put these features beyond the reach of individual researchers. If issues of persistent URLs, archived content, and rich metadata tools are always reduced to “has a DOI,” publishers become the only path to achieve these ends. On the contrary, a rich collection of tools is available to researchers.</p>
<p>So what do we mean when we say a DOI makes something ‘citable?’ If this is shorthand for the properties we would want in something citable: persistent identifier, archival content, machine-readable metadata, than we should start to recognize other things that share these features. Further innovation requires valuing the features the DOI provides, not simply a “brand name” researchers recognize.</p>
<h2 id="alternative-tools">Alternative tools</h2>
<p>In a <a href="http://purl.org/cboettig/2013/05/31/notebook-features-digital-archiving">recent post</a> in a series on technical features of my open notebook, I discuss some of the tools available to address these challenges. In particular:</p>
<ul>
<li>The use of <a href="http://en.wikipedia.org/wiki/Persistent_uniform_resource_locator">PURLs</a> for persistent identifiers</li>
<li>Git for archival redundancy</li>
<li><a href="http://greycite.knowledgeblog.org">Greycite</a> for metadata extraction</li>
</ul>
<p>Of course, if you ever need a DOI for a research product, there is always <a href="http://figshare.com">figshare</a>.</p>
 
<!-- not that raw_content depends on custom generator, 
     see _plugins/jekyll-labnotebook-plugins/raw_content --> 
</article> 
<p> <a href="/2013/06/03/DOI-citable.html"> <em>Read more</em></a> </p>
<br />
<br />


        </div>
      
        <div class="span3">
          <header><h4><a href="/2013/05/31/notebook-features-digital-archiving.html">Notebook features: digital archiving</a></h4></header>
<p><span></span></p>
<p style="font-style:italic"> 31 May 2013</p>

<p style="font-style:italic"> pageviews: 2 </p>

<article>
<div class="excerpt">
<p>Note: this entry is part of a <a href="http://carlboettiger.info/2013/04/26/notebook-features-introduction.html">series of posts</a> which explain some of the technical features of my lab notebook.</p>
<p>Archival preservation of digital scholarly content is an important challenge throughout the research community. As the notebook is the permanent record of my regular scholarly endeavors, this provides the opportunity to experiment with tools and techniques for digital archiving while also better preserving the notebook. In the experimental spirit that drives all my exploration here, I am testing several ways to accomplish this. In so doing, I learn which approaches are easiest to implement, to use, and gather feedback from, while also hedging my bets in the event that any given strategy should fail.</p>
<p>Archiving digital content involves two fundamental challenges that can be difficult to satisfy simultaneously: providing a robust backup copy of the <em>content</em>, and providing a consistent location (such as a URL) where the content can be retrieved.</p>
<h2 id="a-custom-domain">A custom domain</h2>
<p>The simplest archival measure employed in the notebook comes from hosting through my own domain, <a href="http://carlboettiger.info">carlboettiger.info</a> rather than an external server. By controlling the domain structure myself, I am not tied to a University server that can be altered by an IT department without my knowledge, thereby breaking my links. When I choose to move platforms, as I did in migrating from <a href="/2012/09/19/migrating-from-wordpress-to-jekyll.html">Wordpress to Jekyll</a>, I could ensure that links would be appropriately mapped. This was not the case when I started my open notebook on the OpenWetWare platform, since links are all mapped to the <a href="http://openwetware.org">openwetware.org</a> domain which I obviously cannot control, even though I could at least migrate my content. <a href="https://github.com/cboettig/labnotebook/blob/8481569132142c850e585a2fc8c12a671527cd4f/_plugins/redirects.rb">HTML redirects</a> make sure links still resolve when I change structure (e.g. <a href="/archives/211">carlboettiger.info/archives/211</a>). I don’t have to worry about moving my domain when I change institutions, and can seamlessly migrate to a different server or DNS provider to get better rates or uptime performance.</p>
<p>Of course these advantages are also the greatest weaknesses of this approach – they all depend entirely on me. I could make or forget to make any number of changes that could cause this all to break. Time has shown that even the best-intentioned researchers are not the best curators of there own data, and no doubt I am no exception. How can the content and its identifying addresses outlive me or my interest in it?</p>
<h2 id="purls-preserving-identifiers">PURLs: preserving identifiers</h2>
<p><a href="http://purl.org">PURLs</a>, or Persistent Uniform Resource Locators, provide a DOI-like mechanism for addressing the challenge of link-rot. As <a href="http://blogs.plos.org/mfenner/2009/02/17/interview_with_geoffrey_bilder/">Geoffrey Bilder eloquently argues</a>, the technological solution is quite simple, the real challenge lies on the social side of the implementation – a social contract that promises content providers will maintain their identifiers if they want to continue to receive identifiers. Though users must register to be able to create PURLs, PURL does not provide such enforcement.</p>
<p>The PURLs solution is a bit more web-native solution than DOIs, in being more democratic, using a URL structure, and being built upon widely distributed servers and open-source web technology. Not surprisingly, other web-native systems such as most of the major semantic web ontology providers rely on PURLs, e.g. Dublin Core uses <a href="http://purl.org/dc/terms/">purl.org/dc/terms/</a>. The PURL <a href="http://purl.oclc.org/docs/faq.html">FAQ</a> provides a great overview.</p>
<p>Implementing PURLs for the notebook was very straight-forward. After registering as a user at <a href="http://purl.org">purl.org</a> I applied for my own top-level domain: <code>cboettig</code>, which I then mapped to my current domain, <a href="http://carlboettiger.info">carlboettiger.info</a> By enabling partial redirects, each page on my site will also be resolved using this top-level domain followed by my existing page structure. Following my existing structure is not necessary – I could map each page to an arbitrary path in my domain, but would have to enter these somewhat manually. While the partial redirect is simpler to implement, it does require that I maintain the rest of the link structure.</p>
<p>In this way, <a href="http://purl.org/cboettig/lab-notebook.html">purl.org/cboettig/lab-notebook.html</a> now resolves to <a href="http://carlboettiger.info/lab-notebook.html">carlboettiger.info/lab-notebook.html</a>. Likewise, each page in the notebook can be similarly resolved from the purl.org domain instead of my personal carlboettiger.info domain. Should I ever somehow lose control of carlboettiger.info, I could re-assign my PURL to redirect to my new domain URL. This provides DOI-like technology of permanent identifiers for every page in the notebook.</p>
<h2 id="github-preserving-content-and-versions">GitHub: preserving content and versions</h2>
<p>Committing content to an external repository is the recommended way to avoid link-rot from the user errors and website changes that so frequently plague self-archiving of scholarly content. Keeping multiple copies of content in geographically distinct locations is the time-honored approach of digital archiving. Git and GitHub make this easy. Not only does this mean that a backup copy is publicly available and forkable online, but it is also easy to clone copies on each of the machines I work on and rely on git to keep them in sync. Should Github disappear, a little <code>git remote add</code> and everything will be effortlessly deployed with complete history elsewhere.</p>
<p>The notebook has two Github repositories: the “source-code” consisting of plain-text (markdown) content and Jekyll-based templates on <a href="http://github.com/cboettig/labnotebook">labnotebook</a>, and a second for the rendered HTML <a href="http://github.com/cboettig/cboettig.github.com">cboettig.github.com</a> (which also now hosts the website).</p>
<p>While a custom domain and PURLs provide persistent <em>locators</em> for the content, distributed copies on Git help archive the content itself. Should my domain vanish or Github disappear, copies of the content, complete with version history, would remain distributed across various machines with a copy of the repository. Links to Github would break in that process, unless we had remapped all links from the notebook to Github using PURLs.</p>
<h2 id="greycite-programmatic-access-and-indexing-of-metadata">Greycite: Programmatic access and indexing of metadata</h2>
<p>I think of good metadata as the third leg to proper digital archiving, in addition to permanent identifiers and backup of content. We want to be able to point a tool at the permanent identifier / URL of an entry and extract reliable information on the author, time published and last modified, title, author, key words, etc. that might be useful in citing or categorizing the content. Providing this information is really the subject of adding <a href="http://carlboettiger.info/2012/10/23/semantic-markup-examples-for-the-lab-notebook.html">Semantic metadata</a> to the site, and is covered in another entry in this series. Meanwhile, the <a href="http://greycite.knowledgeblog.org">Greycite</a> tool and it’s API are an excellent way to extract this metadata into a variety of useful formats, working much the same way that CrossRef’s tool does using DOIs. Here is an <a href="http://greycite.knowledgeblog.org/?uri=http%3A%2F%2Fpurl.org%2Fcboettig%2F2012%2F10%2F23%2Fsemantic-markup-examples-for-the-lab-notebook.html">example query</a></p>
<figure>
<img src="http://farm6.staticflickr.com/5325/8940923396_fcf4941197.jpg" />
</figure>
<h2 id="robust-archiving-with-figshare"><strong>Robust archiving</strong> with fig<strong>share</strong></h2>
<p>Depositing a copy of the notebook on fig<strong>share</strong> is one of the most robust archival solutions of which I am currently aware. Not so much because it has the coveted DOI solution to the permanent identifier problem but because it has the promise of <a href="http://clocks.org">CLOCKSS</a> archiving, should anything ever happen to fig<strong>share</strong>.</p>
<p>Nevertheless, it raises several challenges. The native home for the content is as rendered HTML at my domain, not as raw HTML on an archive completely unassociated with that domain, difficult to view, and divorced from my usual workflow, unlike my usual publishing source-code to Github and website to my domain. It also raises questions of just what to archive and when. I discuss some of these strengths and challenges as a separate post, <a href="http://purl.org/cboettig/2013-05-31-notebook-features-archiving-with-figshare">archiving the lab notebook on figshare: advantages and challenges</a>.</p>
<h2 id="conclusions">Conclusions</h2>
<p>Digital archiving is a challenging problem that is not completely addressed by any one of these approaches. In the end, robust archiving will be best left in the hands of its experts. Unfortunately, the best examples currently available (such as CLOCKSS, national libraries, etc.) will not archive a researcher’s web page directly. The solutions explored here are not perfect, but they are free and simple to implement. I’d love to hear what others think.</p>
<h3 id="see-also">See also</h3>
<ul>
<li><a href="http://www.digitalpreservation.gov/ndsa/">DigitalPreservation.gov</a></li>
<li><a href="http://internetarchive.org">The Internet Archive</a></li>
</ul>
 
<!-- not that raw_content depends on custom generator, 
     see _plugins/jekyll-labnotebook-plugins/raw_content --> 
</article> 
<p> <a href="/2013/05/31/notebook-features-digital-archiving.html"> <em>Read more</em></a> </p>
<br />
<br />


        </div>
      
        <div class="span3">
          <header><h4><a href="/2013/05/31/notebook-features-archiving-with-figshare.html">Archiving the lab notebook on figshare</a></h4></header>
<p><span>Advantages and challenges</span></p>
<p style="font-style:italic"> 31 May 2013</p>

<p style="font-style:italic"> pageviews: (not calculated) </p>

<article>
<div class="excerpt">
<h2 id="robust-archiving-through-clockss">Robust archiving through CLOCKSS</h2>
<p>One of the most comprehensive approaches I have come across so far uses fig<strong>share</strong>. This offers the most promising avenue for content preservation, but is weakest in managing the URIs and associating them with the original content. All fig<strong>share</strong> content is archived by <a href="http://clockss.org">CLOCKSS</a>, an international library cooperation providing redundant and geopolitically distributed backup of the archives around the world (and used by many academic journals, both subscription based &amp; open access). Should fig<strong>share</strong> vanish from the face of the planet, it will trigger the release of all of its content to resolve through the CLOCKSS servers, with the same appearance and resolving at the same URLs as the original figshare content. Presumably the DOIs provided to figshare content will also continue to resolve there.</p>
<h2 id="challenges">Challenges</h2>
<p>It would certainly be preferable to have the notebook archived by CLOCKSS directly, since the association between the original online content at carlboettiger.info is lost in archiving the entries on figshare. More problematically, the content as archived on fig<strong>share</strong> is not recognized by search engines, etc., as a separate HTML pages to index, but merely as a bundle of attached text files. On the upside, the content becomes part of the global scientific datasets preserved and indexed by fig<strong>share</strong> with appropriate metadata, etc., increasing the chances for discovery through that venue. Also, fig<strong>share</strong> provides a convenient API that can help automate deposition.</p>
<h3 id="what-content-what-format">What content? What format?</h3>
<p>Deciding just what to archive in the fig<strong>share</strong> database is also less straight forward than it may seem. I have gone through a few iterations:</p>
<ol type="1">
<li>Archiving the markdown.<br /></li>
<li>Archiving external images with Data URIs.<br /></li>
<li>Archiving the HTML versions of pages alone</li>
<li>Archiving the whole git repository, <code>_site</code> HTML included (?)</li>
</ol>
<p>I began by archiving the markdown files that I write to create each entry. These are plain-text files that can be easily read in any text editor, even if the conventions for rendering them as HTML are lost. Like HTML, figures are linked to external files, and are thus not captured by this solution. To work around this, I adopted the trick of using <a href="http://carlboettiger.info/2013/01/24/Data-URIs-for-image-archives.html">Data URIs</a> to embed images. This places a binary encoding of the image in the text itself, which can be rendered by almost any browser as the appropriate image. While this keeps the content together, the long data URI strings are rather out-of-place inside a plain text document. Further, the markdown loses all of the valuable semantics that are automatically added to each page when Jekyll renders them to HTML. As Phil Lord argues, if there’s any format that future archivists can read successfully – it will be HTML. Consequently I’ve settled on archiving the HTML versions of each notebook entry, with images embedded as Data URIs. Each HTML file contains rich metadata in the header, sidebar, and footer, that give more information about the content and its context in the notebook (relative path, categories and tags, timestamps and SHA hashes, etc). I have archived these entries in annual chunks following the year/month/day directory structure already employed on the site.</p>
<h3 id="how-about-site-assets">How about site assets?</h3>
<p>There is still additional external content used to render the site – CSS and javascript files – that are not captured in this approach. Though entries actually render <a href="http://stackoverflow.com/questions/14046738">just fine without the css</a>, it would certainly be possible to include this material in the archive (though some Javascript comes from external CDNs). This does make for a bit larger and more cluttered archive, and more to the point is a rather crude solution to a problem already solved by Internet archiving programs such as CLOCKSS or internetarchive.org.</p>
<h3 id="versioning">Versioning?</h3>
<p>Lastly there is the concern of preserving the version history of entries. Though fig<strong>share</strong> provides versioning of its content, this doesn’t capture finer resolution of individual page changes available through the Github repository. At the expense of creating an ever more cumbersome archival object, one could include the <code>.git</code> history, either for the HTML rendered version (which lives at <a href="https://github.com/cboettig/cboettig.github.com/">cboettig.github.com</a>) or the source files used to create it (<a href="https://github.com/cboettig/labnotebook">labnotebook</a>).</p>
<h3 id="connecting-to-the-original-instances">Connecting to the original instances?</h3>
<p>Of course this fails to address the preservation of externally linked content. The most frequent outbound links point to other publications through, usually their DOIs, which we hope will take care of themselves. The most important externally linked content in the notebook entries are the links to scripts, functions, and manuscripts in the various project repositories on Github. The simplest solution is to embed the most important scripts in the notebook entries themselves. Archiving the project repositories is an additional challenge, but if a user can recover a copy of the project repository (along with it’s <code>.git</code> history) then it would be possible to identify the linked file using the SHA hash from these links (by matching it against the SHAs in the log). See my entry on <a href="/2013/05/03/notebook-features-hashes-providing-an-immutable-and-verifiable-research-record.html">SHA hashes</a> for more on this topic.</p>
<h2 id="links-to-the-archives">Links to the archives</h2>
<p>Current and previous archives of my lab notebook can be found on figshare by year. Older versions of these archives have taken a different approach, including just archiving the markdown files. The links use the DOI and point to the most recent version. (At this time linking to explicit versions with FigShare’s DataCite DOI links doesn’t appear to be working)</p>
<ul>
<li><a href="http://dx.doi.org/10.6084/m9.figshare.96916">Lab Notebook, 2010</a></li>
<li><a href="http://dx.doi.org/10.6084/m9.figshare.96919">Lab Notebook, 2011</a></li>
<li><a href="http://dx.doi.org/10.6084/m9.figshare.106620">Lab Notebook, 2012</a></li>
</ul>
 
<!-- not that raw_content depends on custom generator, 
     see _plugins/jekyll-labnotebook-plugins/raw_content --> 
</article> 
<p> <a href="/2013/05/31/notebook-features-archiving-with-figshare.html"> <em>Read more</em></a> </p>
<br />
<br />


        </div>
      
    </div>

    <div class="row">
      
        <div class="span3">
          <header><h4><a href="/2013/05/29/notes.html">Notes</a></h4></header>
<p><span></span></p>
<p style="font-style:italic"> 29 May 2013</p>

<p style="font-style:italic"> pageviews: (not calculated) </p>

<article>
<div class="excerpt">
<h2 id="nonparametric-bayes">nonparametric-bayes</h2>
<p>Not getting good convergence from jags models with uniformative priors without observation noise and arbitary starting postions. See examples:</p>
<ul>
<li>fixed myers_jags run, loads knitr_defaults <a href="https://github.com/cboettig/nonparametric-bayes/commit/783ed119848772dcc3ee26d9e1dbe10b1e1afbbc">11:18 am 2013/05/29</a></li>
<li>trouble with MCMC convergence for process-noise-only: Now with longer runs and better posterior estimator. Set for run on zero. <a href="https://github.com/cboettig/nonparametric-bayes/commit/5e3f3f5b00dbd6085e6cddee03ad03151a759b22">11:01 am 2013/05/29</a></li>
</ul>
<p>Also a few updates:</p>
<ul>
<li>slides for adp section of group meeting <a href="https://github.com/cboettig/nonparametric-bayes/commit/094b44822abb47b1145f0a0bb0ae2c8364bbee25">11:44 am 2013/05/29</a></li>
<li>updated adp-intro <a href="https://github.com/cboettig/nonparametric-bayes/commit/4eb6a30441f28e9cbe87690d9e098b0e068cc395">11:43 am 2013/05/29</a></li>
</ul>
<h2 id="prosecutor">prosecutor</h2>
<ul>
<li>Combine comment code into single file for both models: <a href="https://github.com/cboettig/earlywarning/blob/resubmission/inst/examples/comment_reply.Rmd">comment_reply.Rmd</a></li>
<li>Comment resubmitted. (repository tag: <a href="https://github.com/cboettig/earlywarning/blob/resubmission"><code>resubmission</code></a>)</li>
<li>Ooh: tags provide a convenient way to make readable version-stable links (e.g. as opposed to linking by the hash.)</li>
</ul>
<h2 id="handling-scripts">handling scripts</h2>
<p>Separated out my common knitr settings that usually take up space in my first code chunk.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># My preferred defaults (may be changed in individual chunks)</span>
opts_chunk$<span class="kw">set</span>(<span class="dt">tidy=</span><span class="ot">FALSE</span>, <span class="dt">warning=</span><span class="ot">FALSE</span>, <span class="dt">message=</span><span class="ot">FALSE</span>, <span class="dt">cache=</span><span class="ot">TRUE</span>, 
               <span class="dt">comment=</span><span class="ot">NA</span>, <span class="dt">verbose=</span><span class="ot">TRUE</span>, <span class="dt">fig.width=</span><span class="dv">6</span>, <span class="dt">fig.height=</span><span class="dv">4</span>)
 
<span class="co"># Name the cache path and fig.path based on filename...</span>
 opts_chunk$<span class="kw">set</span>(<span class="dt">fig.path =</span> <span class="kw">paste</span>(<span class="st">&quot;figure/&quot;</span>,
                                 <span class="kw">gsub</span>(<span class="st">&quot;.Rmd&quot;</span>, <span class="st">&quot;&quot;</span>, knitr:::knit_concord$<span class="kw">get</span>(<span class="st">&#39;infile&#39;</span>)),
                                 <span class="st">&quot;-&quot;</span>, <span class="dt">sep=</span><span class="st">&quot;&quot;</span>),
                                 <span class="dt">cache.path =</span> <span class="kw">paste</span>(<span class="kw">gsub</span>(<span class="st">&quot;.Rmd&quot;</span>, <span class="st">&quot;&quot;</span>, knitr:::knit_concord$<span class="kw">get</span>(<span class="st">&#39;infile&#39;</span>) ), 
                                 <span class="st">&quot;/&quot;</span>, <span class="dt">sep=</span><span class="st">&quot;&quot;</span>))
  
<span class="co"># Set plotting to bw plot default, but with transparent background elements.  </span>
<span class="co"># Note transparency requires the panel.background, plot.background, and device background all be set!</span>
  <span class="kw">library</span>(ggplot2) 
  <span class="kw">theme_set</span>(<span class="kw">theme_bw</span>(<span class="dt">base_size=</span><span class="dv">12</span>))
  <span class="kw">theme_update</span>(<span class="dt">panel.background =</span> <span class="kw">element_rect</span>(<span class="dt">fill =</span> <span class="st">&quot;transparent&quot;</span>, <span class="dt">colour =</span> <span class="ot">NA</span>),
               <span class="dt">plot.background =</span> <span class="kw">element_rect</span>(<span class="dt">fill =</span> <span class="st">&quot;transparent&quot;</span>, <span class="dt">colour =</span> <span class="ot">NA</span>))
  opts_chunk$<span class="kw">set</span>(<span class="dt">dev.args=</span><span class="kw">list</span>(<span class="dt">bg=</span><span class="st">&quot;transparent&quot;</span>))
   
<span class="co"># Set a color-blind friendly pallette</span>
<span class="co"># adapted from http://www.cookbook-r.com/Graphs/Colors_(ggplot2)/</span>
   cbPalette &lt;- <span class="kw">c</span>(<span class="st">&quot;#000000&quot;</span>, <span class="st">&quot;#E69F00&quot;</span>, <span class="st">&quot;#56B4E9&quot;</span>, <span class="st">&quot;#009E73&quot;</span>, 
                  <span class="st">&quot;#F0E442&quot;</span>, <span class="st">&quot;#0072B2&quot;</span>, <span class="st">&quot;#D55E00&quot;</span>, <span class="st">&quot;#CC79A7&quot;</span>)</code></pre>
<p>also appears as <a href="https://gist.github.com/cboettig/5600558">gist:5600558</a></p>
<p>Saved script as <code>~/.knit_defaults.R</code> and is sourced in by the first chunk instead.</p>
 
<!-- not that raw_content depends on custom generator, 
     see _plugins/jekyll-labnotebook-plugins/raw_content --> 
</article> 
<p> <a href="/2013/05/29/notes.html"> <em>Read more</em></a> </p>
<br />
<br />


        </div>
      
        <div class="span3">
          <header><h4><a href="/2013/05/28/notes.html">Notes</a></h4></header>
<p><span></span></p>
<p style="font-style:italic"> 28 May 2013</p>

<p style="font-style:italic"> pageviews: 7 </p>

<article>
<div class="excerpt">
<h2 id="mangel-group-talk">Mangel group talk</h2>
<ul>
<li>Presented nonparametric-bayes slides</li>
<li>ADP introduction / trouble-shooting (see yesterday’s entry), <a href="https://github.com/cboettig/nonparametric-bayes/blob/094b44822abb47b1145f0a0bb0ae2c8364bbee25/inst/mydeck/slides.html">html5 slides</a></li>
</ul>
<h3 id="notes">Notes</h3>
<ul>
<li>Decent convergence in the forward algorithm is hard. Consider basis function representation of value function to decrease the search space in the backwards-algorithm first. Also consider searching for policy function (under appropriate piecewise constraints).</li>
<li>Starts to sound more and more similar to POMDP</li>
</ul>
<h2 id="misc">Misc</h2>
<ul>
<li>Trouble with equations in <a href="https://github.com/ramnathv/slidify/issues/214">slidify/214</a></li>
<li><p>Finishing up posts from last week</p></li>
<li><p><strong><a href="http://osswatch.jiscinvolve.org/wp/2013/05/21/unlicensed-code-movement-or-madness/">On the lack of licenses on Github</a></strong></p></li>
</ul>
<p>R packages state licenses in the DESCRIPTION file, which automatically recognizes standard licenses rather than distributing a copy of the license. This seems sensible but it’s not like we don’t have a few bits to spare for a million duplicate copies of license files, so I suppose I could add this in explicitly.</p>
<p>Clearly my own thinking on licenses has evolved ahead of my adaptation:</p>
<pre class="sourceCode bash"><code class="sourceCode bash">$ <span class="kw">grep</span> <span class="st">&quot;License&quot;</span> code/*/DESCRIPTION

AdaptiveDynamics/DESCRIPTION:License: GPL <span class="kw">(&gt;</span>= 2<span class="kw">)</span>
earlywarning/DESCRIPTION:License: BSD
fluctuationDomains/DESCRIPTION:License: CC ZERO 1.0 + <span class="kw">file</span> LICENSE
knitcitations/DESCRIPTION:License: CC0
mcmcTools/DESCRIPTION:License: BSD
multiple_uncertainty/DESCRIPTION:License: BSD
nonparametric-bayes/DESCRIPTION:License: BSD
OUwie/DESCRIPTION:License: GPL <span class="kw">(&gt;</span>= 2<span class="kw">)</span>
pdg_control/DESCRIPTION:License: BSD
pmc/DESCRIPTION:License: CC0
populationdynamics/DESCRIPTION:License: BSD
prosecutors-fallacy/DESCRIPTION:License: BSD
socialR/DESCRIPTION:License: GPL <span class="kw">(&gt;</span>= 2<span class="kw">)</span>
structured-populations/DESCRIPTION:License: GPL <span class="kw">(&gt;</span>= 3<span class="kw">)</span>
warningsignals/DESCRIPTION:License: GPL <span class="kw">(&gt;</span>= 2<span class="kw">)</span>
wrightscape/DESCRIPTION:License: GPL-2</code></pre>
<p>Looks like it’s time for a little</p>
<pre><code>sed -i &quot;s/License: .*/License: CC0/&quot; */DESCRIPTION</code></pre>
<p>Yeehaw!</p>
<p>Just for the sake of being pendantic,</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">wget</span> http://creativecommons.org/publicdomain/zero/1.0/legalcode.txt
<span class="kw">mv</span> legalcode.txt LICENSE
<span class="kw">echo</span> */R/.. <span class="kw">|</span> <span class="kw">xargs</span> -n 1 <span class="kw">cp</span> LICENSE </code></pre>
<h3 id="rcurl-query-from-scott">RCurl query from Scott</h3>
<p>Translate a cURL command’s <code>-d</code> flag to RCurl, e.g.</p>
<pre class="sourceCode bash"><code class="sourceCode bash">curl -H <span class="st">&quot;X-Gauges-Token: &lt;token&gt;&quot;</span> <span class="kw">\</span>
     -d <span class="st">&quot;title=Example&quot;</span> <span class="kw">\</span>
     -d <span class="st">&quot;tz=Eastern Time (US %26 Canada)&quot;</span> <span class="kw">\</span>
     https://secure.gaug.es/gauges</code></pre>
<p>I proposed</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">httpPOST</span>(<span class="st">&quot;https://secure.gaug.es/gauges&quot;</span>, 
         <span class="dt">postfields=</span><span class="st">&quot;title=Example&amp;tz=Eastern Time (US %26 Canada)&quot;</span>, 
         <span class="dt">httpHeader=</span><span class="kw">c</span>(<span class="st">&quot;X-Gauges-Token&quot;</span>=<span class="st">&quot;&lt;token&gt;&quot;</span>), <span class="dt">verbose=</span><span class="ot">TRUE</span>)</code></pre>
<p>Though here is an <a href="http://stackoverflow.com/questions/12302941/">SO example</a> with slightly more elegant construction of postfields.</p>
<h2 id="two-column-layout-with-longtable">Two column layout with <code>longtable</code></h2>
<p>Pandoc now uses the <code>longtable</code> package to generate tables. Annoyingly, these insist on being single-column objects and are not handled properly by <code>elsarticle</code> two-column layouts. To get around this, I edit the latex Pandoc creates, wrapping the table in a float environment (<code>\begin{figure}</code>), followed by a toggle to <code>\onecolumn</code>. After the <code>longtable</code> envirnoment block ends, I include the caption, then toggle back to <code>\twocolumn</code> layout. I also have to tune the width of the <code>minipage</code> objects used by <code>longtable</code>, and change its alignment option to left-align (<code>\begin{longtable}[l]</code>). After these modifications I have a nice floating table in the width of a single column, embedded in my two-column layout.</p>
<p>Brilliantly, arXiv has no trouble with the scores of extra package dependencies introduced by pandoc, as long as the document is pdflatex compatible (no xelatex, hence non-ascii UTF-8, or custom fonts, sorry). Still far ahead of my experience submitting the same document to the acutal journal…</p>
<p>This nicely formatted tex is in the repository as <a href="">arxiv-copy.tex</a>. Should be generated from source with <code>make fancy</code>, since default <code>make</code> builds the 1980s plaintex format for the journal. I need to add make commands to automatically wrap the longtable as described above, hopefully a few lines of <code>sed</code> should do this…</p>
<p>So, arXiv copy sumbmitted… stay tuned on Thursday.</p>
 
<!-- not that raw_content depends on custom generator, 
     see _plugins/jekyll-labnotebook-plugins/raw_content --> 
</article> 
<p> <a href="/2013/05/28/notes.html"> <em>Read more</em></a> </p>
<br />
<br />


        </div>
      
        <div class="span3">
          <header><h4><a href="/2013/05/27/exploring-approximate-dynamic-programming-approaches.html">Exploring Approximate Dynamic Programming Approaches</a></h4></header>
<p><span></span></p>
<p style="font-style:italic"> 27 May 2013</p>

<p style="font-style:italic"> pageviews: 6 </p>

<article>
<div class="excerpt">
<h2 id="introductory-examples-in-approximate-dynamic-programming">Introductory examples in approximate dynamic programming</h2>
<p><em>Based on Powell 2006, page 97. I try to conform to that notation throughout</em>. Haven’t really figured this out yet, so this is more a walk through of me thinking this out then a tutorial. My active copy of this analysis can be found in the <a href="https://github.com/cboettig/nonparametric-bayes/blob/4eb6a30441f28e9cbe87690d9e098b0e068cc395/inst/examples/adp-intro.md">adp-intro</a> file of my nonparametric-bayes repo, see there for the <a href="https://github.com/cboettig/nonparametric-bayes/blob/master/inst/examples/adp-intro.md">most recent</a> (or earlier) versions.</p>
<h2 id="setup-my-sample-problem">Setup my sample problem</h2>
<p>First we define the Beverton-Holt stock-recruitment relationship as a function of stock size <code>x</code>, harvest <code>h</code> and parameters <code>p</code></p>
<pre class="sourceCode r"><code class="sourceCode r">f &lt;- function(x, h, p){
    A &lt;- p[<span class="dv">1</span>] 
    B &lt;- p[<span class="dv">2</span>] 
    s &lt;- <span class="kw">pmax</span>(x-h, <span class="dv">0</span>)
    A * s/(<span class="dv">1</span> + B * s)
}
p &lt;- pars &lt;- <span class="kw">c</span>(<span class="fl">1.5</span>, <span class="fl">0.5</span>)
K &lt;- (p[<span class="dv">1</span>] - <span class="dv">1</span>)/p[<span class="dv">2</span>]
sigma_g &lt;- <span class="fl">0.2</span></code></pre>
<p>We begin with a simulation method <span class="math">\(X_{t+1} = f(X_t, Z_t)\)</span>. For illustration, let us consider <span class="math">\(f(X_t, Z_t) = Z_t \frac{a X_t}{b + X_t}\)</span> with a = 1.5 and b = 0.5. We define a statespace <span class="math">\(S\)</span></p>
<pre class="sourceCode r"><code class="sourceCode r">S &lt;- <span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dt">length=</span><span class="dv">11</span>) </code></pre>
<p>as a uniform grid of 11 points from 0 to 1.<br />We also need a value function on the state space, <span class="math">\(C_t(S_t)\)</span>. For simplicity, we set the price of harvest at unity and the cost of harvesting at zero, so that <span class="math">\(C_t(S_t, x_t) = \min(x_t, S_t)\)</span>.<br />(<span class="math">\(C_t\)</span> is sometimes denoted <span class="math">\(\mathbb{\Pi}\)</span>).<br />We also need an action space <span class="math">\(\chi_t\)</span> of possible harvest values.<br />Again for simplicity we assume that harvest can be set to any possible state size, <span class="math">\(\chi_t \equiv S_t\)</span>,</p>
<pre class="sourceCode r"><code class="sourceCode r">chi &lt;- S</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">T &lt;- <span class="dv">10</span>
N &lt;- <span class="dv">10</span></code></pre>
<p>The approximate dynamic programming algorithm will perform a finite number <span class="math">\(N\)</span> = 10 iterations over a window of time <span class="math">\(T\)</span> =10 in our example. The algorithm can then be described as follows:</p>
<h2 id="algorithm-1">Algorithm (1)</h2>
<ul>
<li><p><strong>Step 0</strong></p></li>
<li><p>Initialize some value <span class="math">\(\tilde V_t^0(S_t)\)</span> for all states <span class="math">\(S_t\)</span>, where the superscripts denote iterations in the forward approximation.<br /> As we know absolutely nothing yet to base our initial guess on, we just arbitrarily set this to zero.</p></li>
</ul>
<pre class="sourceCode r"><code class="sourceCode r">V &lt;- <span class="kw">numeric</span>(<span class="kw">length</span>(S))</code></pre>
<ul>
<li>Choose some initial state <span class="math">\(S_0^1\)</span> We start at some initial state for <span class="math">\(n = 1\)</span> (superscript) and <span class="math">\(t = 0\)</span> (subscript). The choice of initial condition may come from the problem itself, otherwise we choose something arbitrarily.</li>
</ul>
<pre class="sourceCode r"><code class="sourceCode r">S_0 &lt;- <span class="fl">0.5</span></code></pre>
<ul>
<li><p>Set <span class="math">\(n = 1\)</span></p></li>
<li><p><strong>Step 1</strong>: Choose a sample path, <span class="math">\(\omega^n\)</span> (a vector of random draws)</p></li>
</ul>
<pre class="sourceCode r"><code class="sourceCode r">sigma &lt;- <span class="fl">0.2</span>
omega_n &lt;- <span class="kw">rlnorm</span>(T, <span class="dv">0</span>, sigma)</code></pre>
<ul>
<li><p><em>* Step 2</em>*: For <span class="math">\(t = 0, 1, 2, \ldots, T\)</span>, do:</p></li>
<li><p>Solve:</p></li>
</ul>
<p><span class="math">\[V_t(S_t) = \max_{x_t \in \chi_t} \left(C(S_t, x_t) + \gamma \sum_{s^{\prime} \in \mathcal{S}} \mathbb{P}(s^{\prime} | S_t^n, x_t) V_{t+1}^{n-1} s^{\prime} \right)\]</span></p>
<p>That is, choose action <span class="math">\(x_t\)</span> that maximizes the value of the next step.</p>
<p>Let’s start with <span class="math">\(t=0\)</span>, <span class="math">\(n=1\)</span> and fix an <span class="math">\(x_0\)</span> from the set of <span class="math">\(\chi\)</span> (allowing the action space to be the same in each period, we can omit the subscript on <span class="math">\(\chi\)</span>) to get started. We first compute <span class="math">\(C(S_0, x_0)\)</span>.</p>
<p><span class="math">\(S_0 = S_0^1\)</span> which we fixed in step <strong>0b</strong> arbitrarily at 0.5.</p>
<p>The profits/costs <span class="math">\(C(S_t, x_t)\)</span> are the value derived by action (harvest) <span class="math">\(x_t\)</span> at state (stock) <span class="math">\(S_t\)</span>. Assuming a fixed price and no costs to harvesting, this is just whichever number is smaller (since we cannot harvest more than the available stock,</p>
<pre class="sourceCode r"><code class="sourceCode r">C &lt;- function(S, X) <span class="kw">pmin</span>(S, X)</code></pre>
<p>(where we have used R’s vectorized form of the min function).</p>
<p>This forward dynamic programming will still rely on the one-step transition matrix, <span class="math">\(\mathbb{P}\)</span>.</p>
<p>Let’s get the transition matrices for this problem, assuming log-normal noise,</p>
<pre class="sourceCode r"><code class="sourceCode r">sdp_matrix &lt;- <span class="kw">determine_SDP_matrix</span>(f, p, <span class="dt">x_grid=</span>S, <span class="dt">h_grid=</span>chi, sigma_g)</code></pre>
<p>Which is a list of matrices, one for each harvest (action) <span class="math">\(x_t\)</span>.</p>
<p>Then we want to consider a fixed <span class="math">\(S_t^n\)</span> and fixed <span class="math">\(x_t\)</span>, and take the sum of <span class="math">\(\mathbb{P}(s^{\prime} | S_t^n, x_t)\)</span> over the <span class="math">\(s^{\prime}\)</span>, which means we want the <span class="math">\(x_t\)</span> element from the list, and then we need sum over the distribution of future states given the current state <span class="math">\(S_t^n\)</span>, e.g. a row of the matrix, e.g. <code>sdp_matrix[[x]][s,]</code>, which we (vector) multiply by <span class="math">\(V_{t+1}^{n-1}(s^{\prime})\)</span>.</p>
<p>This value <span class="math">\(V\)</span> is of course unknown, other than our initial random guess <span class="math">\(V_{t}^0\)</span>.<br />As we step through the iterations <span class="math">\(V_t^1\)</span>, <span class="math">\(V_t^2\)</span>, <span class="math">\(V_t^3\)</span>, etc., this should convgerge to something meaningful.</p>
<p>Note that the index along <span class="math">\(S\)</span> corresponding to <span class="math">\(S_t^n\)</span> is given by</p>
<pre class="sourceCode r"><code class="sourceCode r">s &lt;- <span class="kw">which.min</span>(<span class="kw">abs</span>(S-S_0))</code></pre>
<p>So our maximization across <span class="math">\(x\)</span> just involves:</p>
<pre class="sourceCode r"><code class="sourceCode r">values &lt;- 
  <span class="kw">sapply</span>(<span class="dv">1</span>:<span class="kw">length</span>(chi), function(x)
    <span class="kw">C</span>(S[s], chi[x]) + sdp_matrix[[x]][s,] %*% V
)

max_x &lt;- <span class="kw">which.max</span>(values)
v_hat &lt;- <span class="kw">max</span>(values)</code></pre>
<p>Trivially, this is just the harvest level that maximizes <span class="math">\(C\)</span> so far (which is just harvesting the <span class="math">\(S_0\)</span>, since <span class="math">\(\bar V^0_t\)</span> begins at zero:</p>
<pre class="sourceCode r"><code class="sourceCode r">chi[max_x]</code></pre>
<pre><code>[1] 0.5</code></pre>
<ul>
<li>step <strong>2b</strong> We can now update our <span class="math">\(\bar V^0_t\)</span> to get <span class="math">\(\bar V^1_t\)</span>, using the rule:</li>
</ul>
<p><span class="math">\[V_t^n(S_t) = \begin{cases} 
\hat v_t^n &amp; S_t = S_t^n \\
\bar V_t^{n-1}(S_t) &amp; \textrm{otherwise} 
\end{cases}\]</span></p>
<p>e.g. use our maximum value for the case of the state we just considered <span class="math">\(S_t = S_t^n\)</span>, otherwise leave <span class="math">\(V_t\)</span> unchanged. Our new <span class="math">\(V\)</span> is thus:</p>
<pre class="sourceCode r"><code class="sourceCode r">V[s] = v_hat</code></pre>
<ul>
<li>step <strong>2c</strong> Compute <span class="math">\(S^n_{t+1} = S^M(S_t^n, x^n_t, W_{t+1}(\omega^n))\)</span></li>
</ul>
<p>We compute the next state using our <code>max_x</code> for <span class="math">\(x^n_t\)</span>, our random samples and the transition function…</p>
<pre class="sourceCode r"><code class="sourceCode r">S_1 &lt;- omega_n[<span class="dv">1</span>] * <span class="kw">f</span>(S_0, chi[hat[<span class="st">&quot;x_nt&quot;</span>]], p)</code></pre>
<ul>
<li><strong>Step 3</strong> Let <span class="math">\(n = n+1\)</span>. if <span class="math">\(n &lt; N\)</span>, go to step 1</li>
</ul>
<h2 id="putting-this-all-together-as-a-recursive-algorithm">Putting this all together as a recursive algorithm</h2>
<pre class="sourceCode r"><code class="sourceCode r">N &lt;- <span class="dv">5000</span> <span class="co"># iterations</span>
M &lt;- <span class="dv">20</span> <span class="co"># gridsize </span>
Tmax &lt;- <span class="dv">5</span> <span class="co"># Time horizon</span>

gamma &lt;- <span class="fl">0.95</span> <span class="co"># Discount</span>
<span class="co"># f (defined above) </span>
<span class="co"># p  (defined above)</span>

sigma_g &lt;- <span class="fl">0.5</span> <span class="co"># larger variation in random draws helps</span>
chi &lt;- <span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dt">length.out =</span> M)
S &lt;- <span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dt">length.out =</span> M)

sdp_matrix &lt;- <span class="kw">determine_SDP_matrix</span>(f, p, <span class="dt">x_grid=</span>S, <span class="dt">h_grid=</span>chi, sigma_g)

V &lt;- <span class="kw">matrix</span>(<span class="dv">1</span>, M, Tmax)  <span class="co"># A* strategy</span>
<span class="co"># Fails to explore at matrix(0, M, Tmax)</span>
<span class="co"># consider: # V &lt;- matrix(rep(chi, Tmax), nrow=M) # </span>
<span class="co"># V[,1] &lt;- chi   # fails to explore if it doesn&#39;t have at least some non-zero values</span>

C &lt;- function(S, X) <span class="kw">pmin</span>(S, X)
S_0 &lt;- <span class="fl">0.5</span> 
alpha &lt;- <span class="dv">1</span> <span class="co"># learning rate</span>


for(n in <span class="dv">1</span>:N){
  
  omega_n &lt;- <span class="kw">rlnorm</span>(Tmax, <span class="dv">0</span>, sigma_g)
  S_current &lt;- S_0 <span class="co">#runif(1,0,1) # explores faster when this is random</span>

  for(t in <span class="dv">1</span>:Tmax){
    <span class="co"># index of the state we&#39;re considering</span>
    s &lt;- <span class="kw">which.min</span>(<span class="kw">abs</span>(S-S_current)) 
    
    <span class="co"># Find the action maximizing the value</span>
    values &lt;- <span class="kw">sapply</span>(<span class="dv">1</span>:<span class="kw">length</span>(chi), function(x)
      <span class="kw">C</span>(S[s], chi[x]) + gamma * sdp_matrix[[x]][s,] %*% V[,t])
    hat &lt;-  <span class="kw">c</span>(<span class="dt">x_nt =</span> <span class="kw">which.max</span>(values), <span class="dt">v_nt =</span> <span class="kw">max</span>(values))

    <span class="co"># Update value V as mixture of new value and previous value</span>
    V[hat[<span class="st">&quot;x_nt&quot;</span>], t] &lt;- (<span class="dv">1</span> - alpha) * V[hat[<span class="st">&quot;x_nt&quot;</span>],t] + alpha * hat[<span class="st">&quot;v_nt&quot;</span>] 
    
    <span class="co"># Advance the state in time along random path  </span>
    S_current &lt;- omega_n[t] * <span class="kw">f</span>(S_current, chi[hat[<span class="st">&quot;x_nt&quot;</span>]], p)

  }
}</code></pre>
<p>for comparison: the SDP solution</p>
<pre class="sourceCode r"><code class="sourceCode r">opt &lt;- <span class="kw">find_dp_optim</span>(sdp_matrix, S, chi, <span class="dv">70</span>, <span class="fl">0.5</span>, C, <span class="dv">1</span>-gamma, <span class="dt">reward=</span><span class="dv">0</span>)
opt$V</code></pre>
<pre><code> [1] 0.000 7.173 7.375 7.496 7.584 7.653 7.710 7.760 7.810 7.860 7.910
[12] 7.960 8.010 8.060 8.110 8.160 8.210 8.260 8.310 8.360</code></pre>
<h3 id="problems-arising-from-the-discretization">Problems arising from the discretization</h3>
<p>Note that after the first iteration, <span class="math">\(n=1\)</span>, the value matrix <span class="math">\(V\)</span> is no longer all zeros. There is a single state, <span class="math">\(S = S_0 =\)</span> 0.5, at which we have value. That value is lost if we set harvest <span class="math">\(x\)</span> too high, since we know we will not then end up in that state – from whence comes the incentive to consider future value. Unfortunately, the value exists only if we hit that state exactly – all other states are assumed to have zero value still.</p>
<h3 id="additional-problems">Additional problems</h3>
<p>We no longer have the loop-over-all-states problem, but we face several new or remaining issues:</p>
<ol type="1">
<li><p>We still require the use of the one-step transition matrix, with the equally troublesome sum over all states <span class="math">\(\sum_{s^{\prime}\in S} \mathbb{P}(s^{\prime} | S_t^n, x_t)\)</span>.<br />We will fix this by approximating the transitions in step 2b using random draws as well.</p></li>
<li><p>We only update the values of states we visit. We still need a way to estimate the value of states we have not visited.</p></li>
<li><p>Worse, we might not visit states that seem bad relative to states we have visited. This is particularly atrocious in this example. Since we initialize the value of all states at 0, the algorithm prefers to harvest all stock from the current state rather than risk a transition into a state starting at 0. There is no convergence guarentee that we will ever escape this cycle of avoiding states we have not seen. We can alter the initial guess of the value of course, and we could alter the starting condition to better explore.</p></li>
</ol>
<h2 id="extensions">Extensions</h2>
<p>The rest of the ADP development is designed to tackle each of these issues. This algorithm gives very poor performance, but very flexible skeleton on which to extend features that have made ADP such a successful approach for impossibly large problems.</p>
<h3 id="stochastic-value-function-sampling">Stochastic value function sampling</h3>
<p>Dealing with problem 1:</p>
<p><span class="math">\[V_t(S_t) = \max_{x_t \in \chi_t} \left(C(S_t, x_t) + \gamma \sum_{\hat \omega \in \hat \Omega^n_{t+1}} p_t+1(\hat \omega) \bar V_{t+1}^{n-1} (S_{t+1}) \right)\]</span></p>
<pre class="sourceCode r"><code class="sourceCode r">    V[hat[<span class="st">&quot;x_nt&quot;</span>], t] &lt;- (<span class="dv">1</span> - alpha) * 
                         V[hat[<span class="st">&quot;x_nt&quot;</span>],t] + 
                          alpha * hat[<span class="st">&quot;v_nt&quot;</span>] </code></pre>
<h3 id="decreasing-the-state-space-size">Decreasing the state space size</h3>
<ul>
<li>Aggregation</li>
<li>Continuous Value function approximations</li>
<li>Using the post-decision state variable (improves dealing with the expectation calc)</li>
</ul>
<h3 id="initialization-problem">Initialization problem</h3>
<ul>
<li>We do not explore if we are too pessimistic about value of visiting other states. Start optimisitc: AI’s A* alogrithm (synchronous)</li>
<li>Asynchronous updating – randomly sampling starting variables</li>
<li>RTDP (Real Time Dynamic Programming – not necessarily what it sounds like) external rule determines which states we visit</li>
</ul>
<h3 id="learning">Learning</h3>
<ul>
<li>The concepts of learning and the trade-off between exploration and exploitation are already built-in to the forward algorithm.</li>
</ul>
<h3 id="using-non-stochastic-transition-information-only-step-2b-can-be-written-as">Using Non-stochastic transition information only, step <strong>2b</strong> can be written as:</h3>
<p>Taking <span class="math">\(x_0\)</span> as the smallest harvest, <span class="math">\(\min(\chi)\)</span> = 0 and evaluating <span class="math">\(C(S_0,X_0) = \min(S_0, X_0)\)</span> gives us 0, rather trivially.<br />The next terms depend on the value <span class="math">\(\tilde V^0_1(s^{\prime})\)</span> for all <span class="math">\(s^{\prime} \in S\)</span>, which we have no idea about. Fortunately we have assumed a value for each of these in step 0a.</p>
<p>We must also come up with some values for the probability <span class="math">\(\mathbb{P}(s^{\prime} | S_1^0, x_1)\)</span> for each state, given our current state <span class="math">\(S_1^0\)</span> and considered action <span class="math">\(x_1\)</span>. This is more straight forward, since it is determined by our one-step transition function (without simulation - recall that the single step transition is given exactly).</p>
<p>To do so, we evaluate the argument for each value in our action space, <span class="math">\(x_t \in \chi_t\)</span>,</p>
<pre class="sourceCode r"><code class="sourceCode r">s &lt;- S_0
C &lt;- function(S, X) <span class="kw">pmin</span>(S, X)
arg &lt;- <span class="kw">sapply</span>(chi, function(x) <span class="kw">C</span>(s, x) + <span class="kw">f</span>(S, x, p) %*% V)
x_nt = <span class="kw">which.max</span>(arg)
v_nt = <span class="kw">max</span>(arg)
V[x_nt] = v_nt</code></pre>
 
<!-- not that raw_content depends on custom generator, 
     see _plugins/jekyll-labnotebook-plugins/raw_content --> 
</article> 
<p> <a href="/2013/05/27/exploring-approximate-dynamic-programming-approaches.html"> <em>Read more</em></a> </p>
<br />
<br />


        </div>
      
    </div>

    <div class="row">
      
        <div class="span3">
          <header><h4><a href="/2013/05/24/notes.html">Notes</a></h4></header>
<p><span></span></p>
<p style="font-style:italic"> 24 May 2013</p>

<p style="font-style:italic"> pageviews: 7 </p>

<article>
<div class="excerpt">
<h3 id="prosecutor">prosecutor</h3>
<ul>
<li>Bit more writing on comment reply. Sent to Alex and Alan for feedback.</li>
</ul>
<h3 id="nonparametric-bayes">nonparametric-bayes</h3>
<p>Demonstrating robustness of the GP approach is remarkably difficult ironically because the comparison methods are not particularly robust; most often due to poor initial conditions. Doing all I can to make the MLE and parametric Bayesian cases suitably automated such that the can give reasonable performance as I loop over various simulation parameters and models without much hand-holding of each of the estimators.</p>
<p>Also an automatic sensitivity analysis gets pretty computationally intensive and generates a lot of different outputs to keep track of, trying to improve this through cleaner code, parallelization, caching, chunk dependencies, and namespaces for scripts.</p>
<ul>
<li>Playing with mcmc convergence over initial conditions</li>
<li>Running case without measurement error for parametric bayesian models</li>
<li>Adaptuing runs for parallel and for execution on farm cluster</li>
<li>Consider ADMB for the MLE estimate to be a bit more robust for automated cases.</li>
</ul>
<h3 id="log">Log</h3>
<ul>
<li>process noise only example (first attempt) <a href="https://github.com/cboettig/nonparametric-bayes/commit/be4d986b46f98d27f19add3ac42e536ee4ef5805">04:50 pm 2013/05/24</a></li>
<li>Consider the case of process noise only in the parametric bayesian versions <a href="https://github.com/cboettig/nonparametric-bayes/commit/bbeaf4fc6b5f999e04d02b3487151c982bcf6771">03:38 pm 2013/05/24</a></li>
<li>parallel jags <a href="https://github.com/cboettig/nonparametric-bayes/commit/29db77699a8ff6b9041f45a952a548b6cd255af3">03:31 pm 2013/05/24</a></li>
</ul>
 
<!-- not that raw_content depends on custom generator, 
     see _plugins/jekyll-labnotebook-plugins/raw_content --> 
</article> 
<p> <a href="/2013/05/24/notes.html"> <em>Read more</em></a> </p>
<br />
<br />


        </div>
      
        <div class="span3">
          <header><h4><a href="/2013/05/23/notes.html">Notes</a></h4></header>
<p><span></span></p>
<p style="font-style:italic"> 23 May 2013</p>

<p style="font-style:italic"> pageviews: 4 </p>

<article>
<div class="excerpt">
<ul>
<li>Added multiple chains, randomized starting points for each chain, and confirming Gelman-Rubin convergence criteron via <code>autojags</code>.<br /></li>
<li>Some edits to adapt the extraction of posteriors from the multiple chains.<br /></li>
<li>Stange behavior in <code>jags.parallel</code> <a href="http://stackoverflow.com/questions/16723036">SO/16723036</a>, looks like an annoying bug.</li>
<li>Ah-ha, and now a nice solution to this problem via <code>do.call</code>.</li>
</ul>
<p>When running on farm, try to remember: (yes it’s in the run.sh script already).</p>
<pre class="sourceCode bash"><code class="sourceCode bash">module load <span class="kw">gcc</span> R jags</code></pre>
<p>This appears to result in greater uncertainty:</p>
<figure>
<img src="http://farm4.staticflickr.com/3826/8797217705_c75548ffa7_o.png" />
</figure>
<p>Suggesting the earlier appearance of convergence occurs only thanks to starting conditions close to the optimum?</p>
<h2 id="log">Log</h2>
<ul>
<li>parallel jags working now <a href="https://github.com/cboettig/nonparametric-bayes/commit/92a1d8d6a1fba819f419d069b0a089da891041e7">05:53 pm 2013/05/23</a></li>
<li>cleanup <a href="https://github.com/cboettig/nonparametric-bayes/commit/e5d76a0718997c215521beb4cbba740b42ff3791">04:50 pm 2013/05/23</a></li>
<li>generic version of allen <a href="https://github.com/cboettig/nonparametric-bayes/commit/669245f2e39839e06cdf58e290b22b783eb08aad">04:09 pm 2013/05/23</a></li>
<li><p>Revising MCMC iterations</p></li>
<li>Added multiple chains, randomized starting points for each chain, and confirming Gelman-Rubin convergence criteron via <code>autojags</code>.</li>
<li>Some edits to adapt the extraction of posteriors from the multiple chains.</li>
<li>Stange behavior in <code>jags.parallel</code> <a href="http://stackoverflow.com/questions/16723036">SO/16723036</a>, looks like an annoying bug. <a href="https://github.com/cboettig/nonparametric-bayes/commit/98b6a58bca43fe25ab0224d582f18a820ac5c57e">04:05 pm 2013/05/23</a></li>
<li><p>No reply from query to package maintainer, but the SO link now has a clever work-around to said annoying bug.</p></li>
</ul>
<h2 id="misc">Misc</h2>
<ul>
<li>Grr, why is <code>dcast</code> not more intuitive to me. Thank you SO folks. <a href="http://stackoverflow.com/questions/16722117">SO/16722117</a></li>
</ul>
 
<!-- not that raw_content depends on custom generator, 
     see _plugins/jekyll-labnotebook-plugins/raw_content --> 
</article> 
<p> <a href="/2013/05/23/notes.html"> <em>Read more</em></a> </p>
<br />
<br />


        </div>
      
        <div class="span3">
          <header><h4><a href="/2013/05/22/notes.html">Notes</a></h4></header>
<p><span></span></p>
<p style="font-style:italic"> 22 May 2013</p>

<p style="font-style:italic"> pageviews: 2 </p>

<article>
<div class="excerpt">
<h2 id="nonparametric-bayes">Nonparametric-bayes</h2>
<ul>
<li><p>Establishing chunck dependencies, simplifying and abstracting code.</p></li>
<li>still need to fix up Allen MCMC convergence when underlying model is Myers <a href="https://github.com/cboettig/nonparametric-bayes/commit/dce19f44d6dec779ba5a1a3e245365cdca4bb034">10:18 am 2013/05/22</a></li>
<li><p>replicate runs on data from allen and myers model <a href="https://github.com/cboettig/nonparametric-bayes/commit/f8a241c677583ef3b324f274f3846b08243ddacb">08:39 pm 2013/05/21</a></p></li>
</ul>
<h3 id="clean-code-for-complicated-scripts">Clean code for complicated scripts</h3>
<p>Pseudo-code somewhat captured by the chuncks. Ideal would be:</p>
<ul>
<li>Define models</li>
<li>Define parameters</li>
<li>Simulate data</li>
<li>Estimate MLE</li>
<li>Estimate under GPP</li>
<li>Allen MCMC</li>
<li>Ricker MCMC</li>
<li>Myers MCMC</li>
<li>Determine optimal policy for each…</li>
<li>Simulation</li>
<li>Graphs</li>
</ul>
<h2 id="a-preponderance-of-preprint-servers">A preponderance of preprint servers</h2>
<p>Having sent in my review for IEE, do I also post it on the peerJ preprint? File each complaint or suggestion as issue on the paper’s Github repository? Post a comment on the corresponding author’s blogpost on the paper? In my own online notebook? Oh, the reviewer’s plight! From review-recognition poverty to an embarassment of riches!</p>
<h2 id="other-writing-and-thoughts">Other writing and thoughts</h2>
<ul>
<li>Open Science cover letters?</li>
<li><a href="https://plus.google.com/112929796403983408632/posts/8whV6rtvsuw">In which I rant about scientific software</a> again</li>
</ul>
<h2 id="ews-review">ews-review</h2>
<ul>
<li>re-submitted. <a href="https://github.com/cboettig/ews-review/tags">submmitted_revisions tag</a></li>
</ul>
<h2 id="reading">Reading</h2>
<ul>
<li><p><span class="showtooltip" title="Joppa L, McInerny G, Harper R, Salido L, Takeda K, O'Hara K,
Gavaghan D and Emmott S (2013). Troubling Trends in Scientific
Software Use. _Science_, *340*. ISSN 0036-8075, 
http://dx.doi.org/10.1126/science.1231535."><a href="http://dx.doi.org/10.1126/science.1231535" rel="http://purl.org/spar/cito/critiques" >Joppa <em>et. al.</em> (2013)</a></span> utoh… I rant about software again</p></li>
<li><p><a href="http://theseamonster.net/2013/05/are-unreasonably-harsh-reviewers-retarding-the-pace-of-coral-reef-science/">Are unreasonably harsh reviews retarding the pace of coral reef science?</a> I applaud the spirit of this piece. When I saw the article, <span class="showtooltip" title="Coral reef baselines: how much macroalgae is natural?.  https://peerj.com/preprints/19/."><a href="https://peerj.com/preprints/19/" rel="http://purl.org/spar/cito/discusses" >Bruno <em>et al.</em> (2013)</a></span> appear on PeerJ last week I thought to myself, “Ooh, looks like controversial stuff! Bravo for using a preprint server,” so it is quite delightful to read the back story and confirm my guess. Though I am a proponent of open peer review, I find the practice of posting anonymous peer reviews a bit ethically murky still.</p></li>
</ul>
<h2 id="misc">Misc</h2>
<ul>
<li><p>Trying to submit <a href="https://github.com/cboettig/knitcitations">knitcitations</a> to CRAN; R-devel has updated linewrapping requirements that brake roxygen2 <a href="https://github.com/klutometis/roxygen/issues/125">roxygen/125</a>, so have to correct <code>.Rd</code> files after the fact.</p></li>
<li><p>My ans: <a href="http://opendata.stackexchange.com/questions/522">Open data vs Linked data</a> on opendata.stackexchange opendata SO launches public beta</p></li>
<li><p><a href="http://stackoverflow.com/questions/1312087/">Why people don’t use WADL</a> Basically we can accomplish structure much better by having well-defined media types. We can define the schema of the json or xml file we return, <sup><a href="#fn1" class="footnoteRef" id="fnref1">1</a></sup> and then the application knows what to expect and what it can do with the data. This is far more useful than just having a programmatic version of the API calls in the native language (“client objects”). Seems like REST was supposed to make such things obsolete, and to make deploying the API far simpler than it was in SOAP (which provides WSDL).</p></li>
<li><p>An interesting discussion on <a href="http://barelyenough.org/blog/2008/05/versioning-rest-web-services/">using mediatypes for REST APIs</a>, which might be referred to as the <a href="http://barelyenough.org/blog/2007/05/hypermedia-as-the-engine-of-application-state/">HATEOAS</a> approach:</p></li>
</ul>
<blockquote>
<p>which basically means that responses from the server will be documents that include URIs to everything you can do next</p>
</blockquote>
<p>hmm, a powerful idea.</p>
<h2 id="references">References</h2>
<ul>
<li>L. N. Joppa, G. McInerny, R. Harper, L. Salido, K. Takeda, K. O’Hara, D. Gavaghan, S. Emmott, (2013) Troubling Trends in Scientific Software Use. <em>Science</em> <strong>340</strong> <a href="http://dx.doi.org/10.1126/science.1231535">10.1126/science.1231535</a></li>
<li>Bruno et al. (2013) <a href="https://peerj.com/preprints/19/">https://peerj.com/preprints/19/</a></li>
</ul>
<section class="footnotes">
<hr />
<ol>
<li id="fn1"><p>yes, JSON has schemas too. wow.<a href="#fnref1">↩</a></p></li>
</ol>
</section>
 
<!-- not that raw_content depends on custom generator, 
     see _plugins/jekyll-labnotebook-plugins/raw_content --> 
</article> 
<p> <a href="/2013/05/22/notes.html"> <em>Read more</em></a> </p>
<br />
<br />


        </div>
      
    </div>

  </div>
</div> <!--end row -->

<div class="row">
  <div class="span11 offset1">
    <div class="socialicons">
      <p> <a href="/archive.html"><i class="icon-calendar"></i> All entries by date</a></p> 
      <p> <a href="/categories.html"><i class="icon-list"></i> All entries by category</a> </p>
      <p> <a href="/tags.html"><i class="icon-tags"></i> All entries by tag</a> </p>
    </div>
  </div> <!--end span9 -->
</div> <!--end row -->




<footer class="footer">
  <!-- ************* Buttons to toggle theme CSS ********************** -->
    <div class="row">
      <div class="span12">
        <form style="font-size:10px" class="pull-right">
          <a onclick="switch_style('dark'); 
                      recordOutboundLink(this, 'Outbound Links', 'dark theme'); 
                      return false;" 
             name="theme" value="dark" id="dark" 
             class="btn btn-mini"><span class="showtooltip" 
                                        title="switch to dark theme"><i class="icon-adjust"></i>
                                   </span></a>
          
          <a onclick="switch_style('light'); 
                      recordOutboundLink(this, 'Outbound Links', 'light theme'); 
                      return false;" 
             name="theme" value="light" id="light" 
             class="btn btn-mini"><span class="showtooltip" 
                                        title="switch to light theme"><i class="icon-certificate"></i>
           <a onclick="switch_style('white'); 
                      recordOutboundLink(this, 'Outbound Links', 'white theme'); 
                      return false;" 
             name="theme" value="white" id="white" 
             class="btn btn-mini"><span class="showtooltip" 
                                        title="switch to white theme"><i class="icon-circle-blank"></i>
                                  </span></a>
                                 </span></a>
        </form>
      </div>
    </div>

<!--************** FOAF information to social networks ***************************** -->
  <div class="row">
    <div class="span3 socialicons" style="font-size:20px" typeof="foaf:Person" about="http://www.carlboettiger.info#me">
      <p>
          <script type="text/javascript" src="/assets/js/obfuscate-email-link.js" language="javascript"></script> 
          <a rel="foaf:account" alt="twitter" href="https://twitter.com/cboettig" 
             onclick="recordOutboundLink(this, 'Outbound Links', 'Twitter'); 
             return false;"><span class="showtooltip" title="follow me on twitter (reading, discussing)"><i class="icon-twitter"></i></span></a> 
          <a rel="foaf:account" alt="github" href="https://github.com/cboettig" 
             onclick="recordOutboundLink(this, 'Outbound Links', 'Github'); 
             return false;"><span class="showtooltip" title="follow me on Github (code, research)"><i class="icon-github"></i></span></a>
      <!--
          <a rel="foaf:account" href="https://plus.google.com/" 
             onclick="recordOutboundLink(this, 'Outbound Links', 'GPlus'); 
             return false;"><i class="icon-google-plus"></i></a>
          <a rel="foaf:account" href="http://www.mendeley.com/profiles/carl-boettiger" 
             onclick="recordOutboundLink(this, 'Outbound Links', 'Mendeley'); 
             return false;"><img src="/assets/img/icon-mendeley.png" alt="mendeley" /></a> 
           citations on google-scholar
           stackoverflow
      -->
      <a alt="rss" type="application/atom+xml" href="/atom.xml"  
         class="showtooltip" title="subscribe to RSS feeds for my open lab notebook" 
         onclick="recordOutboundLink(this, 'Outbound Links', 'RSS'); 
         return false;"><i class="icon-rss"></i></a>
       </p>
    </div>
    <!--**************** End social links **************************** -->
    <div class="span1">
      <br />
    </div>
    <div class="span4">
      <p>
      <a onclick="recordOutboundLink(this, 'Outbound Links', 'ONS_claim'); return false;" href="http://onsclaims.wikispaces.com/"><img src="http://onsclaims.wikispaces.com/file/view/ons-aci2-icon.png" alt="ONS" class="showtooltip" title="An Open Notebook Science (ONS) project claim: Entry provides all content (AC) immediately (I) or without significant delay.  See link for details"/></a>

      <a title="This site uses linked data semantics. Click to extract as RDF XML." class="btn btn-mini showtooltip" style="font-size: .8em" 
       href="http://any23.org/?format=rdfxml&validate=validate&uri=http://www.carlboettiger.info/lab-notebook.html"><i 
         class="icon-cloud-download"  onclick="recordOutboundLink(this, 'Outbound Links', 'RDF'); return false;"></i> RDF</a>
      </p>
    </div>
    <div class="span1">
      <br />
    </div>
    <div class="span3">
      <p>
      <a rel="license" property="http://creativecommons.org/ns#license" href="http://creativecommons.org/publicdomain/zero/1.0/" onclick="recordOutboundLink(this, 'Outbound Links', 'CC0'); return false;"><img src="http://i.creativecommons.org/l/zero/1.0/88x31.png" alt="CC0"/></a> 
      </p>
    </div>

  </div>
  
<!-- COinS metadata (for citation managers like Zotero etc), goes in body text -->
  <span
      class="Z3988" 
      title="ctx_ver=Z39.88-2004
      &amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Adc
      &amp;rfr_id=info%3Asid%2Focoins.info%3Agenerator
      &amp;rft.title=Lab Notebook
      &amp;rft.creator=Carl Boettiger
      &amp;rft.date=
      &amp;rft.language=EN
      &amp;rft.rights=CC0
      &amp;rft_id=http://www.carlboettiger.info/lab-notebook.html">
  </span>



</footer>




    <!-- Le javascript
    ================================================== -->

    <!-- Placed at the end of the document so the pages load faster -->
    <!-- JQuery, used on a few pages -->
    <script type="text/javascript" src="/assets/js/jquery.js"></script>
    <!-- Equations using MathJax -->
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config"> MathJax.Hub.Config({ TeX: { equationNumbers: {autoNumber: "all"} } });       </script>
    <!-- Twitter Bootstrap Javascript -->
    <script src="/assets/js/bootstrap.min.js"></script>
    <!-- Tooltip javascript -->
    <script type="text/javascript">
      $(document).ready(function (){
        $(".showtooltip").tooltip();
      });
    </script>

    <!-- Marran's Search Javascript -->
    <script type="text/javascript" src="/assets/js/porter-stemmer.js"></script>
    <script type="text/javascript" src="/assets/js/site-search.js"></script>

    <!-- Code collapse Javascript -->
    <script type="text/javascript">
    $(document).ready(function(){
      $("#toggle_code").click(function(){
        $(".highlight").toggle();
        $(".sourceCode").toggle();
      });
    });
    </script>


  <script type="text/javascript">
          var _gaq = _gaq || [];
          _gaq.push(['_setAccount', 'UA-18401403-1']);
          _gaq.push(['_trackPageview']);
          (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
          })();
  </script>



<script type="text/javascript">
function recordOutboundLink(link, category, action) {
  try {
    var pageTracker=_gat._getTracker("UA-18401403-1");
    pageTracker._trackEvent(category, action);
    setTimeout('document.location = "' + link.href + '"', 100)
  }catch(err){}
}
</script>




    


    </div>
  </body>
</html>

